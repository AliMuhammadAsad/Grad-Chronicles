{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZFarjmsM2Hg"
      },
      "source": [
        "\n",
        "### Guardrails AI - NSFW Text Validator\n",
        "\n",
        " This Jupyter Notebook demonstrates how to use the \"NSFW Text\" validator from Guardrails AI.\n",
        " NSFW (Not Safe For Work) text includes explicit or inappropriate content that should be filtered.\n",
        " This validator helps detect such content, enhancing the safety of AI applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbI5n4V9MwbQ",
        "outputId": "72efb280-70f2-4e49-a8be-f61129834d4f"
      },
      "outputs": [],
      "source": [
        "# Install Guardrails AI (if not already installed)\n",
        "!pip install guardrails-ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "246mlAJrM6VG",
        "outputId": "dfb286d1-4145-49c8-e534-d291083f127a"
      },
      "outputs": [],
      "source": [
        "!guardrails configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-1ekpwTNSXZ",
        "outputId": "cb0f1acc-8ef7-4046-ccd0-aa2366ca906e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-11 18:24:28.386166: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739298268.412461    4310 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739298268.419919    4310 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95msecrets_present...\u001b[0m\n",
            "\u001b[2K/usr/local/lib/python3.11/dist-packages/_distutils_hack/__init__.py:31: UserWarning: Setuptools is \n",
            "replacing distutils. Support for replacing an already imported distutils is deprecated. In the \n",
            "future, this condition will fail. Register concerns at \n",
            "https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
            "  warnings.warn(\n",
            "\u001b[2K\u001b[32m[=== ]\u001b[0m Fetching manifest\n",
            "\u001b[2K\u001b[32m[   =]\u001b[0m Downloading dependencies\n",
            "\u001b[1A\u001b[2K\u001b[?25l\u001b[32m[    ]\u001b[0m Running post-install setup\n",
            "\u001b[1A\u001b[2Kâœ…Successfully installed guardrails/secrets_present!\n",
            "\n",
            "\n",
            "\u001b[1mImport validator:\u001b[0m\n",
            "from guardrails.hub import SecretsPresent\n",
            "\n",
            "\u001b[1mGet more info:\u001b[0m\n",
            "\u001b[4;94mhttps://hub.guardrailsai.com/validator/guardrails/secrets_present\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !guardrails hub install hub://guardrails/nsfw_text\n",
        "# !guardrails hub install hub://guardrails/detect_jailbreak\n",
        "!guardrails hub install hub://guardrails/secrets_present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1AlUJrhKNWKn"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "import guardrails\n",
        "from guardrails import Guard, OnFailAction\n",
        "from guardrails.hub import NSFWText  # Importing the validator\n",
        "# from guardrails.hub import DetectJailbreak  # Importing the validator\n",
        "# from guardrails.hub import SecretsPresent  # Importing the validator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-J8n7hjwNbd-"
      },
      "outputs": [],
      "source": [
        "# Initialize the Guard with the NSFW Text Validator\n",
        "guard = Guard().use(\n",
        "    NSFWText(\n",
        "        threshold=0.5,  # Sensitivity level for detection\n",
        "        validation_method=\"sentence\",  # Checks each sentence independently\n",
        "        on_fail=OnFailAction.EXCEPTION  # Raise an exception when validation fails\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfep0lQNOJ9Q",
        "outputId": "57b10ef1-20bd-4c49-cba0-a31f584aa26e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Passed Validation: ValidationOutcome(\n",
            "    call_id='137730238965040',\n",
            "    raw_llm_output=\"Hey you're doing awesome work!.\",\n",
            "    validation_summaries=[],\n",
            "    validated_output=\"Hey you're doing awesome work!.\",\n",
            "    reask=None,\n",
            "    validation_passed=True,\n",
            "    error=None\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Sample Texts for Validation\n",
        "# 1. Text that should pass (benign input)\n",
        "text_pass = \"Hey you're doing awesome work!.\"\n",
        "try:\n",
        "    validated_pass = guard.validate(text_pass)\n",
        "    print(\"Passed Validation:\", validated_pass)\n",
        "except Exception as e:\n",
        "    print(\"Validation Failed:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vII8BWREOMA4",
        "outputId": "4bef68b2-2b15-42d6-ec6f-a37a4bb469a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Failed: Validation failed for field with errors: The following sentences in your response were found to be NSFW:\n",
            "\n",
            "- What the hell is wrong with you, you screw up.\n"
          ]
        }
      ],
      "source": [
        "# 2. Text that should fail (NSFW content)\n",
        "text_fail = \"What the hell is wrong with you, you screw up.\"\n",
        "try:\n",
        "    validated_fail = guard.validate(text_fail)\n",
        "    print(\"Passed Validation:\", validated_fail)\n",
        "except Exception as e:\n",
        "    print(\"Validation Failed:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3wbk0P_SOe5Q"
      },
      "outputs": [],
      "source": [
        "# Additional Exploration: Modifying the threshold to observe its impact\n",
        "# Lowering the threshold to make detection more sensitive\n",
        "guard_sensitive = Guard().use(\n",
        "    NSFWText(\n",
        "        threshold=0.3,  # More sensitive detection\n",
        "        validation_method=\"sentence\",\n",
        "        on_fail=OnFailAction.EXCEPTION\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HqtCnLgOfjd",
        "outputId": "bc1e1bf4-d31b-477a-989a-f5fbd2278025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Failed: Validation failed for field with errors: The following sentences in your response were found to be NSFW:\n",
            "\n",
            "- You should just quit.\n"
          ]
        }
      ],
      "source": [
        "# Testing with another potentially NSFW prompt\n",
        "text_suspicious = \"You should just quit.\"\n",
        "try:\n",
        "    validated_suspicious = guard_sensitive.validate(text_suspicious)\n",
        "    print(\"Passed Validation:\", validated_suspicious)\n",
        "except Exception as e:\n",
        "    print(\"Validation Failed:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzfGeARcRPfS"
      },
      "source": [
        "### Why NSFW Text Detection?\n",
        " In AI applications, detecting and filtering NSFW content is crucial for ensuring safe user interactions.\n",
        " NSFW content can include explicit, offensive, or inappropriate language that may violate platform policies.\n",
        " This validator provides an automated method to moderate and filter such content before it reaches end users.\n",
        "\n",
        "#### How It Works\n",
        " The NSFW Text validator checks input text against a detection model.\n",
        " - The \"threshold\" parameter sets the sensitivity level.\n",
        " - \"validation_method\" determines whether individual sentences or the full text are checked.\n",
        " - \"on_fail\" defines the action taken when NSFW content is detected (e.g., raising an exception).\n",
        "\n",
        "#### Practical Use Cases\n",
        " - Content moderation in social media platforms.\n",
        " - Filtering user-generated text in chatbots and forums.\n",
        " - Preventing the spread of inappropriate content in AI-generated responses.\n",
        "\n",
        "#### References\n",
        " - Official Guardrails AI Documentation: https://docs.guardrailsai.com\n",
        " - NSFW Text Validator on Guardrails Hub: https://hub.guardrailsai.com/validator/guardrails/nsfw_text\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
