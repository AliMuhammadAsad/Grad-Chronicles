## **Assignment: Investigating Harmful AI News**

### **Objective**

1. **Real-World Analysis**: Identify a real incident where AI (or Generative AI) caused harm or raised significant ethical/safety/security concerns.  
2. **Critical Examination**: Summarize what happened, who was affected, and how.  
3. **Preventative Measures**: Propose strategies that could have prevented the harm and outline measures to avoid similar incidents in the future.  
4. **Presentation**: Prepare a short (2-minute) in-class presentation summarizing your findings and recommendations.

---

### **Instructions**

1. **Find a Real AI-Related News Story**  
   - The story **must be recent** (within the last 5-6 years) and involve tangible harm or risk, whether it’s bias, privacy breaches, security vulnerabilities, or other unintended consequences of AI.  
   - Possible sources: reputable news outlets, AI industry blogs, academic conference publications, official company statements, etc.  
   - **Important**: You cannot use the Amazon AI bias story provided below—it’s just an example.

2. **Summarize the Incident**  
   - **Identify the context**: Who is involved (the company or institution)? What technology or AI feature was used?  
   - **Clarify the harm**: Explain, in your own words, how the AI system caused or contributed to negative outcomes (e.g., bias, misinformation, security breach).  
   - **Link to Original Source**: Provide a URL to the article or an official report. If the page is behind a paywall or no longer available, include a screenshot or alternative reference.

3. **Analyze What Went Wrong**  
   - Explore **why** the AI system behaved the way it did. Was it a data issue? A design flaw? Lack of ethical oversight?  
   - Include any **technical or organizational factors** that contributed to the incident (e.g., training set bias, inadequate testing, weak security measures, profit-driven deadlines overriding caution).

4. **Propose Preventative Measures**  
   - Offer **practical strategies** to prevent a recurrence:  
     - Technical fixes (e.g., improved data curation, bias mitigation, security patches).  
     - Policy or process changes (e.g., internal audits, ethics review boards, user education).  
     - Monitoring and feedback mechanisms.  
   - State **who** should implement these measures (developers, management, policymakers, etc.).

5. **Prepare a 2-Minute Class Presentation**  
   - In next week’s class, you will give a **concise briefing** on your chosen incident:  
     - **What happened?**  
     - **How could it have been prevented?**  
   - Time limit is strict; practice brevity and clarity.

6. **Submission Format**  
   - **Written Report** (1–2 pages max) in a structured format:  
     1. **Headline and Link**  
     2. **Summary (Incident + Harm)**  
     3. **Analysis of Causes**  
     4. **Preventative Measures**  
     5. **Conclusion** (brief reflection)  
   - You may include visuals or bullet points for clarity.

---

## **Grading Rubric**

| **Criteria**                              | **Exemplary (A)**                                                                                                                                   | **Proficient (B)**                                                                                                                                            | **Developing (C)**                                                                                                                                     | **Needs Improvement (D/F)**                                                                                                                            | **Weight** |
|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|----------:|
| **1. Incident Relevance & Authenticity**  | Presents a *current and authentic* news story directly involving AI harm, with a *credible link or source*; date and context are clearly stated.      | News story is valid, somewhat recent, and link is provided; context is mostly clear.                                                                          | The incident is *loosely relevant* or outdated; source link may be missing or unclear.                                                                  | News story is *unrelated or unverifiable*; no references to legitimate sources.                                                                        | 20%       |
| **2. Summary & Clarity of Explanation**   | Clearly articulates the **who, what, where, and how** of the harm in *own words*, demonstrating deep understanding.                                    | Adequately explains main points of the harm; some minor gaps in detail.                                                                                       | Basic mention of what happened but lacks clarity or depth; might rely too much on direct quotes rather than own words.                                  | Incident is vaguely described or confusing; insufficient explanation of harm or context.                                                                | 20%       |
| **3. Cause Analysis**                     | Offers a *coherent, well-argued* explanation of root causes (technical, social, organizational), backed by relevant insights from AI concepts.         | Identifies plausible causes with some detail; partial integration of AI course concepts.                                                                      | Lists causes superficially; not well connected to AI course learnings.                                                                                  | Minimal or no analysis of underlying causes; lacks understanding of relevant AI or organizational factors.                                             | 20%       |
| **4. Preventative Measures & Solutions**  | Proposes *creative, concrete* methods to prevent or mitigate future harm, aligning solutions with course topics (ethics, security, generative AI, etc.). | Suggests *some viable* solutions, though not fully detailed or aligned with best practices.                                                                   | Solutions are too broad or generic; limited connection to course topics.                                                                                | Little to no actionable suggestions; fails to connect solutions to the identified issues.                                                               | 25%       |
| **5. Presentation (2-Minute Brief)**      | Delivers a concise, *engaging*, and clear summary; effectively highlights key points and lessons learned.                                             | Stays within time limit; explains incident and prevention points fairly well.                                                                                 | Slightly unfocused or rushed; important details missing or unclear.                                                                                    | Over time limit, disorganized, or too vague to convey understanding.                                                                                   | 15%       |

---

## **Sample Example** *(**Do Not** Use This for Your Assignment)*

### **Headline & Source**  
**Headline**: “Amazon Scraps Secret AI Recruiting Tool That Showed Bias Against Women”  
**Link**: [Reuters Article by Jeffrey Dastin (October 10, 2018)](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G) (As per the excerpt provided)

### **Summary of Incident**  
- **What Happened?**  
  Amazon developed an AI-based recruiting tool intended to automate resume screening. Unfortunately, the system started **downgrading resumes** containing terms associated with women’s colleges or women’s organizations.  
- **Harm**:  
  This tool effectively **reinforced gender biases**, penalizing qualified female candidates. It also highlighted the **risk of automating discriminatory practices** when AI models are trained on biased historical data.

### **Analysis of Causes**  
1. **Biased Training Data**: Amazon’s historical hiring patterns favored men in technical roles, so the AI learned those skewed preferences.  
2. **Lack of Oversight**: The system was initially used **without thorough bias testing**.  
3. **Model Design**: Developers **failed to incorporate** fairness constraints or regular audits to detect discriminatory patterns.

### **Preventative Measures**  
- **Data Auditing**: Before training an AI model, thoroughly vet historical data for protected-class biases, ensuring representativeness.  
- **Diversity Goals**: Employ fairness-aware machine learning techniques (e.g., removing gender-indicative keywords).  
- **Ongoing Monitoring**: Continuously test AI output for demographic biases; establish **ethical AI review boards**.  
- **Transparent Feedback Loop**: Gather user feedback (in this case, from HR and candidates) to promptly catch anomalies.

### **Conclusion**  
Amazon’s case underlines how **AI systems can inadvertently replicate societal prejudices** if not carefully designed and monitored. The takeaway is the need for **robust, bias-aware data practices** and **ethical governance** of AI systems.

---

### **What Students Must Do Differently**  
- **You are NOT allowed to use this Amazon example.** Choose a different incident!  
- Find your own case study, provide context, analyze it, and propose actionable recommendations. Then, be ready to present it in next week’s class in **2 minutes**.

---

## **Submission Deadlines**  
- **Written Report Due**: (Specify Date/Time)  
- **In-Class Presentation**: (Specify Date/Time)

Use this assignment to delve deeper into **real-world AI harms** and develop critical thinking around **ethical, secure, and safe AI** practices. Good luck!
