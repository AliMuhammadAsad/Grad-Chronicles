{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z5AEScnYyAwm"
      },
      "outputs": [],
      "source": [
        "#################################################################\n",
        "#                                                               #\n",
        "#  CS435 Generative AI: Security, Ethics and Governance         #\n",
        "#                                                               #\n",
        "#  Instructor: Dr. Adnan Masood                                 #\n",
        "#  Contact:    adnanmasood@gmail.com                            #\n",
        "#                                                               #\n",
        "#  Notebook is MIT Licensed                                     #\n",
        "#################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Em34wJryAwn"
      },
      "source": [
        "# Convolutional Neural Networks (CNNs)\n",
        "\n",
        "In this notebook, we’ll briefly explore Convolutional Neural Networks (CNNs), with progressive levels of explanation, math, code examples in PyTorch, and a hands-on exercise with TODOs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGWa982nyAwo"
      },
      "source": [
        "## Table of Contents\n",
        "1. **Building an Intuitive Understanding**\n",
        "2. **Intuition Behind CNNs**\n",
        "3. **Brief History and Underlying Technology**\n",
        "4. **Mathematical Explanation**\n",
        "5. **Illustrative Example with Code**\n",
        "6. **Step-by-Step Example from Scratch**\n",
        "7. **Illustrative Problem: What Does a CNN Solve?**\n",
        "8. **Real-World Problem**\n",
        "9. **Questions to Ponder & Answers**\n",
        "10. **A Sample Exercise using PyTorch**\n",
        "11. **Glossary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jWY8IlQyAwo"
      },
      "source": [
        "## 1. Building an Intuitive Understanding\n",
        "\n",
        "Imagine you have a big picture. A CNN helps a computer \"look\" at small parts of the picture, find important details, and figure out what the picture is about (like identifying if it's a cat or dog).\n",
        "\n",
        "Think of CNNs like a detective with a magnifying glass. The detective moves the glass over different parts of an image to see if there’s anything interesting (like edges, corners, eyes, etc.). By combining information about these smaller parts, the CNN can understand the bigger picture.\n",
        "\n",
        "A CNN is a specialized type of neural network for analyzing data that has a grid-like structure (e.g., images). It involves applying small filters (kernels) over the image to produce feature maps. By stacking multiple layers, the network learns complex features (from edges to shapes to objects).\n",
        "\n",
        "CNNs exploit local connectivity (filters only look at local patches) and weight sharing (the same filter is used across different regions). This reduces parameters and allows the model to be more efficient and translation-invariant. Pooling layers (max or average) further reduce spatial dimensions.\n",
        "\n",
        "Current CNN research extends to advanced architectures (ResNet, DenseNet, Inception) and optimization techniques (BatchNorm, skip connections). Researchers also investigate interpretability (Grad-CAM, saliency maps) to understand how CNNs focus on relevant image regions. Beyond images, CNNs are adapted for 1D signals, 3D volumes, and even graph structures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n09633lfyAwo"
      },
      "source": [
        "## 2. Intuition Behind CNNs\n",
        "Our eyes process the world in local patches. We first recognize edges and simple patterns, then build up to more complex features. CNNs do the same: sliding small filters across images to detect features step by step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddUXxCu0yAwp"
      },
      "source": [
        "## 3. Brief History and Underlying Technology\n",
        "- **1980 – Fukushima’s Neocognitron**: Early concept of hierarchical feature detection.\n",
        "- **1989 – LeNet (Yann LeCun)**: First popular CNN for handwritten digit recognition.\n",
        "- **2012 – AlexNet**: Achieved breakthrough in ImageNet classification.\n",
        "- **2014 onwards**: Deeper architectures (VGG, GoogleNet, ResNet) improved performance.\n",
        "\n",
        "Key technologies include:\n",
        "- **Convolution Filters**: Shared weights to detect local patterns.\n",
        "- **Backpropagation**: Automated method to learn filter weights.\n",
        "- **High-Performance Hardware (GPUs)**: Speed up matrix operations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_xxxsXryAwp"
      },
      "source": [
        "## 4. Mathematical Explanation\n",
        "### 4.1\n",
        "1. We take a small window (filter) and slide it over the image.\n",
        "2. At each position, we multiply the filter values by the overlapping image pixels and add them up.\n",
        "3. This sum becomes the new “feature” in the output.\n",
        "\n",
        "### 4.2 Deeper Dive\n",
        "In 2D:\n",
        "$$\n",
        "(I * K)(x, y) = \\sum_{m} \\sum_{n} I(m, n) \\cdot K(x - m, y - n)\n",
        "$$\n",
        "where $I$ is the image, $K$ is the kernel (filter), and $(x,y)$ is the position in the output feature map.\n",
        "\n",
        "- **Weight**: The values in the filter.\n",
        "- **Bias**: A constant added after the convolution sum.\n",
        "- **Activation Function (e.g., ReLU)**: $\\text{ReLU}(z) = \\max(0, z)$, introducing non-linearity.\n",
        "- **Pooling**: Reduces the spatial dimension, like picking the maximum value in a small region (max pooling)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLIzymcyyAwp"
      },
      "source": [
        "## 5. Illustrative Example with Code\n",
        "Below, we’ll manually perform a 2D convolution on a small 5x5 image with a 3x3 kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU2OJWguyAwp",
        "outputId": "0d633255-0dac-4e3d-fbad-85c180155961"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-6.,  4.,  4.],\n",
              "        [-6.,  4.,  4.],\n",
              "        [-6.,  4.,  4.]])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# 5x5 image\n",
        "image = torch.tensor([\n",
        "    [1., 2., 3., 4., 5.],\n",
        "    [4., 5., 6., 7., 8.],\n",
        "    [7., 8., 9., 0., 1.],\n",
        "    [2., 3., 4., 5., 6.],\n",
        "    [5., 6., 7., 8., 9.]\n",
        "])\n",
        "\n",
        "# 3x3 kernel\n",
        "kernel = torch.tensor([\n",
        "    [ 1.,  0., -1.],\n",
        "    [ 1.,  0., -1.],\n",
        "    [ 1.,  0., -1.]\n",
        "])\n",
        "\n",
        "def manual_convolution2d(image, kernel):\n",
        "    kernel_size = kernel.shape[0]\n",
        "    output_size = image.shape[0] - kernel_size + 1\n",
        "    output = torch.zeros((output_size, output_size))\n",
        "    for i in range(output_size):\n",
        "        for j in range(output_size):\n",
        "            region = image[i:i+kernel_size, j:j+kernel_size]\n",
        "            output[i, j] = torch.sum(region * kernel)\n",
        "    return output\n",
        "\n",
        "conv_result = manual_convolution2d(image, kernel)\n",
        "conv_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs0Giy5ZyAwq"
      },
      "source": [
        "Observe the resulting tensor in `conv_result`. Each entry corresponds to the filter’s response in that location."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwKH7dg6yAwq"
      },
      "source": [
        "## 6. Step-by-Step Example from Scratch\n",
        "1. **Choose an input image** (or a batch of images).\n",
        "2. **Define a filter (kernel)** with some weights.\n",
        "3. **Convolution**: Multiply and sum over local image patches.\n",
        "4. **Add bias**.\n",
        "5. **Apply an activation function** (e.g. ReLU).\n",
        "6. **Pooling layer** (optional) to reduce spatial dimensions.\n",
        "7. **Repeat** with more convolution layers.\n",
        "8. **Flatten** and feed into a fully connected layer if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyY-hbEhyAwq"
      },
      "source": [
        "## 7. Illustrative Problem: What Does a CNN Solve?\n",
        "CNNs are great at tasks like:\n",
        "- **Image Classification**: e.g., recognizing if an image is a cat or a dog.\n",
        "- **Object Detection**: e.g., locating objects in an image.\n",
        "- **Segmentation**: e.g., highlighting which parts of the image are cat vs. background.\n",
        "It’s basically giving computers “eyes” to see and interpret images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyWcQ_JjyAwq"
      },
      "source": [
        "## 8. Real-World Problem\n",
        "### Example: Medical Imaging\n",
        "CNNs help in detecting tumors in MRI scans or identifying lesions in chest X-rays. By learning features indicative of certain diseases, a CNN can assist healthcare professionals in diagnosis.\n",
        "### Other Applications\n",
        "- Self-driving cars (vision-based lane detection)\n",
        "- Face recognition systems\n",
        "- Retail product scanning\n",
        "- Robotics (visual servoing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgYX3ekSyAwq"
      },
      "source": [
        "## 9. Questions to Ponder & Their Answers\n",
        "1. **Q**: Why do CNNs share weights?\n",
        "   **A**: This reduces the number of parameters and helps detect the same feature across different parts of the image.\n",
        "2. **Q**: Why use ReLU?\n",
        "   **A**: ReLU introduces non-linearity, allowing the model to learn more complex patterns.\n",
        "3. **Q**: How do we handle color images?\n",
        "   **A**: Color images have 3 channels (RGB). The filter extends across all channels, so a 3x3 filter becomes 3x3x3.\n",
        "4. **Q**: What is Padding?\n",
        "   **A**: Adding extra rows/columns (often zeros) around the image to maintain the output size or control it.\n",
        "5. **Q**: How is CNN training performed?\n",
        "   **A**: Through backpropagation, computing partial derivatives of the loss w.r.t. each weight in the filters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6P8enMWyAwq"
      },
      "source": [
        "## 10. A Sample Exercise using PyTorch\n",
        "We’ll train a small CNN on the MNIST dataset (handwritten digits). Some parts are left as TODO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2j8YCtHyAwq",
        "outputId": "f7bc51b0-30c4-4c94-e965-dfe097492b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Loss: 0.0934\n",
            "Test Accuracy: 97.28%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 1. Load Data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) # mean and std for MNIST\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 2. Define a Simple CNN Model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # TODO 1: Add a Conv2d layer: in_channels=1, out_channels=8, kernel_size=3\n",
        "        # HINT: self.conv1 = nn.Conv2d(1, 8, 3)\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
        "\n",
        "        # TODO 2: Add another Conv2d layer: in_channels=8, out_channels=16, kernel_size=3\n",
        "        # HINT: self.conv2 = nn.Conv2d(8, 16, 3)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
        "\n",
        "        # TODO 3: Add a fully connected layer: input features=? output=10 (for 10 digits)\n",
        "        # HINT: self.fc = nn.Linear(16*some_size, 10)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc = nn.Linear(16*5*5, 10)\n",
        "\n",
        "        # # TODO: Example solution: (what is wrong with this?)\n",
        "        # self.conv1 = nn.Conv2d(1, 8, 3)\n",
        "        # self.conv2 = nn.Conv2d(8, 16, 3)\n",
        "        # self.fc = nn.Linear(16*5*5, 10)  # after two conv with kernel=3 each time, MNIST 28->26->24, then pool or not.\n",
        "\n",
        "        # TODO - Do you think this would help solve?\n",
        "        # Can you Calculate the correct input size for the fully connected layer\n",
        "        # Output of conv2 is (28 - 3 + 1 - 3 + 1) = 24 (without padding)\n",
        "        # So, the flattened size is 24 * 24 * 16 = ?\n",
        "        #self.fc = nn.Linear(?, 10) # changed to 24*24*16 which is 9216\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 3. Apply conv1, ReLU, optional pooling\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # 4. Apply conv2, ReLU\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # 5. Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # 6. Fully connected layer\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# 4. Instantiate Model, Define Loss and Optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 5. Train the Model (1 epoch for demo)\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/1], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# 6. Evaluate the Model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgDqUKjPyAwq"
      },
      "source": [
        "## 11. Glossary\n",
        "- **Kernel/Filter**: Small matrix of learnable weights used in convolution.\n",
        "- **Stride**: The step size by which we slide the filter across the image.\n",
        "- **Padding**: Adding extra rows/columns (often zeros) around the image to control output size.\n",
        "- **Feature Map**: The output matrix after the convolution of a filter with the image.\n",
        "- **Pooling**: Operation to reduce spatial dimensions (e.g., max pooling).\n",
        "- **Fully Connected Layer**: A layer where each neuron connects to all outputs of the previous layer.\n",
        "- **Activation Function**: A function (like ReLU) that introduces non-linearity.\n",
        "- **Backpropagation**: The method to compute gradients and update weights.\n",
        "- **Epoch**: One complete pass through the training dataset.\n",
        "- **Batch Size**: Number of samples processed before the model updates its parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FkYn0e_yAwq",
        "outputId": "c89c1953-0b7a-4179-d0d9-d6134802cdb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+++ Acknowledgement +++\n",
            "Executed on: 2025-01-28 18:09:57.470399\n",
            "In Google Colab: No\n",
            "System info: Linux 6.8.0-51-generic\n",
            "Node name: alimuhammad-Inspiron-7559\n",
            "MAC address: 20:47:47:74:94:05\n",
            "IP address: 127.0.1.1\n",
            "Signing off, Ali Muhammad Asad\n"
          ]
        }
      ],
      "source": [
        "import os, sys, platform, datetime, uuid, socket\n",
        "\n",
        "def signoff(name=\"Anonymous\"):\n",
        "    colab_check = \"Yes\" if 'google.colab' in sys.modules else \"No\"\n",
        "    mac_addr = ':'.join(format((uuid.getnode() >> i) & 0xff, '02x') for i in reversed(range(0, 48, 8)))\n",
        "    print(\"+++ Acknowledgement +++\")\n",
        "    print(f\"Executed on: {datetime.datetime.now()}\")\n",
        "    print(f\"In Google Colab: {colab_check}\")\n",
        "    print(f\"System info: {platform.system()} {platform.release()}\")\n",
        "    print(f\"Node name: {platform.node()}\")\n",
        "    print(f\"MAC address: {mac_addr}\")\n",
        "    try:\n",
        "        print(f\"IP address: {socket.gethostbyname(socket.gethostname())}\")\n",
        "    except:\n",
        "        print(\"IP address: Unknown\")\n",
        "    print(f\"Signing off, {name}\")\n",
        "\n",
        "signoff(\"Ali Muhammad Asad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
