{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737811181027,
     "user": {
      "displayName": "Adnan Masood",
      "userId": "04515194584513400333"
     },
     "user_tz": 300
    },
    "id": "1RohAVv8ngD0"
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#  CS435 Generative AI: Security, Ethics and Governance         #\n",
    "#                                                               #\n",
    "#  Instructor: Dr. Adnan Masood                                 #\n",
    "#  Contact:    adnanmasood@gmail.com                            #\n",
    "#                                                               #\n",
    "#  Notebook is MIT Licensed                                     #\n",
    "#################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hi0zJ_7KngD1"
   },
   "source": [
    "# **LLM Instruction Tuning vs. Fine-Tuning**\n",
    "\n",
    "Welcome to our in-depth Jupyter Notebook on the difference between **Instruction Tuning** and **Fine-Tuning** in Large Language Models (LLMs). We will explore these concepts at multiple levels of detail, from a very simple explanation for beginners to a more advanced, PhD-level discussion.\n",
    "\n",
    "We'll use **PyTorch** for our examples and code demonstrations.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Building an Intuitive Understanding](#build-intui)\n",
    "2. [Intuition Behind the Technology](#intuition)\n",
    "3. [Brief History, Invention, and Underlying Tech](#history)\n",
    "4. [Math Behind It (and Beyond)](#math)\n",
    "5. [Illustrative Example with Code](#example-code)\n",
    "6. [Example Calculations](#mock-calc)\n",
    "7. [Step-by-Step Example from Scratch](#from-scratch)\n",
    "8. [Illustrative Problem It Solves](#illustrative-problem)\n",
    "9. [Real-World Problem & How to Solve Using This Tech](#real-world)\n",
    "10. [Points to Ponder (Questions)](#points-to-ponder)\n",
    "11. [Answers to the Questions with Code Examples](#answers)\n",
    "12. [A Sample Exercise](#todo-code)\n",
    "13. [Glossary](#glossary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh-ZhZ9fngD2"
   },
   "source": [
    "<a id=\"build-intui\"></a>\n",
    "## **Building an Intuitive Understanding**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTFq2qhmngD2"
   },
   "source": [
    "**Goal**: Explain the concept of instruction tuning vs. fine-tuning in the simplest possible way (like for a middle schooler).\n",
    "\n",
    "- **Fine-Tuning**: Think of it like teaching a dog new tricks by showing it examples over and over so it learns exactly how to do them.\n",
    "- **Instruction Tuning**: This is like giving the dog simple instructions (\"Sit!\" \"Roll Over!\") and the dog learns to follow many different instructions without being shown examples for each trick hundreds of times. You just guide it on how to follow instructions.\n",
    "\n",
    "That’s the basic idea: **Fine-tuning** = training with many examples of a specific task. **Instruction tuning** = teaching the model to understand and follow instructions in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ds30_2QengD2"
   },
   "source": [
    "**Goal**: Provide a more detailed explanation (like for high school students).\n",
    "\n",
    "- **Fine-Tuning**: You have a big language model that already understands English text. You give it a bunch of examples for a particular task (like summarizing paragraphs or classifying emails) and let the model adjust its internal parameters (weights) so it gets better and better at that specific task.\n",
    "- **Instruction Tuning**: Instead of focusing on just one task, you teach the model to follow instructions in a general sense. You show it examples of many different instructions and how they should be answered. This way, it becomes more flexible; it can handle all sorts of different tasks simply by reading your instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Vy-qAeDngD2"
   },
   "source": [
    "**Goal**: Dive deeper into the difference and talk about training strategies.\n",
    "\n",
    "- **Fine-Tuning**:\n",
    "  - You have a pre-trained LLM, such as GPT-like architecture.\n",
    "  - You collect a large dataset **specific** to the task you care about.\n",
    "  - You continue training (\"fine-tuning\") on this dataset.\n",
    "  - This modifies the model’s weights to make it better for that single or narrow set of tasks.\n",
    "  - End result: The model is specialized for your particular problem.\n",
    "\n",
    "- **Instruction Tuning**:\n",
    "  - You gather many examples of *instructions and correct answers* (spanning multiple tasks).\n",
    "  - The model sees how instructions are structured and how to respond.\n",
    "  - The focus is on teaching the model a general strategy to interpret any new instruction.\n",
    "  - End result: The model is more robust and can handle a variety of tasks when prompted.\n",
    "\n",
    "**Why does it matter?**\n",
    "- Fine-tuning can lead to high performance on a single task but might not generalize well to tasks it hasn't seen.\n",
    "- Instruction tuning aims for more generalizable capabilities, letting the model follow your command on unseen tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5w-UXmmngD2"
   },
   "source": [
    "**Goal**: Discuss more technical details, referencing architecture, data, and optimization.\n",
    "\n",
    "During **fine-tuning**, you typically:\n",
    "1. Take a pre-trained transformer (e.g., GPT-2, GPT-Neo, or other LLMs) that’s been trained on a massive corpus of text.\n",
    "2. Use a labeled dataset, possibly with input-output pairs for a specific task (e.g., sentiment analysis, question answering, etc.).\n",
    "3. Update the entire network’s weights or sometimes just a subset (like a LoRA approach with low-rank adapters) to overfit to the domain/task of interest.\n",
    "\n",
    "For **instruction tuning**:\n",
    "1. You collect or create a dataset of *(instruction, response)* pairs from multiple tasks.\n",
    "2. You might use techniques like **Reinforcement Learning from Human Feedback (RLHF)** to refine the model’s responses to align with what humans expect.\n",
    "3. The objective is to minimize a loss function that measures how well the model’s response matches the \"ideal\" response or the high-quality labeled answer.\n",
    "4. The model emerges as a versatile system that can handle tasks it hasn't explicitly been fine-tuned on, as long as instructions are well-formed.\n",
    "\n",
    "In short:\n",
    "- **Fine-Tuning** = narrower scope, modifies knowledge for a single domain or task.\n",
    "- **Instruction Tuning** = broader, allows the model to interpret and handle diverse tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGytVkwangD2"
   },
   "source": [
    "**Goal**: Provide deep insights into the conceptual and research-based difference.\n",
    "\n",
    "From a research standpoint, **fine-tuning** is often about adapting a large pre-trained model’s weights to a low-data or domain-specific scenario. It was historically used in computer vision (e.g., fine-tuning ResNet on a custom image classification problem) and is widely adopted in NLP.\n",
    "\n",
    "**Instruction tuning** has emerged in the wake of self-supervised language models that are so large and powerful, they can handle extensive tasks if guided properly. Projects like *FLAN, T5, GPT*, and others have demonstrated that providing a mixture of tasks during training with explicit instructions yields a single model capable of zero-shot or few-shot performance on new tasks.\n",
    "\n",
    "Key papers and references:\n",
    "- **Fine-Tuning**: [Howard & Ruder, \"Universal Language Model Fine-tuning for Text Classification (ULMFiT)\"](https://arxiv.org/abs/1801.06146), etc.\n",
    "- **Instruction Tuning**: [Wei et al. \"Finetuned Language Models Are Zero-Shot Learners\" (a.k.a. FLAN)](https://arxiv.org/abs/2109.01652), [Ouyang et al. \"Training language models to follow instructions with human feedback\"](https://arxiv.org/abs/2203.02155) (RLHF for InstructGPT), etc.\n",
    "\n",
    "### Conclusion at the research level\n",
    "- Fine-tuning has a narrower but deeper effect on a model’s parameters.\n",
    "- Instruction tuning is more about multi-task, universal coverage and generalizing from instructions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G29JQjOungD3"
   },
   "source": [
    "<a id=\"intuition\"></a>\n",
    "## **Intuition Behind the Technology**\n",
    "\n",
    "Large Language Models (LLMs) learn patterns from huge amounts of text. Think of them as giant \"prediction machines\" that guess the next word in a sentence. However, once trained to do that, we can show them examples (fine-tuning) or instructions (instruction tuning) that guide them toward a certain type of behavior.\n",
    "\n",
    "If you simply want to adapt the model to do one task **really well**, you fine-tune it on that task. But if you want the model to understand your instructions (\"Translate this text\" or \"Summarize this article\"), you perform instruction tuning with many tasks so it learns the general skill of following instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKxhd7FXngD3"
   },
   "source": [
    "<a id=\"history\"></a>\n",
    "## **Brief History, Invention, and Underlying Tech**\n",
    "\n",
    "1. **Origins**: Transformer models were first introduced in [\"Attention is All You Need\" (Vaswani et al.)](https://arxiv.org/abs/1706.03762).\n",
    "2. **Pre-training + Fine-tuning**: BERT (Devlin et al.) showed that massive unsupervised pre-training can be adapted (fine-tuned) for new tasks.\n",
    "3. **Instruction Tuning**: With GPT-like models, researchers found that instructing the model with different tasks yields a single model capable of many tasks.\n",
    "4. **Reinforcement Learning from Human Feedback (RLHF)**: Takes instruction tuning further by letting humans rank or score outputs, refining the model’s responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYW28Q3XngD3"
   },
   "source": [
    "<a id=\"math\"></a>\n",
    "## **Math Behind It (and Beyond)**\n",
    "\n",
    "### Basic Neural Network Setup\n",
    "A language model is basically a neural network with parameters (weights) $W$ and biases $b$. We pass an input sequence $x$, and the model predicts an output $y$. If we represent the neural network’s function as $f_{W}(x)$, then the training process tries to find $W$ that minimizes a *loss function* $L(y, f_{W}(x))$.\n",
    "\n",
    "### Fine-Tuning\n",
    "- We start with a pre-trained model’s parameters $W_{\\text{pretrained}}$.\n",
    "- We keep training on a task-specific dataset $D = \\{(x_i, y_i)\\}$ for that specialized task.\n",
    "- We update $W$ using gradient descent:\n",
    "$$\n",
    "W \\leftarrow W - \\eta \\frac{\\partial}{\\partial W}\\bigg(\\sum_{(x_i, y_i) \\in D} L(y_i, f_W(x_i))\\bigg)\n",
    "$$\n",
    "- Result: $W_{\\text{fine-tuned}}$ is specialized.\n",
    "\n",
    "### Instruction Tuning\n",
    "- We have multiple tasks, each with instructions. The model is trained to map instructions to the correct output, effectively learning a function $g_{W}(\\text{instruction}) \\to \\text{output}$.\n",
    "- We again perform gradient descent, but now across multiple tasks/instructions:\n",
    "$$\n",
    "W \\leftarrow W - \\eta \\frac{\\partial}{\\partial W}\\bigg(\\sum_{j=1}^{k} \\sum_{(I_{j,i}, O_{j,i}) \\in T_j} L(O_{j,i}, f_W(I_{j,i}))\\bigg)\n",
    "$$\n",
    "- Result: $W_{\\text{instr-tuned}}$ can handle diverse tasks by simply reading an instruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRDbVFiingD3"
   },
   "source": [
    "<a id=\"example-code\"></a>\n",
    "## **Illustrative Example with Code**\n",
    "\n",
    "Below is a **toy** example to show how we might fine-tune or instruction-tune a small model in PyTorch on a very small, made-up dataset.\n",
    "\n",
    "### Example Scenario\n",
    "- We want the model to respond to instructions.\n",
    "- We have a mini-dataset of instructions and correct outputs.\n",
    "- We'll build a mini neural network (not a full transformer, for brevity!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18790,
     "status": "ok",
     "timestamp": 1737811203099,
     "user": {
      "displayName": "Adnan Masood",
      "userId": "04515194584513400333"
     },
     "user_tz": 300
    },
    "id": "YitKSzNHngD3",
    "outputId": "97fc681b-9f3f-4075-96f4-44e27b979671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/300, Loss: 0.3463\n",
      "Epoch 100/300, Loss: 0.2989\n",
      "Epoch 150/300, Loss: 0.2953\n",
      "Epoch 200/300, Loss: 0.2941\n",
      "Epoch 250/300, Loss: 0.2935\n",
      "Epoch 300/300, Loss: 0.2931\n",
      "Instruction: Add 1 and 2, Predicted Response: 3\n",
      "Instruction: Add 3 and 4, Predicted Response: 3\n",
      "Instruction: Reverse cat, Predicted Response: tod\n",
      "Instruction: Reverse dog, Predicted Response: tod\n",
      "Instruction: Add 10 and 20, Predicted Response: 3\n",
      "Instruction: Reverse hello, Predicted Response: tod\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Sample instructions and responses (tiny dataset)\n",
    "# Suppose we have instructions for adding two numbers, reversing a string, etc.\n",
    "instructions = [\n",
    "    \"Add 1 and 2\",\n",
    "    \"Add 3 and 4\",\n",
    "    \"Reverse cat\",\n",
    "    \"Reverse dog\",\n",
    "    \"Add 10 and 20\",\n",
    "    \"Reverse hello\"\n",
    "]\n",
    "\n",
    "responses = [\n",
    "    \"3\",  # result of 1+2\n",
    "    \"7\",  # result of 3+4\n",
    "    \"tac\",  # reverse of cat\n",
    "    \"god\",  # reverse of dog\n",
    "    \"30\",\n",
    "    \"olleh\"\n",
    "]\n",
    "\n",
    "# For simplicity, let's pretend each instruction/response is a vector.\n",
    "# We'll do a naive approach: convert each character to an integer encoding.\n",
    "\n",
    "char_to_idx = {ch: i+1 for i, ch in enumerate(\"abcdefghijklmnopqrstuvwxyz0123456789 \")}  # +1 so we can have 0 be 'pad'\n",
    "idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
    "\n",
    "def encode(text, max_len=10):\n",
    "    # very naive encoding, pad or truncate to max_len\n",
    "    vec = [char_to_idx.get(ch.lower(), 0) for ch in text]\n",
    "    vec = vec[:max_len]\n",
    "    vec += [0]*(max_len - len(vec))\n",
    "    return vec\n",
    "\n",
    "def decode(vec):\n",
    "    return ''.join(idx_to_char.get(x, '?') for x in vec if x != 0)\n",
    "\n",
    "max_len = 10\n",
    "X = torch.tensor([encode(instr, max_len) for instr in instructions])\n",
    "y = torch.tensor([encode(resp, max_len) for resp in responses])\n",
    "\n",
    "# We'll create a very small model to map from instruction -> response.\n",
    "# In a real scenario, you would have a large transformer. This is just a demonstration.\n",
    "\n",
    "class TinyModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=16, hidden_dim=32, max_len=10):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size+1, embed_dim)  # +1 for pad\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size+1)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len)\n",
    "        embedded = self.embed(x)   # (batch_size, seq_len, embed_dim)\n",
    "        out, hidden = self.rnn(embedded)\n",
    "        # we want to produce an output of shape (batch_size, seq_len, vocab_size+1)\n",
    "        logits = self.fc(out)\n",
    "        return logits  # raw logits\n",
    "\n",
    "# Initialize model\n",
    "vocab_size = len(char_to_idx)\n",
    "model = TinyModel(vocab_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    # outputs shape: (batch_size, seq_len, vocab_size+1)\n",
    "    # we need to reshape so we can apply cross entropy properly\n",
    "    outputs_reshaped = outputs.view(-1, vocab_size+1)\n",
    "    # target shape: (batch_size, seq_len)\n",
    "    targets_reshaped = y.view(-1)\n",
    "    loss = criterion(outputs_reshaped, targets_reshaped)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Let's see how the model does\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X)\n",
    "    predictions = torch.argmax(test_outputs, dim=2)\n",
    "\n",
    "    for i, instr in enumerate(instructions):\n",
    "        pred = decode(predictions[i].tolist())\n",
    "        print(f\"Instruction: {instr}, Predicted Response: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc7Abe4TngD3"
   },
   "source": [
    "### Discussion\n",
    "1. **Fine-tuning**: If this model was a pre-trained model on language tasks, we would be updating its weights on our new tasks of \"Add two numbers\" or \"Reverse a string.\" This is effectively *fine-tuning* for these tasks.\n",
    "2. **Instruction Tuning**: If we had many, many tasks with instruction-answer pairs, the model could learn to interpret instructions (\"Add X and Y,\" \"Reverse word\"), effectively bridging multiple tasks in a single model.\n",
    "\n",
    "Here, our example is extremely simplified (toy RNN, tiny dataset). Real instruction tuning uses huge models (millions/billions of parameters) and thousands to millions of instructions from many domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55CPGxSIngD3"
   },
   "source": [
    "<a id=\"mock-calc\"></a>\n",
    "## **Example Calculations**\n",
    "\n",
    "- **Weights ($W$)**: In a neural network layer, these are the numbers multiplied by the inputs. For an embedding layer of dimension $E$, you have a weight matrix of size $V \\times E$ where $V$ is vocabulary size.\n",
    "- **Bias ($b$)**: An extra parameter added to the weighted inputs, allowing the model to shift the activation function.\n",
    "- **Loss Function**: Measures how far off the model’s predictions are from the desired outputs. We used cross-entropy in the code.\n",
    "- **Gradient Descent**: We compute the gradient of the loss function wrt. parameters ($\\partial L / \\partial W$) and adjust the parameters in the opposite direction to reduce the loss.\n",
    "\n",
    "### Example of Weight Update\n",
    "- Suppose the weight is initially 1.0.\n",
    "- The gradient says the weight should be decreased by 0.1 to get a better prediction.\n",
    "- Then the new weight is 1.0 - 0.1 = 0.9.\n",
    "\n",
    "That’s the simplest mock calculation for how neural nets learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APnQem3sngD3"
   },
   "source": [
    "<a id=\"from-scratch\"></a>\n",
    "## **Step-by-Step Example of Creating This Technology from Scratch**\n",
    "\n",
    "We’ll outline a simplified process of building an instruction-tuned model:\n",
    "\n",
    "1. **Collect Data**: Gather a variety of tasks and their instructions. E.g., summarization, sentiment analysis, translation, etc., with actual sample instructions.\n",
    "2. **Pre-processing**: Tokenize the instructions and outputs (split into pieces that the model can handle).\n",
    "3. **Model Architecture**: Choose a large Transformer-based architecture.\n",
    "4. **Initialize Weights**: Typically from a pre-trained checkpoint like GPT-2 or GPT-Neo.\n",
    "5. **Loss Function**: Use cross-entropy that compares predicted token distributions to the gold standard.\n",
    "6. **Optimization**: Use an optimizer like AdamW or similar.\n",
    "7. **Training Loop**:\n",
    "   - For each batch, feed the instructions and desired outputs into the model.\n",
    "   - Compute the loss.\n",
    "   - Backpropagate.\n",
    "   - Update weights.\n",
    "8. **Evaluation**: Check if the model can follow unseen instructions properly.\n",
    "\n",
    "At a large scale, you would do this with millions of instructions and a huge compute cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYtves66ngD3"
   },
   "source": [
    "<a id=\"illustrative-problem\"></a>\n",
    "## **Illustrative Problem It Solves**\n",
    "\n",
    "It solves the problem of making a language model capable of answering different instructions. Instead of training separate models for each task—like one model for translation, one for Q&A, one for summarization—an instruction-tuned model can handle them all, if you simply provide the right instruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUDIU7z8ngD3"
   },
   "source": [
    "<a id=\"real-world\"></a>\n",
    "## **Real-World Problem & How to Solve Using This Tech**\n",
    "\n",
    "### Real-World Example: Customer Support Chatbot\n",
    "\n",
    "- Suppose you want a chatbot that can help customers with a variety of issues:\n",
    "  1. Provide shipping information.\n",
    "  2. Provide refund policies.\n",
    "  3. Troubleshoot connectivity issues.\n",
    "  4. Make suggestions about products.\n",
    "  5. Summarize user complaints.\n",
    "\n",
    "**Solution**: Use an instruction-tuned LLM. You can create instructions like \"Customer wants to track an order,\" \"Customer wants to know the refund policy,\" etc. The model, after instruction tuning, can handle these diverse requests just by reading the prompt.\n",
    "\n",
    "This saves huge amounts of time because you don’t need to build separate specialized models for each new type of query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELmrSP50ngD3"
   },
   "source": [
    "<a id=\"points-to-ponder\"></a>\n",
    "## **Points to Ponder (Questions)**\n",
    "\n",
    "1. What is the main difference between **fine-tuning** and **instruction tuning**?\n",
    "2. Why do we typically start with a **pre-trained** model?\n",
    "3. What does it mean to **align** a model with human preferences?\n",
    "4. How is **instruction tuning** related to **multi-task learning**?\n",
    "5. What are **weights** and **biases**, and why do they matter?\n",
    "6. How does **gradient descent** update the parameters?\n",
    "7. Why do we need a **loss function**?\n",
    "8. How does **tokenization** help in text tasks?\n",
    "9. Can **instruction-tuned** models handle tasks they have never seen before?\n",
    "10. Why do we say **\"Attention is All You Need\"** in transformers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yu1k2hqTngD4"
   },
   "source": [
    "<a id=\"answers\"></a>\n",
    "## **Answers to the Questions with Code Examples**\n",
    "\n",
    "1. **Difference between fine-tuning and instruction tuning**:\n",
    "   - Fine-tuning: Train model on one specific task with labeled data.\n",
    "   - Instruction tuning: Train model to respond to general instructions spanning many tasks.\n",
    "2. **Why start with a pre-trained model?**\n",
    "   - Because it already knows a lot about language structure; we only refine it for our purpose.\n",
    "3. **Align a model with human preferences**:\n",
    "   - Use human feedback (e.g., RLHF) to shape the model’s responses so they are more correct or more helpful.\n",
    "4. **Instruction tuning as multi-task learning**:\n",
    "   - We effectively train the model on multiple tasks at once, capturing a universal instruction-following ability.\n",
    "5. **Weights and biases**:\n",
    "   - Numerical parameters that determine how inputs get transformed into outputs.\n",
    "6. **Gradient descent updates parameters**:\n",
    "   - By computing how changing each parameter slightly changes the loss, then nudging parameters in the direction that reduces loss.\n",
    "7. **Why we need a loss function**:\n",
    "   - We need a quantitative measure of \"how bad\" the model’s predictions are, to know how to improve.\n",
    "8. **Tokenization**:\n",
    "   - Splits text into smaller units (tokens). The model processes each token. This helps the model handle variable-length text.\n",
    "9. **Can instruction-tuned models handle unseen tasks?**\n",
    "   - Often yes, if they are related or can be described with instructions. The model learned how to interpret instructions in general.\n",
    "10. **\"Attention is All You Need\"** in transformers:\n",
    "    - It's the name of the seminal paper that introduced the Transformer architecture, which uses attention mechanisms instead of older RNN-based methods to process sequences more efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojn1CXrsngD4"
   },
   "source": [
    "<a id=\"todo-code\"></a>\n",
    "## **A Sample Exercise**\n",
    "\n",
    "Below is a **starter code** to illustrate a mini version of a text classification fine-tuning task. Please complete the TODO items and run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1737811203570,
     "user": {
      "displayName": "Adnan Masood",
      "userId": "04515194584513400333"
     },
     "user_tz": 300
    },
    "id": "deLGm6BpngD4",
    "outputId": "b7acef9a-5cc6-4a63-f747-80557869beb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'hello': 1, 'there': 2, 'hi,': 3, 'how': 4, 'are': 5, 'you?': 6, 'goodbye': 7, 'bye': 8, 'see': 9, 'you': 10, 'later': 11, 'good': 12, 'evening': 13, 'farewell': 14, 'hey': 15}\n",
      "Epoch 10/50, Loss: 0.4503\n",
      "Epoch 20/50, Loss: 0.0283\n",
      "Epoch 30/50, Loss: 0.0017\n",
      "Epoch 40/50, Loss: 0.0006\n",
      "Epoch 50/50, Loss: 0.0003\n",
      "Accuracy: 100.00%\n",
      "Sentence: 'Hello friend' -> Predicted label: 0 (0=greeting, 1=farewell)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import necessary PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# We have some sample text classification data\n",
    "# Suppose we want to classify short texts as either 'greeting' or 'farewell'.\n",
    "\n",
    "texts = [\n",
    "    \"Hello there\",\n",
    "    \"Hi, how are you?\",\n",
    "    \"Goodbye\",\n",
    "    \"Bye bye\",\n",
    "    \"See you later\",\n",
    "    \"Good evening\",\n",
    "    \"Farewell\",\n",
    "    \"Hey\"\n",
    "]\n",
    "\n",
    "# Labels: greeting=0, farewell=1\n",
    "labels = [0, 0, 1, 1, 1, 0, 1, 0]\n",
    "\n",
    "# TODO: Create a vocabulary and a method to tokenize/encode these texts.\n",
    "vocab = {}\n",
    "index = 1  # start indexing at 1\n",
    "\n",
    "def build_vocab(text_list):\n",
    "    global vocab, index\n",
    "    for t in text_list:\n",
    "        for word in t.lower().split():\n",
    "            if word not in vocab:\n",
    "                vocab[word] = index\n",
    "                index += 1\n",
    "\n",
    "# Build the vocabulary\n",
    "build_vocab(texts)\n",
    "\n",
    "print(\"Vocabulary:\", vocab)\n",
    "\n",
    "def encode_sentence(sentence, max_len=5):\n",
    "    encoded = []\n",
    "    for word in sentence.lower().split():\n",
    "        encoded.append(vocab.get(word, 0))  # 0 if not found\n",
    "    encoded = encoded[:max_len]\n",
    "    # pad if needed\n",
    "    while len(encoded) < max_len:\n",
    "        encoded.append(0)\n",
    "    return encoded\n",
    "\n",
    "# Encode all sentences\n",
    "X_data = [encode_sentence(s) for s in texts]\n",
    "y_data = labels\n",
    "\n",
    "X_tensor = torch.tensor(X_data)\n",
    "y_tensor = torch.tensor(y_data)\n",
    "\n",
    "# Simple classification model\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=8, hidden_dim=16, num_classes=2):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size+1, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embed(x)\n",
    "        out, hidden = self.rnn(embedded)\n",
    "        # Use the last hidden state for classification\n",
    "        last_hidden = hidden[-1]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "# Instantiate model\n",
    "model = SimpleClassifier(vocab_size=len(vocab))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# TODO: Write a training loop to train this classifier\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits = model(X_tensor)\n",
    "    loss = criterion(logits, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_tensor)\n",
    "    predicted_labels = torch.argmax(preds, dim=1)\n",
    "    correct = (predicted_labels == y_tensor).sum().item()\n",
    "    print(f\"Accuracy: {correct / len(y_tensor)*100:.2f}%\")\n",
    "\n",
    "# TODO: Try your own sentences:\n",
    "new_text = \"Hello friend\"\n",
    "encoded_new = torch.tensor([encode_sentence(new_text)])\n",
    "output = model(encoded_new)\n",
    "pred_label = torch.argmax(output, dim=1).item()\n",
    "print(f\"Sentence: '{new_text}' -> Predicted label: {pred_label} (0=greeting, 1=farewell)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sA1StacKngD4"
   },
   "source": [
    "### Explanation:\n",
    "1. We build a small vocabulary from the data.\n",
    "2. We tokenize each sentence into integers.\n",
    "3. We feed this into a small GRU-based classification model.\n",
    "4. We train with CrossEntropyLoss for classification.\n",
    "5. After training, we check how well the model does, then we test with a new sentence.\n",
    "\n",
    "You can expand this example, add more tasks, and eventually build an instruction-based dataset to see how instruction tuning might work in principle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug_65gEbngD4"
   },
   "source": [
    "<a id=\"glossary\"></a>\n",
    "## **Glossary**\n",
    "\n",
    "**LLM (Large Language Model)**: A neural network model that’s been trained on massive text corpora to predict or generate text.\n",
    "\n",
    "**Transformer**: A neural architecture based on the attention mechanism, introduced in the seminal paper \"Attention is All You Need.\" Forms the backbone of most modern LLMs.\n",
    "\n",
    "**Fine-Tuning**: Taking a pre-trained model and further training it on a more specific task to specialize it.\n",
    "\n",
    "**Instruction Tuning**: Training a model to follow a variety of instructions by exposing it to instruction–response pairs across multiple tasks.\n",
    "\n",
    "**Weights and Biases**: Trainable parameters in a neural network that are adjusted via optimization.\n",
    "\n",
    "**Loss Function**: A function that measures how far the model’s predictions deviate from the desired targets. We aim to minimize this.\n",
    "\n",
    "**Gradient Descent**: An optimization algorithm used to minimize the loss function by iteratively moving in the negative direction of the gradient.\n",
    "\n",
    "**Cross Entropy Loss**: A common loss function for classification problems, measuring the distance between two probability distributions.\n",
    "\n",
    "**Epoch**: One full pass of the training data through the model.\n",
    "\n",
    "**Tokenization**: Splitting text into small, discrete units (tokens) for the model to process.\n",
    "\n",
    "**RNN/GRU**: Recurrent Neural Networks / Gated Recurrent Units – older but still relevant architecture for sequential data.\n",
    "\n",
    "**Transformer-based Models**: State-of-the-art models that rely on attention mechanisms, e.g., BERT, GPT, T5, etc.\n",
    "\n",
    "**RLHF (Reinforcement Learning from Human Feedback)**: A method of refining an LLM’s behavior by learning from how humans rate or prefer certain outputs.\n",
    "\n",
    "---\n",
    "End of notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1737811203570,
     "user": {
      "displayName": "Adnan Masood",
      "userId": "04515194584513400333"
     },
     "user_tz": 300
    },
    "id": "qXJIPZYCngD4",
    "outputId": "ec0b346a-e609-4c4f-a0cf-af11182a4c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Acknowledgement +++\n",
      "Executed on: 2025-01-29 01:32:21.780175\n",
      "In Google Colab: No\n",
      "System info: Linux 6.8.0-51-generic\n",
      "Node name: alimuhammad-Inspiron-7559\n",
      "MAC address: 20:47:47:74:94:05\n",
      "IP address: 127.0.1.1\n",
      "Signing off, Ali Muhammad Asad\n"
     ]
    }
   ],
   "source": [
    "import os, sys, platform, datetime, uuid, socket\n",
    "\n",
    "def signoff(name=\"Anonymous\"):\n",
    "    colab_check = \"Yes\" if 'google.colab' in sys.modules else \"No\"\n",
    "    mac_addr = ':'.join(format((uuid.getnode() >> i) & 0xff, '02x') for i in reversed(range(0, 48, 8)))\n",
    "    print(\"+++ Acknowledgement +++\")\n",
    "    print(f\"Executed on: {datetime.datetime.now()}\")\n",
    "    print(f\"In Google Colab: {colab_check}\")\n",
    "    print(f\"System info: {platform.system()} {platform.release()}\")\n",
    "    print(f\"Node name: {platform.node()}\")\n",
    "    print(f\"MAC address: {mac_addr}\")\n",
    "    try:\n",
    "        print(f\"IP address: {socket.gethostbyname(socket.gethostname())}\")\n",
    "    except:\n",
    "        print(\"IP address: Unknown\")\n",
    "    print(f\"Signing off, {name}\")\n",
    "\n",
    "signoff(\"Ali Muhammad Asad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
