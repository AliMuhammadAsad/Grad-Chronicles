{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71f384587e0b4553b07d885350a48dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4de613495504628bee804881b3d8c74",
              "IPY_MODEL_1ec69d6519a143d99d5972c56743a6a7",
              "IPY_MODEL_570ee34a791443cfba0870b23b61f7c9"
            ],
            "layout": "IPY_MODEL_2d059c89edb540c0a822642348478c47"
          }
        },
        "c4de613495504628bee804881b3d8c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63969a2f79ad49d99e291e0494c33daf",
            "placeholder": "​",
            "style": "IPY_MODEL_50c2cdcb6e8f4fc683115f4f28cb2a93",
            "value": "modules.json: 100%"
          }
        },
        "1ec69d6519a143d99d5972c56743a6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4631ec49221494b8f3c70e826bbe06f",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6b0f94b8e1342ae8a4a81b84b790bd3",
            "value": 349
          }
        },
        "570ee34a791443cfba0870b23b61f7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7596d07653a34bcba67a2deb5563c42c",
            "placeholder": "​",
            "style": "IPY_MODEL_ce8f28275db74aacbdefa85168e94a47",
            "value": " 349/349 [00:00&lt;00:00, 33.9kB/s]"
          }
        },
        "2d059c89edb540c0a822642348478c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63969a2f79ad49d99e291e0494c33daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c2cdcb6e8f4fc683115f4f28cb2a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4631ec49221494b8f3c70e826bbe06f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6b0f94b8e1342ae8a4a81b84b790bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7596d07653a34bcba67a2deb5563c42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8f28275db74aacbdefa85168e94a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1ea5a6c8cf44bf3aa972e42a6f89449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41da6c085aa042b48f23081e1bf543c9",
              "IPY_MODEL_492068c601f541019acc0ea2213202af",
              "IPY_MODEL_7a6aa7e1b33047819d7c398b0b3152de"
            ],
            "layout": "IPY_MODEL_f0bc60c16de64998a5952b3b964aab49"
          }
        },
        "41da6c085aa042b48f23081e1bf543c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36673e4d1726400c98e36f6182d00977",
            "placeholder": "​",
            "style": "IPY_MODEL_70ee57e7aba24b0f9695dafd2d775237",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "492068c601f541019acc0ea2213202af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847f8467da7944b4b69454ff3e573241",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb3e9db95d7c4a2da6ea15fca94b00ee",
            "value": 116
          }
        },
        "7a6aa7e1b33047819d7c398b0b3152de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0078407ed9c455dbd40bf63353a66ca",
            "placeholder": "​",
            "style": "IPY_MODEL_2a63d4a922804af0a3fecfc79187ff93",
            "value": " 116/116 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "f0bc60c16de64998a5952b3b964aab49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36673e4d1726400c98e36f6182d00977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70ee57e7aba24b0f9695dafd2d775237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "847f8467da7944b4b69454ff3e573241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb3e9db95d7c4a2da6ea15fca94b00ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0078407ed9c455dbd40bf63353a66ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a63d4a922804af0a3fecfc79187ff93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9423016dd66d4058ae6a98283b87e777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a2064f0a92d43c783af421bae64024d",
              "IPY_MODEL_4755aa8144ff4898b80a364211bfbeed",
              "IPY_MODEL_e9dec7c4e29041d8a36267bd53ea0ffc"
            ],
            "layout": "IPY_MODEL_b471f07e0e0f4856920f378bc1919333"
          }
        },
        "9a2064f0a92d43c783af421bae64024d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f086ceeec049c69eb8a2dde5fb2906",
            "placeholder": "​",
            "style": "IPY_MODEL_8dba3258797845d085e7cd80e2c0f89b",
            "value": "README.md: 100%"
          }
        },
        "4755aa8144ff4898b80a364211bfbeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5022eade0e7b4079afd0533d92dd785a",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_841e592303f744489b5c25617e171314",
            "value": 10454
          }
        },
        "e9dec7c4e29041d8a36267bd53ea0ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e490c1742c58427da4bf7300834c0ef3",
            "placeholder": "​",
            "style": "IPY_MODEL_3a9bb727b1d244be89a978b18f2cc02a",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.02MB/s]"
          }
        },
        "b471f07e0e0f4856920f378bc1919333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f086ceeec049c69eb8a2dde5fb2906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dba3258797845d085e7cd80e2c0f89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5022eade0e7b4079afd0533d92dd785a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "841e592303f744489b5c25617e171314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e490c1742c58427da4bf7300834c0ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9bb727b1d244be89a978b18f2cc02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9801e816e89f4c15983cbbcef1ce42e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_293c966312ee41739743ad863baabc44",
              "IPY_MODEL_8f9e79c0fc284b52a4324f2ae060058a",
              "IPY_MODEL_9633f4341e694cad869d8d57cd85b522"
            ],
            "layout": "IPY_MODEL_f6ca572f8f5e41e3a7a838f8de5f8a9c"
          }
        },
        "293c966312ee41739743ad863baabc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e55702a99ee4a538e7415e74eefe277",
            "placeholder": "​",
            "style": "IPY_MODEL_3c06e87dc8c24731bc487203e8a8ab66",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "8f9e79c0fc284b52a4324f2ae060058a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b822d32639d4ce284b951eba119c1e4",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddf2ef4809d4408ca1bf48586572ab74",
            "value": 53
          }
        },
        "9633f4341e694cad869d8d57cd85b522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72ca3aad3634036885bcf053535b5cb",
            "placeholder": "​",
            "style": "IPY_MODEL_779efa90c47c43a38a3c61b0266d04d8",
            "value": " 53.0/53.0 [00:00&lt;00:00, 6.02kB/s]"
          }
        },
        "f6ca572f8f5e41e3a7a838f8de5f8a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e55702a99ee4a538e7415e74eefe277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c06e87dc8c24731bc487203e8a8ab66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b822d32639d4ce284b951eba119c1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf2ef4809d4408ca1bf48586572ab74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d72ca3aad3634036885bcf053535b5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "779efa90c47c43a38a3c61b0266d04d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b510b5c7fe14913a12107cda36f18f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc9731119c9549409cdd5d61b6a38e42",
              "IPY_MODEL_1283416421a841c6bb88dec79a877890",
              "IPY_MODEL_db4717718c3e43b48f93f76b4f872fa5"
            ],
            "layout": "IPY_MODEL_6666c9a7956241c5b6b970ae0e03a6eb"
          }
        },
        "fc9731119c9549409cdd5d61b6a38e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65956c79ae8445629ae013930554c7f2",
            "placeholder": "​",
            "style": "IPY_MODEL_6b0675320ef74960b25564e9f4afedd1",
            "value": "config.json: 100%"
          }
        },
        "1283416421a841c6bb88dec79a877890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9c513c169a249e3b61da6a8c1060b99",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07a0f87ff9354b4c85cdfba289d03479",
            "value": 612
          }
        },
        "db4717718c3e43b48f93f76b4f872fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4b58f4bbcb641c883c4c53be7fa5729",
            "placeholder": "​",
            "style": "IPY_MODEL_9af903f921064e5484f32457db9aecac",
            "value": " 612/612 [00:00&lt;00:00, 50.4kB/s]"
          }
        },
        "6666c9a7956241c5b6b970ae0e03a6eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65956c79ae8445629ae013930554c7f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0675320ef74960b25564e9f4afedd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9c513c169a249e3b61da6a8c1060b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a0f87ff9354b4c85cdfba289d03479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4b58f4bbcb641c883c4c53be7fa5729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af903f921064e5484f32457db9aecac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb41898edcf94935bde32d172d6d978f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c0e9f6288634a32af8b2af43b9d1830",
              "IPY_MODEL_545d649ade3146feb16272c15ff42fa8",
              "IPY_MODEL_67b7e28e861c41d0b3741b27d9072548"
            ],
            "layout": "IPY_MODEL_3089fbdc77f84dd0ba2d4951e9e3b6ba"
          }
        },
        "6c0e9f6288634a32af8b2af43b9d1830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd51c4418295493b9f68f377db874986",
            "placeholder": "​",
            "style": "IPY_MODEL_6e1bd5d010014b58bdbbb513d91213c0",
            "value": "model.safetensors: 100%"
          }
        },
        "545d649ade3146feb16272c15ff42fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c814e9b7ec241079e48c68cd46a968d",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32c657d729fd4fbdae3a13391ef8a2b9",
            "value": 90868376
          }
        },
        "67b7e28e861c41d0b3741b27d9072548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7b44fb563a1451aba5dd941f804a67b",
            "placeholder": "​",
            "style": "IPY_MODEL_ef70282b85a346d18d563d7c916fdb61",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 231MB/s]"
          }
        },
        "3089fbdc77f84dd0ba2d4951e9e3b6ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd51c4418295493b9f68f377db874986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e1bd5d010014b58bdbbb513d91213c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c814e9b7ec241079e48c68cd46a968d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c657d729fd4fbdae3a13391ef8a2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7b44fb563a1451aba5dd941f804a67b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef70282b85a346d18d563d7c916fdb61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2dda32c91584cde849b41e83673155e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ace37b0370c428bb1a464c586e6e4fe",
              "IPY_MODEL_1588a12a17e449ba8f1179fc470c51e8",
              "IPY_MODEL_03755b8a4d0949e399803034ddd9aef9"
            ],
            "layout": "IPY_MODEL_1a862d1ea11a49068ebe86f44e136b33"
          }
        },
        "5ace37b0370c428bb1a464c586e6e4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a13efbf547470a87be1c9db9dd2272",
            "placeholder": "​",
            "style": "IPY_MODEL_8d36187ecf744498941b515f6ea8c85a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1588a12a17e449ba8f1179fc470c51e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46abe32f03094116a85839cae23b9c0f",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10476b81a0ea41beb3f54069c335b708",
            "value": 350
          }
        },
        "03755b8a4d0949e399803034ddd9aef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbad0d23c34c42f99e82dbc923ba7567",
            "placeholder": "​",
            "style": "IPY_MODEL_4797b886396d4630a9aaf8c5a025eaf2",
            "value": " 350/350 [00:00&lt;00:00, 28.5kB/s]"
          }
        },
        "1a862d1ea11a49068ebe86f44e136b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a13efbf547470a87be1c9db9dd2272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d36187ecf744498941b515f6ea8c85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46abe32f03094116a85839cae23b9c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10476b81a0ea41beb3f54069c335b708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbad0d23c34c42f99e82dbc923ba7567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4797b886396d4630a9aaf8c5a025eaf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50267adf874a4e17a5aeee7c82a14194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_438bd203129440fc93e7ea3dd36d67a8",
              "IPY_MODEL_175088eb061648a79036d70990b42b7e",
              "IPY_MODEL_ef93fb24c9d444d4a928d1167b8bffb0"
            ],
            "layout": "IPY_MODEL_02e1a3b5094b42dfb92bf72a20d48658"
          }
        },
        "438bd203129440fc93e7ea3dd36d67a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1206800d135f435e9fc8da9a5658df86",
            "placeholder": "​",
            "style": "IPY_MODEL_ffb359a1cf4c462e8f7f006dfd148197",
            "value": "vocab.txt: 100%"
          }
        },
        "175088eb061648a79036d70990b42b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb358d4ab1145f0a784011f8ac661c9",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_154d21a5e42c4332af6b9fa093da2e0c",
            "value": 231508
          }
        },
        "ef93fb24c9d444d4a928d1167b8bffb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1220998d0b54205965ebb0feee394c6",
            "placeholder": "​",
            "style": "IPY_MODEL_5e4258f202ee4ebf85c9195c8634e91c",
            "value": " 232k/232k [00:00&lt;00:00, 15.0MB/s]"
          }
        },
        "02e1a3b5094b42dfb92bf72a20d48658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1206800d135f435e9fc8da9a5658df86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb359a1cf4c462e8f7f006dfd148197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb358d4ab1145f0a784011f8ac661c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154d21a5e42c4332af6b9fa093da2e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1220998d0b54205965ebb0feee394c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4258f202ee4ebf85c9195c8634e91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d327e8f53f4846b49814c9a268202f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a8af82a5b324ab89eb058d0583096c1",
              "IPY_MODEL_8e763cb3dfda467abcdfda291e325cb6",
              "IPY_MODEL_ba6fe5b7c30645f1884faf4282d55ba7"
            ],
            "layout": "IPY_MODEL_47b3bb81b8484277906c2b460ac5be0a"
          }
        },
        "7a8af82a5b324ab89eb058d0583096c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c098199528ee45979e849c6e5913254d",
            "placeholder": "​",
            "style": "IPY_MODEL_f9b89c52f676487bbbbc5c83552a1776",
            "value": "tokenizer.json: 100%"
          }
        },
        "8e763cb3dfda467abcdfda291e325cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbdfb39027be4988a6ea9ec090408bf9",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c50b2e2b4b794ff58857fd88d56ff05d",
            "value": 466247
          }
        },
        "ba6fe5b7c30645f1884faf4282d55ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29dd93abef24a20b1157b5abd5d8a48",
            "placeholder": "​",
            "style": "IPY_MODEL_7874344b77bf48bda06473cc7f788737",
            "value": " 466k/466k [00:00&lt;00:00, 2.16MB/s]"
          }
        },
        "47b3bb81b8484277906c2b460ac5be0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c098199528ee45979e849c6e5913254d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b89c52f676487bbbbc5c83552a1776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbdfb39027be4988a6ea9ec090408bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50b2e2b4b794ff58857fd88d56ff05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b29dd93abef24a20b1157b5abd5d8a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7874344b77bf48bda06473cc7f788737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d04f911c0d614436b26a0690dae20b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2b41f0ff1e144aab36469bd09531a8e",
              "IPY_MODEL_a050b5dfa21a430a82222e3949b909f9",
              "IPY_MODEL_90ff7a5db7fa4925b6fa560656ad8b0f"
            ],
            "layout": "IPY_MODEL_59d2470f514243b6b51a51a6c769acbb"
          }
        },
        "f2b41f0ff1e144aab36469bd09531a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3ee03896594418fa1d9fa1f2c33a2d2",
            "placeholder": "​",
            "style": "IPY_MODEL_de0485a3bd254764853f3adcb6c26674",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a050b5dfa21a430a82222e3949b909f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_800161aa93974147b4619728f44a3bd2",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc476a0b2a7147e99e8e51f09b077f20",
            "value": 112
          }
        },
        "90ff7a5db7fa4925b6fa560656ad8b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a57427b060e14babb10b2ab25d0961c3",
            "placeholder": "​",
            "style": "IPY_MODEL_f301d0ba13004c2dbedd5ba05cb61448",
            "value": " 112/112 [00:00&lt;00:00, 10.9kB/s]"
          }
        },
        "59d2470f514243b6b51a51a6c769acbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3ee03896594418fa1d9fa1f2c33a2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0485a3bd254764853f3adcb6c26674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "800161aa93974147b4619728f44a3bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc476a0b2a7147e99e8e51f09b077f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a57427b060e14babb10b2ab25d0961c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f301d0ba13004c2dbedd5ba05cb61448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e62f425c0ae74c99a52fc52fa51681f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58f2912b50ec4a749b3d3efed0a06ae2",
              "IPY_MODEL_4a960afdd85f4c1f810712ca447f51fa",
              "IPY_MODEL_86b48514e0f44eb4ace81af26d5acddf"
            ],
            "layout": "IPY_MODEL_e4e25537895a4ff3b919c09ffcfc46b7"
          }
        },
        "58f2912b50ec4a749b3d3efed0a06ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b708eede63f74354b5100a6efaf63b24",
            "placeholder": "​",
            "style": "IPY_MODEL_ec2e39a5b641410e97a7267967920e8e",
            "value": "config.json: 100%"
          }
        },
        "4a960afdd85f4c1f810712ca447f51fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07355938f4174d6f9289812ccbc4d3e9",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8a5943235bd4ee1b3d36d9b9644f6b9",
            "value": 190
          }
        },
        "86b48514e0f44eb4ace81af26d5acddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb53e6c6e908497dbd709def074e4a6e",
            "placeholder": "​",
            "style": "IPY_MODEL_44247bd81dee43f185898791f9f62915",
            "value": " 190/190 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "e4e25537895a4ff3b919c09ffcfc46b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b708eede63f74354b5100a6efaf63b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2e39a5b641410e97a7267967920e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07355938f4174d6f9289812ccbc4d3e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a5943235bd4ee1b3d36d9b9644f6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb53e6c6e908497dbd709def074e4a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44247bd81dee43f185898791f9f62915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "891f0c94c80c4bceb5928af747eab8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c0d55bd93974d4d89db34e2401050d6",
              "IPY_MODEL_27828d1b909148e68263aed5ebbd1f3c",
              "IPY_MODEL_f61294417a3b487281c36cb264ae7bb4"
            ],
            "layout": "IPY_MODEL_dad7ed65b2304eb9bed2e8301a2c2103"
          }
        },
        "7c0d55bd93974d4d89db34e2401050d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf5d5e0d6c2343f1bbcbff29acee3545",
            "placeholder": "​",
            "style": "IPY_MODEL_1789afc9665b420e86ce56f2dafa7072",
            "value": "Batches: 100%"
          }
        },
        "27828d1b909148e68263aed5ebbd1f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8119660ee8459bbd65f6268a8258aa",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bdd2bafdc1e46498df5eb177a0616e3",
            "value": 3
          }
        },
        "f61294417a3b487281c36cb264ae7bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_757cbbec88c8430fb6b88cfd1b8e4e63",
            "placeholder": "​",
            "style": "IPY_MODEL_49ed227c7e8149e8b01893fefdbc3893",
            "value": " 3/3 [00:01&lt;00:00,  2.39it/s]"
          }
        },
        "dad7ed65b2304eb9bed2e8301a2c2103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5d5e0d6c2343f1bbcbff29acee3545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1789afc9665b420e86ce56f2dafa7072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de8119660ee8459bbd65f6268a8258aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bdd2bafdc1e46498df5eb177a0616e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "757cbbec88c8430fb6b88cfd1b8e4e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ed227c7e8149e8b01893fefdbc3893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eql0asAS9Q-3",
        "outputId": "240cefb0-f623-4ab7-8107-27c7e305e00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.0.1)\n",
            "Requirement already satisfied: faiss-gpu-cu12 in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (24.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.4.5.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade  PyPDF2 pdfplumber sentence-transformers faiss-gpu-cu12 transformers torch nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "7v7NJ_D7-Epm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentence_transformers, transformers\n",
        "print(\"PyPDF2:\", PyPDF2.__version__)\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Sentence Transformers:\", sentence_transformers.__version__)\n",
        "print(\"FAISS:\", faiss.__version__)\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"Transformers:\", transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al6neiN-0qga",
        "outputId": "5a1e0c9d-28e5-4157-af57-743cc16a21c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyPDF2: 3.0.1\n",
            "NumPy: 1.26.4\n",
            "Sentence Transformers: 4.0.1\n",
            "FAISS: 1.10.0\n",
            "Torch: 2.6.0+cu124\n",
            "Transformers: 4.50.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdfs(pdf_files):\n",
        "    documents = []\n",
        "    for pdf_name in pdf_files:\n",
        "        pdf_file = open(pdf_name, 'rb')\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        num_pages = len(pdf_reader.pages)\n",
        "        for page_num in range(num_pages):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text = page.extract_text()\n",
        "            if text.strip():  documents.append({'text': text, 'metadata': {'pdf_name': pdf_name, 'page_number': page_num + 1}})\n",
        "        pdf_file.close()\n",
        "    return documents"
      ],
      "metadata": {
        "id": "2tyDV8jz-5hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_files = [\"pdfs/paper1.pdf\", \"pdfs/paper2.pdf\", \"pdfs/paper3.pdf\", \"pdfs/paper4.pdf\", \"pdfs/paper5.pdf\", \"pdfs/paper6.pdf\"]\n",
        "documents = extract_text_from_pdfs(pdf_files)\n",
        "print(f\"Extracted from {len(documents)} documents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "synHXpw-A6V2",
        "outputId": "53f9c644-fc20-4231-ef45-c13ceec0936a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted from 80 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltO7ZbGLBt0U",
        "outputId": "d1904802-c417-4e4e-cd15-44b7f2138925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'Overview of PAN 2024:\\nMulti-Author Writing Style Analysis,\\nMultilingual Text Detoxification,\\nOppositional Thinking Analysis, and\\nGenerative AI Authorship Verification\\nCondensed Lab Overview\\nAbinew Ali Ayele,1Nikolay Babakov,2Janek Bevendorff,3\\nXavier Bonet Casals,4Berta Chulvi,5Daryna Dementieva,6Ashaf Elnagar,7\\nDayne Freitag,8Maik Fröbe,9Damir Korenčić,10Maximilian Mayerl,11\\nDaniil Moskovskiy,12Animesh Mukherjee,13Alexander Panchenko,12\\nMartin Potthast,14Francisco Rangel,15Naquee Rizwan,13Paolo Rosso,5,16\\nFlorian Schneider,1Alisa Smirnova,17Efstathios Stamatatos,18\\nElisei Stakovskii, Benno Stein,19Mariona Taulé,4Dmitry Ustalov,20\\nXintong Wang,1Matti Wiegmann,19Seid Muhie Yimam,1and Eva Zangerle21\\n1Universität Hamburg, Germany,2Universidade de Santiago de Compostela, Spain\\n3Leipzig University, Germany,4Universitat de Barcelona, Spain,5Univ. Politècnica\\nde València, Spain,6Technical University of Munich, Germany,7University of\\nSharjah, United Arab Emirates,8SRI International, USA,9Friedrich Schiller\\nUniversity Jena, Germany,10Ruđer Bošković Institute, Croatia,11University of\\nApplied Sciences BFI Vienna, Austria,12Skoltech & AIRI, Russia,13Indian\\nInstitute of Technology Kharagpur, India,14University of Kassel, hessian.AI, and\\nScaDS.AI, Germany15Symanto Research, Spain,16ValgrAI - Valencian Graduate\\nSchool and Research Network of AI, Spain,17Toloka, Switzerland,18University of\\nthe Aegean, Greece,19Bauhaus-Universität Weimar, Germany,20JetBrains, Serbia,\\n21University of Innsbruck, Austria\\npan@webis.de pan.webis.de\\nAbstract The goal of the PAN lab is to advance the state of the art\\nin text forensics and stylometry through an objective evaluation of new\\nand established methods on new benchmark datasets. In 2024, we or-\\nganized four shared tasks: (1) multi-author writing style analysis, which\\nwe continue from 2023; (2) multilingual text detoxification, a new task\\nthat aims to re-formulate text in a non-toxic way for multiple languages;\\n(3) oppositional thinking analysis, a new task that aims to discriminate\\ncritical thinking from conspiracy narratives and identify their core ac-\\ntors; and (4) generative AI authorship verification, which formulates the\\ndetection of AI-generated text as an authorship problem. PAN 2024 con-\\ncluded as one of our most successful editions with 74 notebook papers\\nby 147 participating teams.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 1}},\n",
              " {'text': '2 Ayele et al.\\n1 Introduction\\nPAN is a workshop series and a networking initiative for stylometry and digi-\\ntal text forensics. PAN hosts computational shared tasks on authorship analy-\\nsis, computational ethics, and the originality of writing. Since the workshop’s\\ninception in 2007, we organized 73 shared tasks1and assembled 57 evalua-\\ntion datasets2plus nine datasets contributed by the community. In 2024, we\\norganized four tasks that concluded in 74 notebook papers by 147 participating\\nteams.\\nFirst, the Multi-Author Writing Style Analysis task asks to, given a docu-\\nment, determine at which positions the author changes. This task was revamped\\nfor 2023 with a new dataset and structured around topical heterogeneity as\\nan indicator of difficulty. We continued the task in 2024 with minor modifica-\\ntions since it attracts consistent participation of high technical quality and the\\nproblem is still relevant and offers room for improvements. A total of 15 teams\\nsubmitted notebook papers to Multi-Author Writing Style Analysis . The task\\ndetails are described in Section 2.\\nSecond, the new Multilingual Text Detoxification task asks to, given a toxic\\npiece of text, re-write it in a non-toxic way while saving the main content as\\nmuch as possible. The task was prepared for 9 languages—English, Spanish,\\nGerman, Chinese, Arabic, Hindi, Ukrainian, Russian, and Amharic—and had\\ncross-lingual and multilingual challenges. A total of 31 teams submitted their\\nsolutions to Multilingual Text Detoxification resulting in 12 notebook papers.\\nThe task details are described in Section 3.\\nThird, the new Oppositional Thinking Analysis task asks, given an online\\nmessage, to first distinguish between critical and conspiracy texts, and second,\\nto detect the elements of the oppositional narratives. A total of 83 teams sub-\\nmitted their solutions to Oppositional Thinking Analysis resulting in 18 note-\\nbook papers. The task details are described in Section 4.\\nFourth, the new Generative AI Authorship Verification task asks, given one\\ntext authored by a human and one by a machine, to pick out the human-written\\none. Detecting AI-generated text is a task of high urgency and, as an authorship\\ntask, it falls deeply within PAN’s expertise. We formulate AI-detection as a\\nverification task and collaborate with the ELOQUENT Lab to generate a total\\nof 70 different verification datasets to benchmark the PAN submissions. A total\\nof 34 teams submitted to Generative AI Authorship Verification , resulting in\\n29 notebook papers. The task details are described in Section 5.\\nPAN is committed to reproducible research in IR and NLP, hence all par-\\nticipants are asked to submit their software (instead of just their predictions)\\nthrough the submission software TIRA. With the recent updates to the TIRA\\nplatform [32], a majority of the submissions to PAN are publicly available as\\ndocker containers. In the following sections, we briefly outline the 2024 tasks\\nand their results.\\n1Find PAN’s past shared tasks at pan.webis.de/shared-tasks.html\\n2Find PAN’s datasets at pan.webis.de/data.html',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 2}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 3\\n2 Multi-Author Writing Style Analysis\\nThe analysis of writing styles is the foundation of authorship identification tasks.\\nThe multi-author writing style analysis task, as part of PAN@CLEF, continues\\nto develop challenges in this crucial field of research. Over the years, the task\\nhas evolved significantly: from identifying and grouping individual authors [108]\\nto detecting whether a document has been written by a single or multiple au-\\nthors [127, 55, 146] and identifying the actual number of authors [145], and\\nfinally, to paragraph-level style change detection [141, 142, 143].\\nIn the PAN’24 multi-author writing style analysis task, participants were\\nasked to identify all positions of writing style changes within a given text. Specif-\\nically, for each pair of consecutive paragraphs, the task was to compute whether\\nthere is a change in writing style between the two paragraphs. The dataset used\\nfor this task is split into three subsets of increasing difficulty: Easy: Each doc-\\nument contains a variety of topics, therefore, topic information can be used for\\ndetecting changes in writing style. Medium: The topics contained in a document\\nare more homogeneous, requiring the approaches to focus more on writing style\\nto solve the detection task. Hard:The paragraphs in a document are of a single\\ntopic. We control for topical diversity to ensure that, particularly in the hard\\ndataset, topical differences cannot be used as a proxy signal for authorship and\\nthat the focus remains on stylistic cues for detecting changes in writing style.\\nData Set and Evaluation\\nThe dataset used for the multi-author writing analysis task is based on user\\nposts on Reddit3. We selected posts from the following subreddits to ensure that\\navarietyoftopicsisusedforthecreationofthedatasets: r/worldnews ,r/politics ,\\nr/askhistorians , andr/legaladvice . After extracting posts from these subreddits,\\nwe applied cleaning steps, such as removing quotes, whitespace, emojis, or hy-\\nperlinks. The cleaned user posts were then split into paragraphs.\\nTo generate documents for the dataset, we used paragraphs from a single\\nReddit post to ensure minimal topical coherence between paragraphs of the\\ngenerated document. Each document was composed of paragraphs written by\\na randomly selected number of two to four authors. For each paragraph, we\\nextracted and computed semantic and stylistic feature vectors to characterize\\nthe paragraph. The paragraphs were then concatenated based on the similarity\\nof their feature vectors. This mixing approach allowed us to control for topical\\nand stylistic similarity, enabling the creation of more coherent documents and\\nallowing us to adjust the difficulty of the multi-author writing style task. For the\\nthree datasets, we configured the similarity threshold for consecutive paragraphs\\nto be (1) relatively large for the easydataset, (2) moderate for the medium\\ndataset, and (3) small for the harddataset. Each of the easy, medium, and hard\\ndatasets contains 6,000 documents. We provided participants with training, test,\\nand validation splits for all three datasets. The training sets contain 70% of the\\n3https://www.reddit.com/',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 3}},\n",
              " {'text': '4 Ayele et al.\\nTable 1: Overall results for the multi-author analysis task, ranked by average F 1\\nperformance across all three datasets. Best results are marked in bold.\\nTeam Easy F 1Medium F 1Hard F 1\\nfosu-stu [80] 0.987 0.887 0.834\\nnycu-nlp [68] 0.964 0.857 0.863\\nno-999 [139] 0.991 0.830 0.832\\nhuangzhijian [50] 0.985 0.815 0.826\\ntext-understanding-and-analysi [46] 0.991 0.815 0.818\\nbingezzzleep [135] 0.985 0.818 0.807\\nopenfact [63] 0.981 0.821 0.805\\nchen [20] 0.968 0.822 0.807\\nbaker [134] 0.976 0.816 0.770\\ngladiators [56] 0.956 0.809 0.783\\nkhaldi-abderrahmane 0.905 0.806 0.641\\nkarami-sh [117] 0.972 0.664 0.642\\nriyahsanjesh [113] 0.825 0.712 0.599\\nliuc0757 [72] 0.696 0.717 0.503\\nlxflcl66666 [66] 0.606 0.455 0.484\\nfoshan-university-of-guangdong [73] 0.517 0.394 0.352\\nBaseline Predict 1 0.466 0.343 0.320\\nBaseline Predict 0 0.112 0.323 0.346\\nBaseline Random 0.414 0.506 0.495\\ndocuments in each dataset, while the test and validation sets contain 15% each.\\nThe test sets were withheld for the evaluation phase of the competition.\\nThe performance of the submitted approaches is evaluated per dataset by\\nmacro-averaged F1-score value across all documents.\\nResults\\nThe task received 16 valid software submissions. The results achieved by the\\nparticipants are shown in Table 1. The best average F 1across the three datasets\\nwas achieved by the fosu-stu team. For the easy dataset, teams no-999 [139] and\\ntext-understanding-and-analysi [46] achieved the highest F 1score (0.991), for\\nthe medium dataset, fosu-stu [80] reached an F 1score of 0.887, and for the hard\\ndataset, team nycu-nlp [68] achieved a F 1of 0.863. All submissions were able to\\noutperform the three simple baselines: a random baseline, one that predicted a\\nstyle change for each pair of paragraphs, and one that predicted no style change\\nforeachpairofparagraphs.Furtherdetailsontheapproachestakencanbefound\\nin the overview paper [144].\\n3 Multilingual Text Detoxification\\nText detoxification is a subtask of text style transfer where the style of text\\nshould be changed from toxic to neutral while preserving the content. As lan-',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 4}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 5\\nTable 2: The statistics of all ParaDetox datasets used in the TextDetox shared\\ntask. The human detoxified references were collected either via crowdsourcing or\\nlocally hired native speaker. For English and Russian, the previously collected\\ntrain data was available during all shared task’s phases. For other languages,\\n1000 samples per language were divided correspondingly into development and\\ntest parts.\\nLanguage Source of Annotation Train Dev Test\\nToxic Samples Process\\nEnglish [53] Crowdsourcing+Manual 11 939 400 600\\nRussian [11, 115] Crowdsourcing+Manual 8 500 400 600\\nUkrainian [16] Crowdsourcing — 400 600\\nSpanish [96, 124, 97] Crowdsourcing — 400 600\\nGerman [133, 106, 107] Manual — 400 600\\nHindi [82] Manual — 400 600\\nAmharic [8, 7] Manual — 400 600\\nArabic [90, 40, 87, 89] Manual — 400 600\\nChinese [77] Manual — 400 600\\nguage modeling advances, there is growing concern about the potential unin-\\ntended consequences of this technology. One such concern is the possibility of\\nharmful or biased texts, which could perpetuate negative stereotypes or mis-\\ninformation [64]. This has led to a growing interest in AI safety and the need\\nfor approaches to mitigating these risks [17]. This presents a major challenge\\nfor researchers and practitioners in language model safety, who need to develop\\neffective detoxification techniques that can be applied to many languages. Pre-\\nviously, the first parallel corpus for such a task was released for English [75] and\\nRussian [27] that built a foundation for the RUSSE-2022 Text Detoxification\\nshared task.\\nIn PAN 2024, we extend our data and challenges even to more languages.\\nThe participants were asked to develop text detoxification systems for 9 lan-\\nguages: English, Spanish, German, Chinese, Arabic, Hindi, Ukrainian, Russian,\\nand Amharic. For each language, the prepared dataset was split into two parts:\\n(i) development and (ii) test. For the train part, we did not provide any training\\ndata except for English and Russian that was publicly available from the previ-\\nous work [75, 27, 26]. Thus, in the shared task, the participants were asked to\\ndo experiments in two setups:\\n– Cross-lingual setup : In thedevelopment phase, participants were provided\\n400toxic sentences per each language. They have to experiment with various\\ntechniques for cross-lingual detoxification.\\n– Multilingual setup : Then, in the test phase , we released parallel dev data\\nandaskedparticipantstoperformdetoxificationon 600samplesperlanguage\\n(3600instances in total). At this phase, participants were able to utilize par-',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 5}},\n",
              " {'text': '6 Ayele et al.\\nallel training corpora to improve their approaches and perform multilingual\\ndetoxification for any subset of languages.\\nFor both phases, an automatic leaderboard was open to provide the partici-\\npants scores of the adequacy and the proximity to the human references of their\\noutputs. However, the finalleaderboard was based on a human evaluation with\\ncrowdsourcing of subsamples from the test dataset. The human judgment gave\\na fair assessment of responses and prevented participants from over-tuning on\\nautomated metrics.\\nData Set and Evaluation\\nMultilingual ParaDetox for 9 languages The full picture of the collected Pa-\\nraDetox data for all target languages is presented in Table 2. While the methods\\nof collecting human annotations vary across languages—some data were gath-\\nered via crowdsourcing, others by hiring local native speakers—the quality of\\nthe texts was uniformly verified by experts to ensure three key attributes as\\nintroduced in [28, 75]: (i) the style of new paraphrases is genuinely non-toxic,\\n(ii) the main content is preserved, and (iii) the new texts are fluent.\\nFor each language for the shared task’s phases:\\n–During the development phase: 400onlytoxic parts were available for par-\\nticipants to perform cross-lingual experiments.\\n–During the testphase: (i) 400ParaDetox instances were fully released; (ii)\\nparticipants should provide their final solutions for 600toxic parts of the\\ntest dataset.\\nFor English and Russian during all phases, additional training parallel\\ndatasets were available from previous work [75, 27, 26]. All the data is avail-\\nable online for public usage.4\\nAutomatic Evaluation For both phases, we provided the leaderboard based\\non an automatic evaluation setup. We evaluate the outputs based on three\\nparameters—style of text, content preservation, and conformity to human\\nreferences—combining them into the final Joint score:\\n– Style Transfer Accuracy (STA) ensures that the generated text is indeed\\nmore non-toxic. It was estimated with XLM-R [22] largeinstance fine-tuned\\nfor the binary toxicity classification task for our target languages. The model\\ndetermined the degree of non-toxicity in the texts.\\n– Content Similarity (SIM) is the cosine similarity between LaBSE em-\\nbeddings [31] of the source texts and the generated texts.\\n– Fluency (ChrF1) is used to estimate the proximity of the detoxified texts\\nto human references and their fluency.\\n4https://huggingface.co/textdetox',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 6}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 7\\nHuman Evaluation We selected 100 random original toxic samples per each\\nlanguage from the testpart of our dataset and performed human evaluation via\\nToloka crowdsourcing platform.5The concept of the human evaluation mirrored\\nthe approach used in the automatic evaluation. Each project type focused on\\nassessing one of the three key qualities of detoxification; style transfer accuracy,\\ncontent similarity, or fluency:\\n– Style Transfer Accuracy : we employed a pairwise comparison between\\nthe original toxic text and the generated detoxified text. Participants were\\ntasked with determining which text was more toxic: the left text, the right\\ntext, or neither.\\n– Content Similarity : participants were shown pairs of texts (toxic phrase\\nfollowed by detoxified phrase) and asked to indicate if the sense was similar,\\nresponding with “yes” or “no”.\\n– Fluency : individual sentences were evaluated for intelligibility and correct-\\nness. Annotators could respond with “yes”, “partially”, or “no”, corresponding\\nto scores of 1, 0.5, and 0, respectively. The fluency score for a text pair was\\ndetermined by comparing the detoxified text’s score to the original. If the\\ndetoxified text had a higher or equal fluency score, the pair received a 1;\\notherwise, it received a 0.\\nFinal Joint Score (J) For both automatic and human evaluation setups, the J\\nscore was the aggregation of the three above metrics. The metrics STA,SIM\\nandFLwere subsequently combined into the final Jscore used for the final\\nranking of approaches. Given an input toxic text xiand its output detoxified\\nversion yi, for a test set of nsamples:\\nJ=1\\nnnP\\ni=1STA (yi)·SIM(xi, yi)·FL(xi, yi),\\nwhereSTA(yi),SIM(xi, yi),FL(xi, yi)∈[0,1]forautomatic and∈ {0,1}for\\nhumanevaluation for each text detoxification output yi.\\nWe calculated all the metrics separately per each language. In the end, we\\ncalculated the Average score of 9 Joint scores per all languages that were used\\nto compile the leaderboard.\\nResults\\nWe received 20 submissions for the development phase leaderboard and 31 sub-\\nmissionsforthetestphaseleaderboard;thefinalmanuallyevaluatedleaderboard\\nwas based on 17 submissions who confirmed their participation in the competi-\\ntion [93, 130, 110, 149, 95, 78, 34, 123, 91, 63, 105, 102, 99]. The final leaderboard\\nbased on human assessments is presented in Table 3.\\nAlmost all of the participants used the current SOTA LLMs, among which\\nare GPT-3.5 [92] and Llama-3 [3] models; to enhance the model’s performance\\n5https://toloka.ai',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 7}},\n",
              " {'text': '8 Ayele et al.\\nTable 3: Results of the humanfinal evaluation of the TextDetox test phase.\\nScores are sorted by the average Joint score. Scores are sorted by the average\\nJoint score across all 9 languages. Baselines are highlighted with gray , Human\\nReferences are highlighted with green .\\nTeam Avg System\\nHuman References 0.851Human paraphrases from our multilingual ParaDetox\\nSomethingAwful 0.774Few-shot LLaMa-3 prompting+mT0-XL\\nadugeen 0.741Fine-tuned mT0-XL with ORPO [43]\\nVitalyProtasov 0.723Preprocessing+mT0-large\\nnikita.sushko 0.712Fine-tuned mT0-XL+postprocessing\\nerehulka 0.708Few-shot LLaMa-3 prompting\\nbmmikheev 0.685Few-shot LLaMa-3 prompting+GPT-3.5 post-eval.\\nmkrisnai 0.681Few-shot GPT-3.5 prompting\\nd1n910 0.654Few-shot Kimi.AI prompting\\nYekaterina29 0.639Fine-tuned mT5-XL\\nestrella 0.576Tree of Thought GPT3.-5 prompting\\ngleb.shnshn 0.564Zero-shot LLaMa-3-70b prompting\\nDelete 0.560Elimination of toxic keywords\\nmT5 0.541Fine-tuned mT5-XL\\nshredder67 0.524Fine-tuned mT5-XL\\nrazvor 0.516Few-shot LLaMa-3 prompting\\nZhongyuLuo 0.513Translation+BART-detox&ruT5-detox\\ngangopsa 0.500Fine-tuned T5&BART+token-level editing\\nBacktranslation 0.411Translation of data to English+BART-detox\\nmaryam.najafi 0.177Mistral-7b with PPO\\ndkenco 0.119Few-shot Cotype-7b prompting\\non the task of detoxification participants tested both zero-shot and few-shot\\nprompting methods. Among smaller models, there were used mT5 [137] and\\nmT0 [88]—these models were usually finetuned using ad hoc filtering and data\\naugmentation techniques, for instance, as RAG and backtranslation. Addition-\\nally, region-specific LLMs were also employed: Cotype-7b [86] and Kimi.AI [2].\\nThe majority of the participants overcame the baselines and even a couple\\nof solutions outperformed human references. Still, for not-so-rich-resource lan-\\nguages such as Ukrainian, Chinese, Amharic, and Hindi human detoxified para-\\nphrases remained the gold standard. At the same time, various experiments from\\nparticipants illustrate that vanilla usage of LLMs for the detoxification task does\\nnot achieve high results. At least more advanced prompting techniques and fine-\\ntuning on the downstream task with our provided data boosted the performance\\nsignificantly achieving such interesting SOTA results.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 8}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 9\\nFigure1: A Telegram text annotated with elements of oppositional narrative.\\n4 Oppositional Thinking Analysis: Conspiracy Theories\\nvs Critical Thinking Narratives\\nConspiracy theories are complex narratives that attempt to explain the ultimate\\ncauses of significant events as cover plots orchestrated by secret, powerful, and\\nmalicious groups [29]. A challenging aspect of identifying conspiracy with NLP\\nmodels [109, 100, 101, 35, 62, 33] stems from the difficulty of distinguishing\\ncritical thinking from conspiratorial thinking in automatic content moderation.\\nThis distinction is vital because labeling a message as conspiratorial when it is\\nonly oppositional could drive those who were simply asking questions into the\\narms of the conspiracy communities.\\nAtPAN2024weaimatanalyzingoppositionalthinking,andmoreconcretely,\\nat discriminating conspiracy from critical narratives from a stylometry perspec-\\ntive. The task will address two new challenges for the NLP research community:\\n(1) to distinguish the conspiracy narrative from other oppositional narratives\\nthat do not express a conspiracy mentality (i.e., critical thinking); and (2) to\\nidentify in online messages the key elements of a narrative that fuels the inter-\\ngroup conflict in oppositional thinking. Accordingly, we propose two sub-tasks:\\n– Subtask 1 is a binary classification task differentiating between (1) critical\\nmessages that question major decisions in the public health domain, but\\ndo not promote a conspiracist mentality; and (2) messages that view the\\npandemic or public health decisions as a result of a malevolent conspiracy\\nby secret, influential groups.\\n– Subtask2 isatoken-levelclassificationtaskaimedatrecognizingtextspans\\ncorresponding to the key elements of oppositional narratives. Since conspir-\\nacy narratives are a special kind of causal explanation, we developed a span-\\nlevel annotation scheme that identifies the goals, effects, agents, and the\\ngroups-in-conflict in these narratives.\\nFor the second task, a new fine-grained annotation scheme was developed\\nwith the goal of identifying, at the text span level, how oppositional and con-\\nspiracy narratives use inter-group conflict. The annotation was performed for the\\ndescribed 5,000 binary-labeled messages per language. We identify the following\\nsix categories of narrative elements at the span level (see Figure 1):\\n– Agents : the hidden power that pulls the strings of the conspiracy. In crit-\\nical messages, agents are actors that design the mainstream public health\\npolicies: Government, WHO, ...;',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 9}},\n",
              " {'text': '10 Ayele et al.\\nTable 4: Overall results for subtask 1 on Conspiracy theories vs Critical thinking\\nnarratives in English (EN) in terms of Matthew’s correlation coefficient (MMC).\\nTeam EN MCC\\nIUCL 0.838\\nAI_Fusion 0.830\\nSINAI 0.829\\nezio 0.821\\nhinlole 0.819\\nZleon 0.819\\nvirmel 0.819\\ninaki 0.814\\nyeste 0.812\\nauxR 0.808\\nElias&Sergio 0.803\\ntheateam 0.803\\ntrustno1 0.798\\nDSVS 0.797\\nsail 0.796\\nojo-bes. 0.796\\nRD-IA-FUN 0.796\\nBaseline BERT 0.796\\naish_team 0.791\\nrfenthusiasts 0.790\\nDap_upv 0.789\\noppositional_opposition 0.789\\nRD-IA-FUN 0.789\\nmiqarn 0.788\\nCHEEXIST 0.787\\ntulbure 0.787\\nXplaiNLP 0.787\\nTheGymNerds 0.785Team EN MCC\\nnlpln 0.784\\nRalloRico 0.777\\nLasGarcias 0.775\\nzhengqiaozeng 0.775\\nALC-UPV-JD-2 0.772\\nLorenaEloy 0.771\\nlnr-alhu 0.770\\nNACKO 0.769\\nparanoia-pulverizers 0.768\\nDiTana 0.765\\nFredYNed 0.764\\ndannuchihaxxx 0.764\\nlnr-detectives 0.763\\nTargaMarhuenda 0.761\\nTrainers 0.759\\nthetaylorswift 0.757\\nlocasporlnr 0.757\\nlnr-adri 0.755\\nTokoAI 0.754\\nede 0.753\\nlnr-verdnav 0.752\\nlnr-dahe 0.748\\nepistemologos 0.748\\nlucia&ainhoa 0.747\\npistacchio 0.741\\nlnr-BraulioP. 0.739\\nMarc_Coral 0.739\\nRamon&Cajal 0.728Team EN MCC\\nlnr-lladrogal 0.725\\nlnr-fanny-nuria 0.725\\nMarcosJavi 0.719\\nlnr-cla 0.716\\nlnr-jacobant. 0.716\\nMUCS 0.716\\nlnr-aina-julia 0.715\\nLaDolceVita 0.707\\nalopfer 0.705\\nlnr-luqrud 0.705\\nLNR-JoanPau 0.705\\nlnr-carla 0.700\\nlnr-Inetum 0.698\\nlnr-antonio 0.685\\nLluisJorge 0.678\\nanselmo-team 0.672\\nlnr-pavid 0.595\\nLNRMADME 0.546\\nlnr-mariagb. 0.506\\nLNR_08 0.442\\nKaprov 0.370\\nlnr_cebusqui 0.048\\njtommor 0.040\\neledu 0.459\\ndavid-canet 0.631\\nlnr-guilty 0.659\\nlnrANRI 0.755\\nROCurve 0.800\\n– Objectives : parts of the narrative that answer the question “What is in-\\ntended by the agents of the conspiracy theory or by the promoters of the\\naction being criticized from a critical thinking perspective?”;\\n– Consequences : parts of the narrative that describe the effects of the agent’s\\nactions;\\n– Facilitators : the facilitators are those who collaborate with the conspira-\\ntors; in critical messages, facilitators are those who implement the measures\\ndictated by the authorities;\\n– Campaigners : in conspiracy messages, the campaigners are the ones who\\nuncover the conspiracy theory; in critical messages, campaigners are those\\nwho resist the enforcement of laws and health instructions; and\\n– Victims : the people who are deceived into following the conspiratorial plan\\nor the ones who suffer due to the decisions of the authorities.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 10}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 11\\nTable 5: Overall results for subtask 1 on Conspiracy theories vs Critical thinking\\nnarratives in Spanish (ES) in terms of Matthew’s correlation coefficient (MMC).\\nTeam ES MCC\\nSINAI 0.742\\nauxR 0.720\\nRD-IA-FUN 0.702\\nElias&Sergio 0.697\\nAI_Fusion 0.687\\nzhengqiaozeng 0.687\\nvirmel 0.685\\ntrustno1 0.684\\nZleon 0.682\\nojo-bes 0.681\\ntulbure 0.672\\nsail 0.671\\nnlpln 0.668\\nBaseline BERT 0.668\\npistacchio 0.667\\nrfenthusiasts 0.665\\nXplaiNLP 0.662\\nyeste 0.660\\noppositional_opposition 0.660\\nepistemologos 0.656\\nmiqarn 0.656\\ntheateam 0.655\\nezio 0.653\\nlucia&ainhoa 0.652\\nTargaMarhuenda 0.651\\nTokoAI 0.651\\nparanoia-pulver. 0.649Team ES MCC\\nNACKO 0.646\\nALC-UPV-JD-2 0.646\\nDSVS 0.646\\nRD-IA-FUN 0.644\\nlocasporlnr 0.643\\nDiTana 0.637\\nlnr-BraulioPaula 0.635\\nDap_upv 0.630\\nTheGymNerds 0.630\\nMUCS 0.629\\nLasGarcias 0.624\\nlnr-dahe 0.619\\nlnr-adri 0.619\\nhinlole 0.619\\nRalloRico 0.610\\nlnr-aina-julia 0.61\\nlnr-verdnav 0.61\\nthetaylorswift 0.60\\nlnr-alhu 0.60\\nlnr-luqrud 0.60\\nlnr-lladrogal 0.59\\nede 0.59\\nFred&Ned 0.59\\nLaDolceVita 0.59\\nLNR-JoanPau 0.59\\nanselmo-team 0.58Team ES MCC\\nRamon&Cajal 0.58\\nlnr-fanny-nur. 0.58\\nlnr-antonio 0.57\\nLluisJorge 0.56\\nlnr-cla 0.56\\nlnr-jacobant. 0.56\\nlnr-pavid 0.55\\nalopfer 0.55\\nLNRMADME 0.54\\nlnr-carla 0.54\\nLorenaEloy 0.54\\nCHEEXIST 0.53\\nlnr-guilty 0.52\\neledu 0.50\\nlnr-mariagb. 0.49\\ndannuchihaxxx 0.47\\nlnr-detectives 0.40\\nLNR_08 0.06\\njtommor 0.01\\nlnr-Inetum 0.00\\nMarc_Coral 0.00\\nMarcosJavi -0.03\\nlnr_cebusqui -0.41\\ndavid-canet -0.50\\nlnrANRI -0.61\\nROCurve -0.64\\nData Set and Evaluation\\nFor the creation of the corpus, we first manually compiled a list of 2,273 pub-\\nlic Telegram channels in English andSpanish that contain oppositional non-\\nmainstream views on the COVID-19 pandemic. We retrieved and filtered mes-\\nsages from the channels based on a set of oppositional and conspiracy keywords\\nrelated to COVID-19. Then the messages were cleaned by removing duplicates,\\nshorttexts,andtextswithalargeproportionofnon-regularwords(suchasURLs\\nand mentions). Finally, the messages were ranked using an index of quality based\\non the properties of a message and its channel. The index is composed of several\\ncriteria capturing the prevalence of COVID-19 topics and the channel’s activity.\\nWe developed an annotation schema to differentiate between the messages\\ncriticizing the mainstream views on COVID-19 and the messages evoking the\\nexistence of a conspiracy. A message was labeled \"conspiracy\" if any of these four\\ncriteria were met: (1) it framed COVID-19 or a related public health strategy as\\nthe result of the agency of a small and malevolent secret group; (2) it claimed\\nthat the pandemic is not real (e.g. a plandemic); (3) it accused critics of the',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 11}},\n",
              " {'text': '12 Ayele et al.\\nTable 6: Overall results for subtask 2 on the Text-span recognition of elements\\nof oppositional narratives, in English (EN) and Spanish (ES), in terms of macro-\\naveraged span-F1\\nTeam EN span-F1\\ntulbure 0.6279\\nZleon 0.6089\\nhinlole 0.5886\\noppositional_opposition 0.5866\\nAI_Fusion 0.5805\\nvirmel 0.5742\\nmiqarn 0.5739\\nTargaMarhuenda 0.5701\\nezio 0.5694\\nzhengqiaozeng 0.5666\\nElias&Sergio 0.5627\\nDSVS 0.5598\\nCHEEXIST 0.5524\\nrfenthusiasts 0.5479\\nALC-UPV-JD-2 0.5377\\nBaseline BETO 0.5323\\nDap_upv 0.5272\\naish_team 0.5213\\nSINAI 0.4582\\nTrainers 0.3382\\nnlpln 0.3339\\nROCurve 0.2996\\nTokoAI 0.2760\\nDiTana 0.2756\\nTheGymNerds 0.2070\\nepistemologos 0.1709\\ntheateam 0.1503\\nLaDolceVita 0.0726\\nkaprov 0.0150Team ES span-F1\\ntulbure 0.6129\\nZleon 0.5875\\nAI_Fusion 0.5777\\nCHEEXIST 0.5621\\nvirmel 0.5616\\nmiqarn 0.5603\\nDSVS 0.5529\\nTargaMarhuenda 0.5364\\nElias&Sergio 0.5151\\nhinlole 0.4994\\nBaseline BETO 0.4934\\nDap_upv 0.4914\\nzhengqiaozeng 0.4903\\nALC-UPV-JD-2 0.4885\\nezio 0.4869\\nnlpln 0.4672\\nrfenthusiasts 0.4666\\nSIANI 0.4151\\nTheGymNerds 0.3984\\nDiTana 0.3004\\nROCurve 0.2649\\nTokoAI 0.1878\\nepistemologos 0.1657\\nLaDolceVita 0.1056\\ntheateam 0.0994\\noppositional_opposition 0.0037\\nconspiracytheoryofbeingapartoftheplot;(4)itdividedsocietyintotwo:those\\nwho know the truth (the conspiracy theorists) and those who remain ignorant.\\nA message was labeled “critical” if it opposed publicly accepted understandings\\nof events but had none of these four characteristics of the conspiratorial mindset.\\nUsing this annotation scheme, 5,000 messages per language were anno-\\ntated as \"conspiracy\" or \"critical\" thinking. For these messages, we performed\\nanonymization by removing sensitive and identifiable information such as nick-\\nnames, user IDs, and e-mail addresses. The average text length is 128 tokens for\\nSpanish texts and 265 tokens for English texts that tend to elaborate more on\\nconspiracy theories.\\nEachmessagewasannotatedbythreelinguistsandtheinter-annotatoragree-\\nment (IAA) was calculated. Disagreements were discussed with the social psy-\\nchologist who created the annotation scheme. For English messages, the IAA in\\nterms of Krippendorf’s αis 0.79 for “conspiracy” messages and 0.60 for “criti-',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 12}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 13\\ncal” messages, while the average observed percentage of agreement between the\\nthree annotators is 91.4%, and 80.3%, respectively. For Spanish messages, Krip-\\npendorf’s αis 0.80 for “conspiracy” messages and 0.70 for “critical” messages,\\ncorresponding to the percentage agreements of 90.9% and 84.9%.\\nFor the second task, a new fine-grained annotation scheme was developed\\nwith the goal of identifying, at the text span level, how oppositional and con-\\nspiracy narratives use intergroup conflict. The annotation was performed for the\\ndescribed 5,000 binary-labeled messages per language.\\nIn the process of span-level annotation, each of the 5,000 Spanish and English\\nmessages were annotated by two linguists. Currently, the annotation instructions\\nare being discussed and improved and, to this end, we are using the Gamma ( γ)\\nmeasure of the IAA test [83], yielding a first average γof0.43. The following\\nbatchhadanaveragegammaof 0.53,andthelastonehada γof0.61.Wedeemed\\nthis a good agreement because it is close to or above the average agreement of\\nother highly conceptual span-level schemes [24, 132]. A detailed description of\\nthe dataset can be found in [60].\\nThe official evaluation metric for subtask 1 (critical vs. conspiracy classifica-\\ntion) is Matthew’s correlation coefficient (MCC) [21], while the official metric for\\nsubtask 2 (span-level detection of narrative elements) is macro-averaged span-F1\\n[23].\\nResults\\nA total of 83 teams submitted their runs for subtasks 1 and 2, resulting in\\n18 notebook submissions [51, 131, 44, 9, 25, 112, 4, 150, 30, 111, 36, 6, 81,\\n147, 47, 128, 71]. In the tables above we illustrate the ranking per language.\\nConcretely, Table 4 and Table 5 show the overall results obtained for subtask\\n1 on Conspiracy theories vs critical thinking narratives, in terms of Matthew’s\\ncorrelation coefficient; while Table 6 shows the results of subtask 2 on Text-span\\nrecognition of elements of oppositional narratives, in terms of macro-averaged\\nspan-F1.\\nWe will analyze in detail the results and describe the models of the partici-\\npants in the task overview paper [61].\\n5 Voight-Kampff Generative AI Authorship Verification\\nAuthorshipverificationisafundamentaltaskinauthoridentification.Allcasesof\\nquestioned authorship can be decomposed into a series of verification instances,\\nbe it in a closed-set or open-set scenario [59]. Since PAN has been continuously\\norganizing Authorship verification tasks [119, 13, 12, 118], we are well-equipped\\nto tackle a timely and highly important issue: identification of machine author-\\nship in contrast to human authorship.\\nAuthorship identification of generative AI “in the wild” where a single doc-\\nument is disputed without reference is an open-set problem and the hardest',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 13}},\n",
              " {'text': '14 Ayele et al.\\nInput / Task\\n1. {?,?}\\n2. {?,?}\\n3. {?,?}\\n4. {?,?}\\n5. {?,?}\\n6. {?,?}\\n7.?−→Possible Assignment Patterns\\n1. {A,M}\\n2. {A,M}, {A,A}\\n3. {A,M}, {M,M}\\n4. {A,M}, {A,A}, {M,M}\\n5. {A,M}, {A,A}, {A,B}\\n6. {A,M}, {A,A}, {A,B}, {M,M}\\n7.A, M\\nFigure2: Hierarchy of authorship verification problems from “easiest” (1) to\\n“hardest” (7), involving LLM-generated text. Ignoring mixed human and ma-\\nchine authorship, the difficulty arises from the pairing constraints imposed by\\nthe possible assignment patterns. Mdenotes LLM-generated text, while Aand\\nBdenote human-authored text (same letter meaning same human author).\\nformulation of the task. Although the literature suggests limited success in solv-\\ningthisproblemgiventhecurrentgenerationofLLMs,itisquestionablewhether\\nthis will remain so with improving technology. Setting aside mixed human and\\nmachine authorship, we have broken down all possible formulations of the prob-\\nlem with increasing levels of difficulty to get a more fundamental understanding\\nof the task at hand and the feasibility of potential solutions. Figure 2 visual-\\nizes the cascade of all problem variants from easiest (Task 1) to most difficult\\n(Task 7). In the easiest case, two documents with unknown authorship are given,\\nyet we guarantee that exactly one is generated by a human A, and the other by\\na machine M, respectively. This constraint is relaxed in the following variants\\nwhere, for example, both texts may also stem from a machine, { M,M}. In the\\nhardest case, a single text is given, which could be either AorM.\\nFor the 2024 task on “Generative AI Authorship Verification,” we follow the\\n“easiest” formulation of the task in order to establish a feasibility baseline. The\\ntask description reads: “Given two texts, one authored by a human, one by a\\nmachine: pick out the human. ”\\nThe task is organized in collaboration with the ELOQUENT Lab [54] in\\na builder-breaker style, in which PAN participants build systems to identify\\nmachine authorship, while ELOQUENT participants supply datasets trying to\\nbreak the systems.\\nData Set\\nIn addition to the ELOQUENT-provided data, we collected 1,359 articles of\\nmajor 2021 U.S. news headlines from Google News. We chose this time period\\nspecifically as it predates the release of GPT-3.5 so that we could be reasonably\\ncertain the articles were actually human-authored. We used GPT-4-Turbo to\\ngenerate a bullet-point summary of each article and the summaries were then',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 14}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 15\\nTable 7: Overview of the 65 dataset variants provided as baseline datasets. All\\nvariants contain the same 271 human texts and (roughly) one machine gener-\\nated text per LLM used. Discarding erroenous generations, this results in 3,441\\npairings each for main and cross-domain variants, 600 for both unicode variants\\nand short texts, 543 for german texts, 542 for the Kaggle prompt, 272 for both\\ncontrastive decoding (* using Llama2-13B).\\nChatCat\\nBloomz\\nGemini Pro\\nwith temp.\\nText-Bison\\nGPT\\nLlama2\\nMistral\\nQwen-1.5\\nVariation / Obfuscation 7B 7B 0.6 0.9 002 2-OI 3.5 4 7B 70B 7B 8x7B 72B\\nMain x x x x x x x x x x x x x\\nUnicode sub. (machine) x x x x x x x\\nUnicode sub. (both) x x x x x x x\\nCross-domain x x x x x x x x x x x x x.\\nShort text x x x x x x x x x x x x x\\nGerman text (machine) x x\\nContr. decoding ( α= 0.1) x*\\nContr. decoding ( α= 0.6) x*\\nKaggle prompt x x\\ngiven to a selection of 13 downstream large language models to write new articles\\nfrom them.\\nOf the original 1,359 human-authored articles, participants were given 1,087\\ntogether with their machine counterparts from 13 LLMs to calibrate their sys-\\ntems. The remaining 272 articles and generations from 15 LLMs were kept back\\nfor testing, resulting in 3,984 test cases, which together form the “main” portion\\nof the test set.\\nTo further test the robustness of the submitted systems, we generated mul-\\ntiple variants of the original pairs. In particular, we: (1) amended the prompt to\\ngenerate German instead of English texts (this was already part of the “main”\\ntestset,butnotcommunicatedtotheparticipants);(2)replaced15%ofthechar-\\nacters in (a) the machine texts and (b) both the human and machine texts with\\nUnicode lookalike characters; (3) shuffled the test case pairs to break the topic\\ncoherence; (4) used contrastive decoding [121] instead of top- k/top- psampling;\\n(5) cropped texts to 35 words; and (6) used the prompt from a previous Kaggle\\ncompetition on LLM detection [57] to generate more faithful paraphrases of the\\noriginal articles, instead of using the stripped-down bullet point summaries.\\nIn total, we created 65 test set variations from 13 (15) different LLMs, which\\nare summarized in Table 7, with ELOQUENT providing another five. A more\\ndetailed description is available in the joint task overview paper [15].',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 15}},\n",
              " {'text': '16 Ayele et al.\\nEvaluation\\nAt test time, participants were given pairs of human and LLM texts and had\\nto calculate a score between 0 and 1, indicating which text was more likely to\\nbe human-authored. Scores less than 0.5 mean the left text is human and scores\\ngreater than 0.5 mean the right text is human. A score of exactly 0.5 could be\\ngiventosignalanon-decision.Weborrowedthisevaluationschemefromprevious\\ninstallments of the PAN Authorship Verification Task.\\nWe rank systems by their macro-average effectiveness across all n= 70\\ndataset variants (including ELOQUENT submissions) discounted by half a stan-\\ndard deviation (estimated from the scores with n−1DoF), which penalizes un-\\nstable systems that are not robust against text obfuscations or other text vari-\\nations. We use the macro average over datasets since all datasets have different\\nnumbers of examples, yet we consider them equally important as performance\\nindicators.\\nAlso in line with previous task installments, we compute the effectiveness for\\neach dataset variant as the average of the established evaluation measures in\\nauthorship verification (all with comparable 0–1 scales). In particular:\\n–Roc-Auc : The area under the Receiver Operating Characteristic curve.\\n–Brier: The complement of the Brier score (mean squared loss)\\n–C@1: A modified accuracy score that assigns non-answers (score = 0.5) the\\naverage accuracy of the remaining cases.\\n–F1: The harmonic mean of precision and recall.\\n–F0.5u: A modified F 0.5measure (precision-weighted F measure) that treats\\nnon-answers (score = 0.5) as false negatives.\\nSubmitted Systems\\nIntotal,ourtaskattracted34teamstosubmitsystemsinadditiontothebaseline\\nsystems we provided. Table 8 shows the best-performing system of each team\\nthat submitted notebook papers and a brief description of their approach.\\nBaselines Weprovidedimplementationsofsixbaselinesystemstocomparesub-\\nmitted systems against four state-of-the-art zero-shot LLM detection baselines\\nand two adapted authorship verification baselines.\\nThe zero-shot LLM detection baselines are: (1) Binoculars [42], (2) De-\\ntectLLM (both NPR and LRR scoring mode), (3) DetectGPT [85], and (4)\\nFast-DetectGPT[10].AllthreewereprovidedintwovariantsusingeitherFalcon-\\n7B [5] or Mistral-7B [52] to estimate text perplexities. The required text pertur-\\nbations for DetectGPT and DetectLLM-NPR were generated with T5-3B [104].\\nThe two authorship verification baselines were adapted to the LLM detection\\ntask by splitting each text in half and comparing the two halves against each\\nother under the assumption that LLM texts are stylistically more self-similar\\nthan human texts. The baselines provided are a compression model (PPMd\\nCBC) [114, 41] and short-text authorship unmasking [58, 14].',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 16}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 17\\nTable 8: The score is the mean of all evaluation measures across all other metrics\\non the main dataset corrected by half a standard deviation to correct for spread.\\nTeam Score System\\nTavan [125] 0.924 Ensemble: LoRA-trained LLM + Binoculars\\nJ. Huang [46] 0.921 BERT with multiscale PU loss [126]\\nLorenz [76] 0.886 SVM with TF-IDF features\\nM. Guo [39] 0.884 LSTM embeddings + GPT-2 PPL\\nZ. Lin [69] 0.851 Finetuned BERT + R-Drop\\nAbburi [1] 0.843 Ensemble: RoBERTa + E5 + GPT-2 Perplexity\\nMiralles [84] 0.806 Entropy and text features + XGBoost\\nYadagiri [138] 0.806 Finetuned BERT + linguistic features\\nLv [79] 0.804 Finetuned DeBERTa with Reptile meta learning\\nGritsai [37] 0.796 Ensemble: LoRA-trained LLMs\\nCao [18] 0.778 Finetuned BERT\\nL. Guo [38] 0.763 BERT and text features + Bi-LSTM\\nBinoculars 1 0.741 Baseline Binoculars (Falcon-7B) [42]\\nB. Huang [45] 0.735* Finetuned BERT + R-Drop [67]\\nValdez-Valenzuela [129] 0.727* Graph Neural Network + BERT\\nYe [140] 0.722 T5 with LM head trained to predict class\\nChen [19] 0.694 Ensemble: 2x BERT + GPT-2 (PPL)\\nW. Huang [49] 0.683 Perplexity of GPT-2 trained on LLMs + SVM\\nQin [103] 0.680* Ensemble: BERTs + R-Drop\\nBinoculars 2 0.671 Baseline Binoculars (Mistral-7B) [42]\\nDetectLLM 1 0.654 Baseline DetectLLM LRR (Mistral-7B) [120]\\nPetropoulos [98] 0.641 RoBERTa embeddings + Bi-LSTM\\nFast-DetectGPT 1 0.638 Baseline Fast-DetectGPT (Mistral-7B) [10]\\nWu [136] 0.608 BERT embeddings + extra Transformer block\\nText Length 0.604 Baseline Text length\\nZ. Lin [70] 0.565 T5 with LM head trained to predict class\\nZhu [148] 0.555 Finetuned DeBERTa\\nPPMd CBC 0.544 Baseline PPMd Compression-based Cosine [114, 41]\\nSun [122] 0.531 BERT embeddings + CNN\\nDetectLLM 2 0.512 Baseline DetectLLM NPR (Mistral-7B) [120]\\nLei [65] 0.504 LoRA-trained ChatGLM\\nFast-DetectGPT 2 0.500 Baseline Fast-DetectGPT (Falcon-7B) [10]\\nLiu [74] 0.497 Preplexity of pre-trained GPT-2\\nDetectGPT 1 0.488 Baseline DetectGPT (Mistral-7B) [85]\\nK. Huang [48] 0.480 Siamese DeBERTa\\nDetectLLM 3 0.468 Baseline DetectLLM NPR (Falcon-7B) [120]\\nUnmasking 0.467 Baseline Authorship Unmasking [58, 14]\\nSheykhlan [116] 0.460 Ensemble: BERT, RoBERTa, and Electra\\nDetectLLM 4 0.460 Baseline DetectLLM LRR (Falcon-7B) [120]\\nDetectGPT 2 0.439 Baseline DetectGPT (Falcon-7B) [85]\\nOstrower [94] [No software submitted]\\n* Scores estimated due to run failures on some dataset variants.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 17}},\n",
              " {'text': '18 Ayele et al.\\nAs an additional seventh baseline, we measured and compared the text\\nlengths in characters. This baseline serves as both a quasi-random baseline and\\nas a data sanity check.\\nParticipant Systems While our baseline systems reproduce established meth-\\nods in either authorship verification or intrinsic, zero-shot LLM detection, the\\nparticipant systems cover a broad range of approaches. The most popular ap-\\nproach is to use a BERT-based classifier with some modification (like PU loss\\nor R-Drop), bagging, and/or expansion of the given training data with other\\nLLM detection datasets. Some systems use engineered features like perplexity,\\nproperties of token distributions, or stylometrics (exclusively or in addition to\\nBERT-embeddings) as classifier (Linear, XGBoost, LSTM) inputs. Most of these\\nclassification methods apply a posterior comparison of scores similar to how we\\nuse Binoculars, although some participants also train models to directly discrim-\\ninate between the pairings. In some cases, participants also developed zero-shot\\nmethods and adapted LLMs directly for the detection task, often using LoRa.\\nResults\\nTable 8 shows the ranking scores of the best system submitted by each partic-\\nipating team and the baselines. In total, 10 teams surpassed all baselines. The\\noverall best submission (by Tavan and Najafi; mean score of 0.924) finetunes\\nMistral and Llama2 models, combining them into an ensemble with the Binoc-\\nulars baseline [42]. This approach beats the original baseline by 0.183 points,\\nthough there appears to be no general best strategy for AI detection. The top 5\\nsystemsareamixtureofzero-shotperplexityestimatorsandsupervisedblackbox\\nclassifiers based on BERT or even linear classifiers.\\nOn the individual datasets, we see that almost all submissions perform quite\\nwell on non-obfuscated text ( Roc-Auc >0.9). We must therefore conclude that\\neven the most advanced LLMs still exhibit obvious stylistic idiosyncrasies which\\nmake their texts easy to distinguish from human ones. However, none of the\\nsystems is entirely robust against (unexpected) obfuscations and particularly\\nshort text samples are a big challenge for all systems. Some systems did not\\nproduce any output on the short texts due to a programming problem. For\\nthe final evaluation, the missing values were filled with the corresponding mean\\nvalues from all other systems. Affected systems are marked with * in Table 8.\\nA more detailed description and analysis of the submissions and the results\\ncan be found in the joint PAN and ELOQUENT task overview paper [15].\\nAcknowledgments\\nThe work of Paolo Rosso, Damir Korenčić, and Berta Chulvi was in the\\nframework of XAI-DisInfodemics: eXplainable AI for disinformation and con-\\nspiracy detection during infodemics (MICIN PLEC2021-007681), funded by',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 18}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 19\\nMCIN/AEI/10.13039/501100011033 and by the European Union NextGener-\\nationEU/PRTR.\\nThe work from Symanto has been partially funded by XAI-DisInfodemics:\\neXplainable AI for disinformation and conspiracy detection during infodemics\\n(MICIN PLEC2021-007681), Pro2Haters – Proactive Profiling of Hate Speech\\nSpreaders (CDTi IDI-20210776), OBULEX - OBservatorio del Uso de Lenguage\\nsEXista en la red (IVACE IMINOD/2022/106), and the ANDHI – ANomalous\\nDiffusion of Harmful Information (CPP2021-008994) R&D grants.\\nThe work of Janek Bevendorff, Matti Wiegmann, Maik Fröbe, Martin Pot-\\nthast, and Benno Stein has been funded as part of the OpenWebSearch project\\nby the European Commission (OpenWebSearch.eu, GA 101070014).\\nBibliography\\n[1] Abburi, H., Pudota, N., Veeramani, B., Bowen, E., Bhattacharya, S.: Team Deloitte at\\nPAN: Generative AI Text Detection. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[2] AI, M.: Kimi chatbot (2024), URL https://kimi.moonshot.cn, accessed: 2024-05-31\\n[3] AI@Meta: Llama 3 model card (2024), URL\\nhttps://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md\\n[4] Albladi, A., Seals, C.: Detection of Conspiracy vs. Critical Narratives and Their Elements\\nusing NLP. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[5] Almazrouei, E., Alobeidli, H., Alshamsi, A., Cappelli, A., Cojocaru, R., Hesslow, D.,\\nLaunay, J., Malartic, Q., Mazzotta, D., Noune, B., Pannier, B., Penedo, G.: The Falcon\\nseries of open language models. arXiv [cs.CL] (28 Nov 2023)\\n[6] Ansari, T., Ghazi, T., Alvi, F., Samad, A.: Decoding COVID-19 Narratives: Conspiracy or\\nCritique? Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[7] Ayele, A.A., Dinter, S., Belay, T.D., Asfaw, T.T., Yimam, S.M., Biemann, C.: The 5Js in\\nEthiopia: Amharic hate speech data annotation using Toloka Crowdsourcing Platform. In:\\nProceedings of the 4th International Conference on Information and Communication\\nTechnology for Development for Africa (ICT4DA), pp. 114–120, Bahir Dar, Ethiopia (2022),\\nURL https://ieeexplore.ieee.org/document/9971189\\n[8] Ayele, A.A., Yimam, S.M., Belay, T.D., Asfaw, T., Biemann, C.: Exploring Amharic hate\\nspeech data collection and classification approaches. In: Proceedings of the 14th\\nInternational Conference on Recent Advances in Natural Language Processing, (Sep 2023),\\nURL https://aclanthology.org/2023.ranlp-1.6\\n[9] Balasundaram, P., Swaminathan, K., Sampath, O., Km, P.: Oppositional Thinking Analysis:\\nConspiracy Theories vs Critical Thinking Narratives. Working Notes of CLEF 2024,\\nCEUR-WS.org (2024)\\n[10] Bao, G., Zhao, Y., Teng, Z., Yang, L., Zhang, Y.: Fast-DetectGPT: Efficient zero-shot\\ndetection of machine-generated text via conditional probability curvature. arXiv [cs.CL]\\n(8 Oct 2023)\\n[11] Belchikov, A.: Russian language toxic comments.\\nhttps://www.kaggle.com/blackmoon/russian-language-toxic-comments (2019), accessed:\\n2023-12-14\\n[12] Bevendorff, J., Chulvi, B., la Peña Sarracén, G.L.D., Kestemont, M., Manjavacas, E.,\\nMarkov, I., Mayerl, M., Potthast, M., Rangel, F., Rosso, P., Stamatatos, E., Stein, B.,\\nWiegmann, M., Wolska, M., Zangerle, E.: Overview of PAN 2021: Authorship verification,\\nprofiling hate speech spreaders on twitter, and style change detection. In: Experimental IR\\nMeets Multilinguality, Multimodality, and Interaction - 12th International Conference of the\\nCLEF Association, CLEF 2021, Springer (2021)\\n[13] Bevendorff, J., Ghanem, B., Giachanou, A., Kestemont, M., Manjavacas, E., Markov, I.,\\nMayerl, M., Potthast, M., Pardo, F.M.R., Rosso, P., Specht, G., Stamatatos, E., Stein, B.,\\nWiegmann, M., Zangerle, E.: Overview of PAN 2020: Authorship verification, celebrity\\nprofiling, profiling fake news spreaders on twitter, and style change detection. In:\\nExperimental IR Meets Multilinguality, Multimodality, and Interaction - 11th International\\nConference of the CLEF Association, CLEF 2020, Thessaloniki, Greece, September 22-25,\\n2020, Springer (2020)\\n[14] Bevendorff, J., Stein, B., Hagen, M., Potthast, M.: Generalizing unmasking for short texts.\\nIn: Proceedings of the 2019 Conference of the North, pp. 654–659, Association for\\nComputational Linguistics, Stroudsburg, PA, USA (2019),\\nhttps://doi.org/10.18653/v1/n19-1068',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 19}},\n",
              " {'text': '20 Ayele et al.\\n[15] Bevendorff, J., Wiegmann, M., Karlgren, J., Dürlich, L., Gogoulou, E., Talman, A.,\\nStamatatos, E., Potthast, M., Stein, B.: Overview of the “Voight-Kampff” Generative AI\\nAuthorship Verification Task at PAN and ELOQUENT 2024. Working Notes of CLEF 2024,\\nCEUR Workshop Proceedings (2024)\\n[16] Bobrovnyk, K.: Automated building and analysis of ukrainian twitter corpus for toxic text\\ndetection. In: COLINS 2019. Volume II: Workshop (2019), URL https://ena.lpnu.ua:\\n8443/server/api/core/bitstreams/c4c645c1-f465-4895-98dd-765f862cf186/content\\n[17] Brundage, M., Avin, S., Clark, J., Toner, H., Eckersley, P., Garfinkel, B., Dafoe, A., Scharre,\\nP., Zeitzoff, T., Filar, B., Anderson, H.S., Roff, H., Allen, G.C., Steinhardt, J., Flynn, C.,\\nhÉigeartaigh, S.Ó., Beard, S., Belfield, H., Farquhar, S., Lyle, C., Crootof, R., Evans, O.,\\nPage, M., Bryson, J., Yampolskiy, R., Amodei, D.: The malicious use of artificial\\nintelligence: Forecasting, prevention, and mitigation. CoRR abs/1802.07228 (2018)\\n[18] Cao, H., Han, Z., Ye, J., Liu, B., Han, Y.: Enhancing Human-Machine Authorship\\nDiscrimination in Generative AI Verification Task with BERT and Augmented Data.\\nWorking Notes of CLEF 2024, CEUR-WS.org (2024)\\n[19] Chen, J., Kong, L.: Integrating Dual BERT Models and Causal Language Models for\\nEnhanced Detection of Machine-Generated Texts. Working Notes of CLEF 2024,\\nCEUR-WS.org (2024)\\n[20] Chen, Z., Han, Y., Yi, Y.: Team chen at PAN: Integrating R-Drop and Pre-trained\\nLanguage Model for Multi-author Writing Style Analysis. Working Notes of CLEF 2024,\\nCEUR-WS.org (2024)\\n[21] Chicco, D., Tötsch, N., Jurman, G.: The Matthews correlation coefficient (MCC) is more\\nreliable than balanced accuracy, bookmaker informedness, and markedness in two-class\\nconfusion matrix evaluation. BioData Mining 14(1), 13 (Feb 2021), ISSN 1756-0381,\\nhttps://doi.org/10.1186/s13040-021-00244-z\\n[22] Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán, F., Grave,\\nE., Ott, M., Zettlemoyer, L., Stoyanov, V.: Unsupervised cross-lingual representation\\nlearning at scale. Proceedings of the 58th ACL, ACL (2020),\\nhttps://doi.org/10.18653/V1/2020.ACL-MAIN.747\\n[23] Da San Martino, G., Barrón-Cedeño, A., Wachsmuth, H., Petrov, R., Nakov, P.:\\nSemEval-2020 Task 11: Detection of Propaganda Techniques in News Articles. In:\\nProceedings of the Fourteenth Workshop on Semantic Evaluation, pp. 1377–1414,\\nInternational Committee for Computational Linguistics, Barcelona (online) (2020),\\nhttps://doi.org/10.18653/v1/2020.semeval-1.186, URL\\nhttps://aclanthology.org/2020.semeval-1.186\\n[24] Da San Martino, G., Yu, S., Barrón-Cedeño, A., Petrov, R., Nakov, P.: Fine-Grained\\nAnalysis of Propaganda in News Articles. In: Proceedings of the 2019 Conference on\\nEmpirical Methods in Natural Language Processing and the 9th International Joint\\nConference on Natural Language Processing (EMNLP-IJCNLP), pp. 5636–5646, Association\\nfor Computational Linguistics, Hong Kong, China (Nov 2019),\\nhttps://doi.org/10.18653/v1/D19-1565, URL https://aclanthology.org/D19-1565\\n[25] Damian, S., Herrera-Gonzalez, B., Vazquez-Santana, D., Calvo, H., Felipe-Riverón, E.,\\nYáñez-Márquez, C.: DSVS at PAN 2024: Ensemble Approach of Large Language Models for\\nAnalyzing Conspiracy Theories Against Critical Thinking Narratives. Working Notes of\\nCLEF 2024, CEUR-WS.org (2024)\\n[26] Dementieva, D., Babakov, N., Panchenko, A.: Multiparadetox: Extending text detoxification\\nwith parallel data to new languages. arXiv preprint arXiv:2404.02037 (2024)\\n[27] Dementieva, D., Logacheva, V., Nikishina, I., Fenogenova, A., Dale, D., Krotova, I.,\\nSemenov, N., Shavrina, T., Panchenko, A.: RUSSE-2022: Findings of the First Russian\\nDetoxification Shared Task Based on Parallel Corpora. COMPUTATIONAL LINGUISTICS\\nAND INTELLECTUAL TECHNOLOGIES (2022), URL\\nhttps://api.semanticscholar.org/CorpusID:253169495\\n[28] Dementieva, D., Ustyantsev, S., Dale, D., Kozlova, O., Semenov, N., Panchenko, A.,\\nLogacheva, V.: Crowdsourcing of parallel corpora: the case of style transfer for\\ndetoxification. Proceedings of the 2nd Crowd Science Workshop: Trust, Ethics, and\\nExcellence in Crowdsourced Data Management at Scale co-located with 47th International\\nConference on Very Large Data Bases (VLDB 2021), CEUR Workshop Proceedings (2021),\\nURL https://ceur-ws.org/Vol-2932/paper2.pdf\\n[29] Douglas, K.M., Sutton, R.M.: What are conspiracy theories? a definitional approach to their\\ncorrelates, consequences, and communication. Annual Review of Psychology 74(1), 271–298\\n(2023), URL https://doi.org/10.1146/annurev-psych-032420-031329\\n[30] Espinosa, D., Sidorov, G., Ricárdez-Vázquez, E.: Using BERT to Identify Conspiracy\\nTheories. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[31] Feng, F., Yang, Y., Cer, D., Arivazhagan, N., Wang, W.: Language-agnostic BERT sentence\\nembedding. Proceedings of the 60th ACL, ACL (2022),\\nhttps://doi.org/10.18653/V1/2022.ACL-LONG.62\\n[32] Fröbe, M., Wiegmann, M., Kolyada, N., Grahm, B., Elstner, T., Loebe, F., Hagen, M.,\\nStein, B., Potthast, M.: Continuous Integration for Reproducible Shared Tasks with\\nTIRA.io. Advances in Information Retrieval. 45th European Conference on IR Research\\n(ECIR 2023), Springer (2023)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 20}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 21\\n[33] Gambini, M., Tardelli, S., Tesconi, M.: The anatomy of conspiracy theorists: Unveiling\\ntraits using a comprehensive twitter dataset. Computer Communications 217, 25–40 (2024),\\nhttps://doi.org/10.1016/j.comcom.2024.01.027\\n[34] Gangopadhyay, S., Khan, M., Jabeen, H.: HybridDetox: Combining Supervised and\\nUnsupervised Methods for Effective Multilingual Text Detoxification. Working Notes of\\nCLEF 2024, CEUR-WS.org (2024)\\n[35] Giachanou, A., Ghanem, B., Rosso, P.: Detection of conspiracy propagators using\\npsycho-linguistic characteristics. Journal of Information Science 49(1), 3–17 (2023),\\nhttps://doi.org/10.1177/0165551520985486\\n[36] Gómez-Romero, J., González-Silot, S., Montoro-Montarroso, A., Molina-Solana, M.,\\nMartínez Cámara, E.: Detection of conspiracy-related messages in Telegram with\\nanonymized named entities. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[37] Gritsai, G., Boyeva, G., Grabovoy, A.: Team ap-team at PAN: LLM Adapters for Various\\nDatasets. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[38] Guo, L., Yang, W., Ma, L., Ruan, J.: BLGAV: Generative AI Author Verification Model\\nBased on BERT and BiLSTM. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[39] Guo, M., Han, Z., Chen, H., Peng, J.: A Machine-Generated Text Detection Model Based on\\nText Multi-Feature Fusion. Working Notes of CLEF 2024, CEUR-WS.org (Sep 2024)\\n[40] Haddad, H., Mulki, H., Oueslati, A.: T-hsab: A tunisian hate speech and abusive dataset.\\nIn: International conference on Arabic language processing, pp. 251–263, Springer (2019)\\n[41] Halvani, O., Winter, C., Graner, L.: On the usefulness of compression models for authorship\\nverification. In: Proceedings of the 12th International Conference on Availability, Reliability\\nand Security, vol. Part F1305, ACM, New York, NY, USA (29 Aug 2017), ISBN\\n9781450352574, https://doi.org/10.1145/3098954.3104050\\n[42] Hans, A., Schwarzschild, A., Cherepanova, V., Kazemi, H., Saha, A., Goldblum, M.,\\nGeiping, J., Goldstein, T.: Spotting LLMs with Binoculars: Zero-shot detection of\\nmachine-generated text. arXiv [cs.CL] (22 Jan 2024)\\n[43] Hong, J., Lee, N., Thorne, J.: ORPO: monolithic preference optimization without reference\\nmodel. CoRR abs/2403.07691 (2024), https://doi.org/10.48550/ARXIV.2403.07691, URL\\nhttps://doi.org/10.48550/arXiv.2403.07691\\n[44] Hu, Q., Han, Z., Peng, J., Guo, M., Liu, C.: An Oppositional Thinking Analysis Method\\nUsing BERT-based Model with BiGRU. Working Notes of CLEF 2024, CEUR-WS.org\\n(2024)\\n[45] Huang, B., Zhong, C., Yan, K., Han, Y.: Author authentication of generative AI based on\\nBERT by regularization method. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[46] Huang, J., Chen, Y., Luo, M., Li, Y.: Generative AI Authorship Verification Of Tri-Sentence\\nAnalysis Base On The Bert Model. Working Notes of CLEF 2024, CEUR-WS.org (Sep 2024)\\n[47] Huang, J., Han, Z., Zhu, R., Guo, M., Sun, K.: Conspiracy Theory Text Classification Based\\non CT-BERT and BETO Models. Working Notes of CLEF 2024, CEUR-WS.org (Sep 2024)\\n[48] Huang, K., Qi, H., Yan, K.: Voight-Kampff Generative AI Authorship Verification based on\\nContrastive Learning and Domain Adaptation. Working Notes of CLEF 2024,\\nCEUR-WS.org (Sep 2024)\\n[49] Huang, W., Grieve, J.: Authorial Language Models For AI Authorship Verification. Working\\nNotes of CLEF 2024, CEUR-WS.org (2024)\\n[50] Huang, Z., Kong, L.: Team huangzhijian at PAN: DeBERTa-v3 with R-Drop Regularization\\nfor Multi-Author Writing Style Analysis. Working Notes of CLEF 2024, CEUR-WS.org\\n(2024)\\n[51] Huertas-García, Á., Martí-González, C., Muñoz, J., Ambite, E.: Small Language Models and\\nLarge Language Models in Oppositional thinking analysis: Capabilities and Biases and\\nChallenges. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[52] Jiang, A.Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.S., Casas, D.d.l.,\\nBressand, F., Lengyel, G., Lample, G., Saulnier, L., Lavaud, L.R., Lachaux, M.A., Stock, P.,\\nScao, T.L., Lavril, T., Wang, T., Lacroix, T., Sayed, W.E.: Mistral 7B. arXiv [cs.CL]\\n(10 Oct 2023)\\n[53] Jigsaw: Toxic comment classification challenge.\\nhttps://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge (2017), accessed:\\n2024-03-18\\n[54] Karlgren, J., Dürlich, L., Gogoulou, E., Guillou, L., Nivre, J., Sahlgren, M., Talman, A.:\\nELOQUENT CLEF Shared Tasks for Evaluation of Generative Language Model Quality:\\n46th European Conference on Information Retrieval (ECIR), Springer Nature Switzerland\\n(2024), https://doi.org/10.1007/978-3-031-56069-9_63\\n[55] Kestemont, M., Tschuggnall, M., Stamatatos, E., Daelemans, W., Specht, G., Stein, B.,\\nPotthast, M.: Overview of the Author Identification Task at PAN 2018: Cross-domain\\nAuthorship Attribution and Style Change Detection. In: Working Notes of CLEF 2018,\\nCEUR-WS.org (2018)\\n[56] Khan, A., Rai, M., Khan, K., Shah, S., Alvi, F., Samad, A.: Team Gladiators at PAN:\\nImproving Author Identification: A Comparative Analysis of Pre-Trained Transformers for\\nMulti-Author Classification. Working Notes of CLEF 2024, CEUR-WS.org (2024)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 21}},\n",
              " {'text': '22 Ayele et al.\\n[57] King, J., Baffour, P., Crossley, S., Holbrook, R., Demkin, M.: Llm – detect ai generated text\\n(2023), URL https://kaggle.com/competitions/llm-detect-ai-generated-text\\n[58] Koppel, M., Schler, J.: Authorship verification as a one-class classification problem. In:\\nTwenty-first international conference on Machine learning - ICML ’04, pp. 489–495, ACM\\nPress, New York, New York, USA (2004), ISBN 9781581138283,\\nhttps://doi.org/10.1145/1015330.1015448\\n[59] Koppel, M., Winter, Y.: Determining if two documents are written by the same author.\\nJournal of the Association for Information Science and Technology 65(1), 178–187 (2014)\\n[60] Korenčić, D., Chulvi, B., Bonet, X., Mariona, T., Toselli, A., Rosso, P.: What distinguishes\\nconspiracy from critical narratives? a computational analysis of oppositional discourse.\\nexpert systems. Expert System (2024)\\n[61] Korenčić, D., Chulvi, B., Bonet Casals, X., Taulé, M., Rosso, P., Rangel, F.: Overview of\\nthe oppositional thinking analysis pan task at clef 2024. In: Faggioli, G., Ferro, N.,\\nGaluščáková, P., de Herrera, A.G.S. (eds.) Working Notes of CLEF 2024 – Conference and\\nLabs of the Evaluation Forum (2024)\\n[62] Korenčić, D., Grubišić, I., Toselli, A.H., Chulvi, B., Rosso, P.: Tackling Covid-19\\nConspiracies on Twitter using BERT Ensembles, GPT-3 Augmentation, and Graph NNs. In:\\nWorking Notes Proceedings of the MediaEval 2022 Workshop Bergen, Norway and Online\\n(2023), URL https://2022.multimediaeval.com/paper8969.pdf\\n[63] Ksi¸ eżniak, E., W¸ ecel, K., Sawiński, M.: Team OpenFact at PAN 2024: Fine-Tuning BERT\\nModels with Stylometric Enhancements. Working Notes of CLEF 2024, CEUR-WS.org\\n(2024)\\n[64] Kumar, S., Balachandran, V., Njoo, L., Anastasopoulos, A., Tsvetkov, Y.: Language\\ngeneration models can cause harm: So what can we do about it? an actionable survey.\\nCoRR abs/2210.07700 (2022)\\n[65] Lei, H., Liu, X., Niu, G., Zhou, Y., Zhou, Y.: Generative AI Authorship Verification based\\non ChatGLM. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[66] Liang, X., Lei, H.: Team lxflcl66666 at PAN: Fine-Tuned Reasoning for Writing Style\\nAnalysis. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[67] Liang, X., Wu, L., Li, J., Wang, Y., Meng, Q., Qin, T., Chen, W., Zhang, M., Liu, T.:\\nR-drop: Regularized dropout for neural networks. In: 34th Annual Conference on Neural\\nInformation Processing Systems 2021, NeurIPS (2021)\\n[68] Lin, T., Wu, Y., Lee, L.: Team NYCU-NLP at PAN 2024: Integrating Transformers with\\nSimilarity Adjustments for Multi-Author Writing Style Analysis. Working Notes of CLEF\\n2024, CEUR-WS.org (2024)\\n[69] Lin, Z., Han, Z., Kong, L., Chen, M., Zhang, S., Peng, J., Sun, K.: A Verifying Generative\\nText Authorship Model With Regularized Dropout. Working Notes of CLEF 2024,\\nCEUR-WS.org (2024)\\n[70] Lin, Z., Li, Y., Huang, J.: Voight-Kampff Generative AI Authorship Verification Based on\\nT5. Working Notes of CLEF 2024, CEUR-WS.org (Sep 2024)\\n[71] Liu, B., Han, Z., Cao, H.: An Approach to Classifying Conspiratorial and Critical Public\\nHealth Narratives. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[72] Liu, C., Han, Z., Chen, H., Hu, Q.: Team liuc0757 at PAN: A Writing Style Embedding\\nMethod Based on Contrastive Learning for Multi-Author Writing Style Analysis. Working\\nNotes of CLEF 2024, CEUR-WS.org (Sep 2024)\\n[73] Liu, X., Chen, H., Lv, J.: Team foshan-university-of-guangdong at PAN: Adaptive\\nEntropy-Based Stability-Plasticity for Multi-Author Writing Style Analysis. Working Notes\\nof CLEF 2024, CEUR-WS.org (Sep 2024)\\n[74] Liu, X., Kong, L.: AI Text Detection Method Based on Perplexity Features with Strided\\nSliding Window. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[75] Logacheva, V., Dementieva, D., Ustyantsev, S., Moskovskiy, D., Dale, D., Krotova, I.,\\nSemenov, N., Panchenko, A.: ParaDetox: Detoxification with parallel data. In: Muresan, S.,\\nNakov, P., Villavicencio, A. (eds.) Proceedings of the 60th Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 1: Long Papers), pp. 6804–6818,\\nAssociation for Computational Linguistics, Dublin, Ireland (May 2022),\\nhttps://doi.org/10.18653/v1/2022.acl-long.469, URL\\nhttps://aclanthology.org/2022.acl-long.469\\n[76] Lorenz, L., Aygüler, F.Z., Schlatt, F., Mirzakhmedova, N.: BaselineAvengers at PAN 2024:\\nOften-Forgotten Baselines for LLM-Generated Text Detection. Working Notes of CLEF\\n2024, CEUR-WS.org (2024)\\n[77] Lu, J., Xu, B., Zhang, X., Min, C., Yang, L., Lin, H.: Facilitating fine-grained detection of\\nChinese toxic language: Hierarchical taxonomy, resources, and benchmarks. In: Rogers, A.,\\nBoyd-Graber, J., Okazaki, N. (eds.) Proceedings of the 61st Annual Meeting of the\\nAssociation for Computational Linguistics, pp. 16235–16250 (Jul 2023), URL\\nhttps://aclanthology.org/2023.acl-long.898\\n[78] Luo, Z., Luo, M., Wang, A.: Multilingual Text Detoxification Using Google Cloud\\nTranslation and Post-Processing. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[79] Lv, J., Han, Y., Kong, L.: Meta-Contrastive Learning for Generative AI Authorship\\nVerification. Working Notes of CLEF 2024, CEUR-WS.org (2024)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 22}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 23\\n[80] Lv, J., Yi, Y., Qi, H.: Team Fosu-stu at PAN: Supervised fine-tuning of large language\\nmodels for Multi Author Writing Style Analysis. Working Notes of CLEF 2024,\\nCEUR-WS.org (Sep 2024)\\n[81] Mahesh, S., Divakaran, S., Girish, K., Lakshmaiah, S.: Binary Battle: Leveraging ML and\\nTL Models to Distinguish between Conspiracy Theories and Critical Thinking. Working\\nNotes of CLEF 2024, CEUR-WS.org (2024)\\n[82] Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C., Patel, A.: Overview\\nof the hasoc track at fire 2019: Hate speech and offensive content identification in\\nindo-european languages. In: Proceedings of the 11th Annual Meeting of the Forum for\\nInformation Retrieval Evaluation, p. 14–17, FIRE ’19, ACM (2019), ISBN 9781450377508,\\nhttps://doi.org/10.1145/3368567.3368584\\n[83] Mathet, Y., Widlöcher, A., Métivier, J.P.: The Unified and Holistic Method Gamma for\\nInter-Annotator Agreement Measure and Alignment. Computational Linguistics 41(3),\\n437–479 (Sep 2015), ISSN 0891-2017, https://doi.org/10.1162/COLI_a_00227, URL\\nhttps://doi.org/10.1162/COLI_a_00227\\n[84] Miralles, P., Martín, A., Camacho, D.: Ensembling Normalized Log Probabilities. Working\\nNotes of CLEF 2024, CEUR-WS.org (2024)\\n[85] Mitchell, E., Lee, Y., Khazatsky, A., Manning, C.D., Finn, C.: DetectGPT: Zero-shot\\nmachine-generated text detection using probability curvature. International Conference on\\nMachine Learning 202, 24950–24962 (26 Jan 2023),\\nhttps://doi.org/10.48550/arXiv.2301.11305\\n[86] MTS.AI: Cotype: Generative ai solutions (2022), URL https://mts.ai, accessed: 2024-05-31\\n[87] Mubarak, H., Darwish, K., Magdy, W., Elsayed, T., Al-Khalifa, H.: Overview of osact4\\narabic offensive language detection shared task. In: Proceedings of the 4th Workshop on\\nopen-source arabic corpora and processing tools, with a shared task on offensive language\\ndetection, pp. 48–52 (2020)\\n[88] Muennighoff, N., Wang, T., Sutawika, L., Roberts, A., Biderman, S., Scao, T.L., Bari, M.S.,\\nShen, S., Yong, Z.X., Schoelkopf, H., Tang, X., Radev, D., Aji, A.F., Almubarak, K.,\\nAlbanie, S., Alyafeai, Z., Webson, A., Raff, E., Raffel, C.: Crosslingual generalization\\nthrough multitask finetuning. In: Proceedings of the 61st ACL, ACL (2023),\\nhttps://doi.org/10.18653/V1/2023.ACL-LONG.891\\n[89] Mulki, H., Ghanem, B.: Let-mi: An Arabic Levantine Twitter dataset for misogynistic\\nlanguage. In: Habash, N., Bouamor, H., Hajj, H., Magdy, W., Zaghouani, W., Bougares, F.,\\nTomeh, N., Abu Farha, I., Touileb, S. (eds.) Proceedings of the Sixth Arabic Natural\\nLanguage Processing Workshop, pp. 154–163, Association for Computational Linguistics,\\nKyiv, Ukraine (Virtual) (Apr 2021), URL https://aclanthology.org/2021.wanlp-1.16\\n[90] Mulki, H., Haddad, H., Ali, C.B., Alshabani, H.: L-hsab: A levantine twitter dataset for\\nhate speech and abusive language. In: Proceedings of the third workshop on abusive\\nlanguage online, pp. 111–118 (2019)\\n[91] Najafi, M., Tavan, E., Colreavy, S.: Marsan at PAN 2024 TextDetox: ToxiCleanse RL and\\nPaving the Way for Toxicity-Free Online Discourse. Working Notes of CLEF 2024,\\nCEUR-WS.org (2024)\\n[92] OpenAI: Chatgpt: Optimizing language models for dialogue (2022), URL\\nhttps://openai.com/blog/chatgpt, accessed: 2024-05-31\\n[93] Osipenko, M., Korchagin, M., Toleugazinov, A., Egorov, S., Udobang, J.: Fancy\\nTransformers at PAN 2024 TextDetox: Surpassing the Baselines. Working Notes of CLEF\\n2024, CEUR-WS.org (2024)\\n[94] Ostrower, B., Wessell, J., Bindal, A.: AI Authorship Verification: An Ensembled Approach.\\nWorking Notes of CLEF 2024, CEUR-WS.org (2024)\\n[95] Peng, J., Han, Z., Zhang, H., Ye, J., Liu, C., Liu, B., Guo, M., Chen, H., Lin, Z., Tang, Y.:\\nA Multilingual Text Detoxification Method Based on Few-shot Learning and CO-STAR\\nFramework. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[96] Pereira-Kohatsu, J.C., Sánchez, L.Q., Liberatore, F., Camacho-Collados, M.: Detecting and\\nmonitoring hate speech in twitter. Sensors 19(21), 4654 (2019),\\nhttps://doi.org/10.3390/S19214654, URL https://doi.org/10.3390/s19214654\\n[97] Pérez, J.M., Furman, D.A., Alonso Alemany, L., Luque, F.M.: RoBERTuito: a pre-trained\\nlanguage model for social media text in Spanish. Proceedings of the 13th LREC, ELRA\\n(2022), URL https://aclanthology.org/2022.lrec-1.785\\n[98] Petropoulos, P., Petropoulos, V.: RoBERTa and Bi-LSTM for Human vs AI generated Text\\nDetection. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[99] Pletenev, S.: Memu_pro_kotow at PAN 2024 TextDetox: Uncensored Llama3 Helps to\\nCensor Better. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[100] Pogorelov, K., Schroeder, D.T., Brenner, S., Langguth, J.: FakeNews: Corona Virus and\\nConspiracies Multimedia Analysis Task at MediaEval 2021. In: Working Notes Proceedings\\nof the MediaEval 2021 Workshop Bergen, Norway and Online (2021)\\n[101] Pogorelov, K., Schroeder, D.T., Brenner, S., Maulana, A., Langguth, J.: Combining tweets\\nand connections graph for fakenews detection at mediaeval 2022. In: Proceedings of the\\nMediaEval 2022 Workshop, Bergen, Norway and Online, 12-13 January 2023. (2023)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 23}},\n",
              " {'text': '24 Ayele et al.\\n[102] Protasov, V.: PAN 2024 Multilingual TextDetox: Exploring Cross-lingual Transfer in Case\\nof Large Language Models. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[103] Qin, R., Qi, H., Yi, Y.: A model fusion approach for generative AI authorship verification.\\nWorking Notes of CLEF 2024, CEUR-WS.org (2024)\\n[104] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., Liu,\\nP.J.: Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv\\n[cs.LG] (23 Oct 2019)\\n[105] Řehulka, E., Šuppa, M.: RAG Meets Detox: Enhancing Text Detoxification Using\\nOpen-Source Large Language Models with Retrieval Augmented Generation. Working Notes\\nof CLEF 2024, CEUR-WS.org (2024)\\n[106] Risch, J., Stoll, A., Wilms, L., Wiegand, M.: Overview of the GermEval 2021 Shared Task\\non the Identification of Toxic, Engaging, and Fact-Claiming Comments. In: Proceedings of\\nthe GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming\\nComments, pp. 1–12, Duesseldorf, Germany (2021)\\n[107] Ross, B., Rist, M., Carbonell, G., Cabrera, B., Kurowsky, N., Wojatzki, M.: Measuring the\\nReliability of Hate Speech Annotations: The Case of the European Refugee Crisis.\\nProceedings of NLP4CMC III: 3rd Workshop on Natural Language Processing for\\nComputer-Mediated Communication, Bochumer Linguistische Arbeitsberichte, vol. 17, pp.\\n6–.9, Bochum, Germany (2016)\\n[108] Rosso, P., Rangel, F., Potthast, M., Stamatatos, E., Tschuggnall, M., Stein, B.: Overview of\\nPAN’16—New Challenges for Authorship Analysis: Cross-genre Profiling, Clustering,\\nDiarization, and Obfuscation. In: Experimental IR Meets Multilinguality, Multimodality,\\nand Interaction. 7th International Conference of the CLEF Initiative (CLEF 16) (2016)\\n[109] Ruffo, G., Semeraro, A., Giachanou, A., Rosso, P.: Studying fake news spreading,\\npolarisation dynamics, and manipulation by bots: A tale of networks and language.\\nComputer Science Review 47, 100531 (2023), ISSN 1574-0137,\\nhttps://doi.org/https://doi.org/10.1016/j.cosrev.2022.100531, URL\\nhttps://www.sciencedirect.com/science/article/pii/S157401372200065X\\n[110] Rykov, E., Zaytsev, K., Anisimov, I., Voronin, A.: SmurfCat at PAN TexDetox 2024:\\nAlignment of Multilingual Transformers for Text Detoxification. Working Notes of CLEF\\n2024, CEUR-WS.org (2024)\\n[111] Sahitaj, A., Sahitaj, P., Mohtaj, S., Möller, S., Schmitt, V.: Towards a Computational\\nFramework for Distinguishing Critical and Conspiratorial Texts by Elaborating on the\\nContext and Argumentation with LLMs. Working Notes of CLEF 2024, CEUR-WS.org\\n(2024)\\n[112] Sánchez-Hermosilla, I., Panizo Lledot, A., Camacho, D.: A Study on NLP Model Ensembles\\nand Data Augmentation Techniques for Separating Critical Thinking from Conspiracy\\nTheories in English Texts. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[113] Sanjesh, R., Mangai, A.: Team riyasanjesh at PAN: Multi-feature with CNN and Bi-LSTM\\nNeural Network approach to Style Change Detection. Working Notes of CLEF 2024,\\nCEUR-WS.org (2024)\\n[114] Sculley, D., Brodley, C.E.: Compression and machine learning: A new perspective on feature\\nspace vectors. In: Data Compression Conference (DCC’06), pp. 332–341, IEEE (2006), ISBN\\n9780769525457, ISSN 1068-0314,2375-0359, https://doi.org/10.1109/dcc.2006.13\\n[115] Semiletov, A.: Toxic Russian Comments: Labelled comments from the popular Russian\\nsocial network. https://www.kaggle.com/alexandersemiletov/toxic-russian-comments (2020),\\naccessed: 2023-12-14\\n[116] Sheykhlan, M., Abdoljabbar, S., Mahmoudabad, M.: Team karami-kheiri at PAN:\\nEnhancing Machine-Generated Text Detection with Ensemble Learning Based on\\nTransformer Models. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[117] Sheykhlan, M., Abdoljabbar, S., Mahmoudabad, M.: Team karami-sh at PAN:\\nTransformer-based Ensemble Learning for Multi-Author Writing Style Analysis. Working\\nNotes of CLEF 2024, CEUR-WS.org (Sep 2024)\\n[118] Stamatatos, E., Kestemont, M., Kredens, K., Pezik, P., Heini, A., Bevendorff, J., Potthast,\\nM., Stein, B.: Overview of the Authorship Verification Task at PAN 2022. In: CLEF 2022\\nLabs and Workshops, CEUR-WS.org (2022)\\n[119] Stamatatos, E., Potthast, M., Pardo, F.M.R., Rosso, P., Stein, B.: Overview of the\\nPAN/CLEF 2015 evaluation lab. Experimental IR Meets Multilinguality, Multimodality,\\nand Interaction - 6th International Conference of the CLEF Association, CLEF 2015,\\nSpringer (2015)\\n[120] Su, J., Zhuo, T.Y., Wang, D., Nakov, P.: DetectLLM: Leveraging log rank information for\\nzero-shot detection of machine-generated text. arXiv [cs.CL] (23 May 2023)\\n[121] Su, Y., Lan, T., Wang, Y., Yogatama, D., Kong, L., Collier, N.: A contrastive framework for\\nneural text generation. arXiv [cs.CL] (13 Feb 2022)\\n[122] Sun, G., Yang, W., Ma, L.: BCAV: A Generative AI Author Verification Model Based on\\nthe Integration of Bert and CNN. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[123] Sushko, N.: PAN 2024 Multilingual TextDetox: Exploring Different Regimes For Synthetic\\nData Training For Multilingual Text Detoxification. Working Notes of CLEF 2024,\\nCEUR-WS.org (2024)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 24}},\n",
              " {'text': 'Overview of PAN 2024: Condensed Lab Overview 25\\n[124] Taulé, M., Nofre, M., Bargiela, V., Bonet, X.: Newscom-tox: a corpus of comments on news\\narticles annotated for toxicity in spanish. LREC (2024)\\n[125] Tavan, E., Najafi, M.: Marsan at PAN: BinocularLLM and Fusing Binoculars’ Insight with\\nthe Proficiency of Large Language Models for Cutting-Edge Machine-Generated Text\\nDetection. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[126] Tian, Y., Chen, H., Wang, X., Bai, Z., Zhang, Q., Li, R., Xu, C., Wang, Y.: Multiscale\\npositive-unlabeled detection of ai-generated texts. CoRR abs/2305.18149 (2023),\\nhttps://doi.org/10.48550/ARXIV.2305.18149\\n[127] Tschuggnall, M., Stamatatos, E., Verhoeven, B., Daelemans, W., Specht, G., Stein, B.,\\nPotthast, M.: Overview of the author identification task at PAN 2017: style breach\\ndetection and author clustering. In: CLEF 2017 Labs and Workshops (2017)\\n[128] Tulbure, A., Coll Ardanuy, M.: Conspiracy vs critical thinking using an ensemble of\\ntransformers with data augmentation techniques. Working Notes of CLEF 2024,\\nCEUR-WS.org (2024)\\n[129] Valdez-Valenzuela, A., Gómez-Adorno, H.: Team iimasnlp at PAN: Leveraging Graph\\nNeural Networks and Large Language Models for Generative AI Authorship Verification.\\nWorking Notes of CLEF 2024, CEUR-WS.org (2024)\\n[130] Vallecillo-Rodríguez, M., Martín-Valdivia, A.M.: SINAI at PAN 2024 TextDetox:\\nApplication of Tree of Thought Strategy in Large Language Models for Multilingual Text\\nDetoxification. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[131] Vallecillo-Rodríguez, M., Martín-Valdivia, M., Montejo-Ráez, A.: SINAI at PAN 2024\\nOppositional Thinking Analysis: Exploring the fine-tuning performance of LLMs. Working\\nNotes of CLEF 2024, CEUR-WS.org (2024)\\n[132] Weimer, A.M., Barth, F., Dönicke, T., Gödeke, L., Varachkina, H., Holler, A., Sporleder, C.,\\nGittel, B.: The (In-)Consistency of Literary Concepts. Operationalising, Annotating and\\nDetecting Literary Comment. Journal of Computational Literary Studies 1(1) (Dec 2022),\\nISSN 2940-1348, https://doi.org/10.48694/jcls.90, URL https://jcls.io/article/id/90/,\\nnumber: 1 Publisher: Universitäts- und Landesbibliothek Darmstadt\\n[133] Wiegand, M., Siegel, M., Ruppenhofer, J.: Overview of the GermEval 2018 Shared Task on\\nthe Identification of Offensive Language (2018)\\n[134] Wu, B., Han, Y., Yan, K., Qi, H.: Team baker at PAN: Enhancing Writing Style Change\\nDetection with Virtual Softmax. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[135] Wu, Q., Kong, L., Ye, Z.: Team bingezzzleep at PAN: A Writing Style Change Analysis\\nModel Based on RoBERTa Encoding and Contrastive Learning for Multi-Author Writing\\nStyle Analysis. Working Notes of CLEF 2024, CEUR-WS.org (Sep 2024)\\n[136] Wu, Z., Yang, W., Ma, L., Zhao, Z.: BertT: A Hybrid Neural Network Model for Generative\\nAI Authorship Verification. Working Notes of CLEF 2024, CEUR-WS.org (Sep 2024)\\n[137] Xue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., Siddhant, A., Barua, A., Raffel,\\nC.: mt5: A massively multilingual pre-trained text-to-text transformer. Proceedings of the\\nNAACL-HLT 2021, ACL, https://doi.org/10.18653/V1/2021.NAACL-MAIN.41, URL\\nhttps://doi.org/10.18653/v1/2021.naacl-main.41\\n[138] Yadagiri, A., Kalita, D., Ranjan, A., Bostan, A., Toppo, P., Pakray, P.: Team cnlp-nits-pp\\nat PAN: Leveraging BERT for Accurate Authorship Verification: A Novel Approach to\\nTextual Attribution. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[139] Ye, Z., Zhong, Y., Huang, C., Kong, L.: Team no-999 at PAN: Continual Transfer Learning\\nwith Progress Prompt for Multi-Author Writing Style Analysis\". Working Notes of CLEF\\n2024, CEUR-WS.org (2024)\\n[140] Ye, Z., Zhong, Y., Huang, Z., Kong, L.: Token Prediction as Implicit Classification for\\nGenerative AI Authorship Verification. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[141] Zangerle, E., Mayerl, M., , Potthast, M., Stein, B.: Overview of the Style Change Detection\\nTask at PAN 2021. In: Faggioli, G., Ferro, N., Joly, A., Maistro, M., Piroi, F. (eds.) CLEF\\n2021 Labs and Workshops, CEUR-WS.org (2021)\\n[142] Zangerle, E., Mayerl, M., , Potthast, M., Stein, B.: Overview of the Style Change Detection\\nTask at PAN 2022. In: CLEF 2022 Labs and Workshops, CEUR-WS.org (2022)\\n[143] Zangerle, E., Mayerl, M., , Potthast, M., Stein, B.: Overview of the Style Change Detection\\nTask at PAN 2023. In: CLEF 2023 Labs and Workshops, CEUR-WS.org (2023)\\n[144] Zangerle, E., Mayerl, M., Potthast, M., Stein, B.: Overview of the Multi-Author Writing\\nStyle Analysis Task at PAN 2024. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[145] Zangerle, E., Mayerl, M., Specht, G., Potthast, M., Stein, B.: Overview of the Style Change\\nDetection Task at PAN 2020. In: CLEF 2020 Labs and Workshops (2020)\\n[146] Zangerle, E., Tschuggnall, M., Specht, G., Stein, B., Potthast, M.: Overview of the Style\\nChange Detection Task at PAN 2019. In: CLEF 2019 Labs and Workshops (2019)\\n[147] Zeng, Z., Han, Z., Ye, J., Tan, Y., Cao, H., Li, Z., Huang, R.: A Conspiracy Theory Text\\nDetection Method based on RoBERTa and XLM-RoBERTa Models. Working Notes of\\nCLEF 2024, CEUR-WS.org (2024)\\n[148] Zhu, Y., Kong, L.: AI Authorship Verification Based On Deberta Model. Working Notes of\\nCLEF 2024, CEUR-WS.org (2024)\\n[149] Zinkovich, V., Karpukhin, S., Kurdiukov, N., Tikhomirov, P.: nlp_enjoyers at Multilingual\\nTextual Detoxification (CLEF-2024. Working Notes of CLEF 2024, CEUR-WS.org (2024)\\n[150] Zrnić, L.: Conspiracy theory detection using transformers with multi-task and multilingual\\napproaches. Working Notes of CLEF 2024, CEUR-WS.org (2024)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper1.pdf', 'page_number': 25}},\n",
              " {'text': 'Overview of the Multi-Author Writing Style Analysis Task\\nat PAN 2024\\nEva Zangerle1, Maximilian Mayerl2, Martin Potthast3and Benno Stein4\\n1University of Innsbruck\\n2University of Applied Sciences BFI Vienna\\n3University of Kassel, hessian.AI, and ScaDS.AI\\n4Bauhaus-Universität Weimar\\npan@webis.de https://pan.webis.de\\nAbstract\\nAnalyzing the writing style of individual authors in texts in which several authors are involved is a fundamental\\ntask in attributing authorship and detecting plagiarism, as it makes it possible to identify the points at which\\nauthorship changes. This year’s multi-author writing style analysis task focuses on identifying all instances of\\nparagraph-level writing style changes within a given text. We provide datasets with three different degrees of\\ntopical homogeneity to investigate how different degrees of topic consistency affect the detection of writing style\\nchanges. This paper gives an overview of the task, its definition and the data used, the approaches proposed by\\nthe participants, and the results obtained.\\n1. Introduction\\nWriting style analysis requires an intrinsic analysis of author writing styles: no information on author-\\nship from external sources is used. The core of intrinsic writing style analysis is the computation of\\nstylistic profiles on the basis of text features. By computing similarities between the profiles of text\\nsegments, changes in writing style can be detected, which is an indicator for a potential change in\\nauthorship [ 1,2]. Profiles are based on features that describe the writing style of authors, including\\n(1) lexical features (character n-grams (e.g., [3, 4, 5]), word frequencies (e.g., [6]), and average word or\\nsentence lengths (e.g., [ 7])), (2) syntactic features (such as part-of-speech tag frequencies and structures\\n(e.g., [ 8]), or grammar trees (e.g., [ 9])), or (3) structural features (e.g., indentation usage (e.g., [ 7])).\\nThese profiles are then used to match text fragments written by the same author [ 10], cluster authorial\\nthreads [11, 12, 13, 14], or to predict the number of authors [15].\\nThe multi-author writing style analysis task, formerly known as the style change detection task, has\\nbeen organized at PAN since 2016. Over the years, the tasks and the data used have constantly evolved.\\nHowever, the main objective has remained the same: analyzing authors’ writing styles to identify the\\npositions at which authorship changes in texts by multiple authors. Since the first edition in 2016, we\\nhave seen significant progress in the results.\\nIn the first editions of the PAN task in 2016, participants were asked to identify and cluster text\\nsegments by author [ 16]. In 2017, the aim was to recognize whether a document was written by several\\nauthors [ 17]; if there were several authors, the participants were asked to indicate the exact positions\\nof these changes. In 2018, the task was to distinguish between documents from single authors and\\ndocuments from multiple authors [ 18]. In 2019, the task was extended to also predict the number of\\nauthors [ 19]. Since 2020, style changes had to be identified at the paragraph level [ 20,21], and in 2021\\nalso the authors had to be assigned to paragraphs [ 21]. In 2022, the task was extended to detect changes\\nnot only at the paragraph level, but even at the sentence level [ 22], while in 2023 the recognition was\\nperformed at the paragraph level again [23].\\nIn recent years, large language models (LLMs) have made considerable progress; they are inherently\\nwell suited to analyzing writing styles with multiple authors. For example, while in 2018 the winning\\nCLEF 2024: Conference and Labs of the Evaluation Forum, September 09–12, 2024, Grenoble, France\\n©2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\\nCEURWorkshopProceedingsceur-ws.orgISSN 1613-0073',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper2.pdf', 'page_number': 1}},\n",
              " {'text': 'approach was based on the extraction of lexical and syntactic features [ 24] and a stacking ensemble\\nclassifier, from 2020 the majority of submitted approaches are based on LLMs fine-tuned on the training\\ndata [25, 26, 27, 28].\\nFor the 2024 edition of the writing style analysis task at PAN, we ask participants to detec any changes\\nin writing style at the paragraph level. We provide three datasets with increasing topical homogeneity\\nof the paragraphs and thus increasing difficulty.\\nThe remainder of this paper is structured as follows. Section 2 presents the PAN 2024 multi-author\\nwriting style analysis task, the data used, and the evaluation setup. Section 3 surveys the participants’\\nsubmissions, while Section 4 presents an analysis and comparison of the achieved results, and Section 5\\nconcludes the paper.\\n2. Style Change Detection Task\\n2.1. Task Definition\\nParticipants of this year’s multi-author writing style analysis task were asked to solve the following\\nintrinsic style change detection task: For a given text, find all positions of writing style change at\\nthe paragraph level, i.e., for each pair of consecutive paragraphs, assess whether there was a style\\nchange. We control the difficulty of the task by managing the variety of topics in the given documents.\\nParticipants are provided with data sets with three levels of difficulty:\\neasy The document covers a range of topics, allowing topical changes between paragraphs to be\\nused as style change signals.\\nmedium The document exhibits minimal topical variety (though some still exists), requiring the\\napproaches to focus on stylistic features for the task.\\nhard The paragraphs of a document all are on the same topic.\\n2.2. Dataset\\nContinuing our efforts from the 2023 competition, this year’s data set for the multi-author writing style\\nanalysis task is again based on user posts on Reddit, a popular social messaging platform.\\nFor the generation of the dataset, we selected a set of subreddits (topical sub-threads on Reddit)\\nthat we expected to yield longer and more detailed texts by individual users: r/worldnews ,r/politics ,\\nr/askhistorians , and r/legaladvice . After scraping these threads, we applied cleaning and preprocessing\\nsteps to the gathered texts. This included removing citations, markdown, emojis, hyperlinks, multiple\\nline breaks, and extra whitespace.\\nThe texts were divided into individual paragraphs. Paragraphs originating from the same Reddit\\nthread were combined into documents for the datasets, ensuring minimal topical coherence within each\\ndocument. Style changes were introduced by randomly selecting paragraphs from different authors\\nwithin the thread. To control for topical variability and thus the extent to which thematic aspects can\\nbe used as a style change signal (and thus the complexity of the task), we consider the semantic and\\nstylistic properties of the paragraphs. The paragraphs are arranged based on these pair-wise paragraph\\nsimilarities, configuring these similarities to be (1) “large” for the easy dataset, (2) “moderate” for the\\nmedium dataset, and (3) “small” for the hard dataset.\\nWe configured the dataset creation process to create documents written by two to four authors\\nto ensure an even distribution of documents according to the number of authors. Each of the three\\nresulting datasets contains 6,000 documents, each split into a training dataset (70% of all documents), a\\nvalidation dataset (15% of all documents), and a test dataset (15% of all documents), which is held back\\nuntil the evaluation phase of the task.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper2.pdf', 'page_number': 2}},\n",
              " {'text': '2.3. Performance Measures\\nWe evaluate the submitted approaches independently for each of the three datasets. Each approach is\\nevaluated using the 𝐹𝛼-Measure, where 𝛼= 1 weights the harmonic mean between precision and recall\\nequally, and the results are macro-averaged over all documents.\\nAll approaches are submitted on the TIRA platform [ 29], which allows participants to evaluate and\\noptimize their methods based on training, validation, and unseen test data. For the test data, blind\\nevaluation ensures that participants cannot optimize their approaches based on the test data.\\n3. Survey of Submissions\\nWe received 16 software submissions and 15 working note papers for the task of multi-author writing\\nstyle analysis in 2024. Below is a brief description of the submitted solutions.\\nLv et al. [ 30] leverage the decoder of LLaMA-3 to obtain vector representations of paragraph pairs,\\nsubsequently using these representations to perform binary classification via a feed-forward network.\\nTo increase the efficiency of their model training, they use a technique called low-rank adaptation.\\nLin et al. [ 31] use an ensemble of multiple transformer-based models (ReBERTa, DeBERTa, and\\nERNIE) to solve the task. Crucially, to improve performance for the easy and medium datasets, where\\ntopical variety within the documents is higher, they also perform a post-processing step based on\\nthe semantic similarity of two consecutive paragraphs for those two datasets; paragraphs with a high\\ndegree of semantic similarity are then deemed to have been written by the same author, irrespective of\\nthe predictions obtained from the transformer ensemble.\\nThe submission of Ye et al. [ 32] utilizes continual learning to approach the task. Their goal is to\\nachieve a knowledge transfer across different difficulty levels, using learned progress prompts to do so.\\nHuang and Kong [ 33] employ DeBERTa-v3 to fine-tune a model for this year’s task. To improve\\nthe performance of the model, they use regularized dropout during the fine-tuning process. They also\\nperform early stopping during the training process to prevent the model from overfitting.\\nThe approach by Huang and Kong [ 34] employs models of the BERT family to solve the task. Like\\nmost other participants, they fine-tuned the models on the training sets and then tested the performance\\nof various BERT-derived models on the validation set to decide on which model to use for the final\\nsubmission. Ultimately, they settled on DeBERTa for the easy and hard datasets, and on RoBERTa for\\nthe medium dataset.\\nWu, Kong, and Ye [ 35] use RoBERTa to encode the positive and negative sample paragraph pairs.\\nThey add a contrastive learning component to optimize the training process of RoBERTa that essentially\\naims to reduce the cosine distance of positive paragraph pairs while increasing the distance of negative\\nparagraph pairs.\\nLiu et al. [ 36] also employ contrastive learning for the encoding phase, using RoBERTa as the encoder.\\nFor each pair of paragraphs, they form a feature matrix, consisting of the latent representations of the\\ntwo paragraphs, and the absolute distance between the two embeddings. The feature matrix is then fed\\ninto a fully connected layer to compute the final prediction.\\nKsiężniak et al. [ 37] utilize RoBERTa and DeBERTa models for their solution. To give the models\\nadditional information they could use to determine style changes, they augmented the texts of the\\ndocuments with tags containing stylometric features.\\nChen, Hand, and Yi [ 38] use RoBERTa and for the fine-tuning phase, they employ R-Drop regulariza-\\ntion to mitigate overfitting and to ensure consistency that the model, given identical inputs, computes\\nconsistent predictions.\\nWu et al. [ 39] compared the performance of BERT, RoBERTa, and DistilBERT for task 1 and showed\\nthat RoBERTa achieved the best results. Consequently, they used RoBERTa for the encoding and feed the\\nresulting pooled contextual features into a Virtual Softmax layer to perform a three-class classification\\ntask, where the intuition behind introducing a third class is to enforce stricter boundary constraints\\nbetween the two original classes.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper2.pdf', 'page_number': 3}},\n",
              " {'text': 'Table 1\\nOverall results for the multi-author analysis task, ranked by average F 1performance across all three datasets.\\nBest results are marked in bold.\\nTeam Easy F 1Medium F 1Hard F 1\\nfosu-stu [30] 0.987 0.887 0.834\\nnycu-nlp [31] 0.964 0.857 0.863\\nno-999 [32] 0.991 0.830 0.832\\nhuangzhijian [33] 0.985 0.815 0.826\\ntext-understanding-and-analysi [34] 0.991 0.815 0.818\\nbingezzzleep [35] 0.985 0.818 0.807\\nopenfact [37] 0.981 0.821 0.805\\nchen [38] 0.968 0.822 0.807\\nbaker [39] 0.976 0.816 0.770\\ngladiators [40] 0.956 0.809 0.783\\nkhaldi-abderrahmane 0.905 0.806 0.641\\nkarami-sh [41] 0.972 0.664 0.642\\nriyahsanjesh [42] 0.825 0.712 0.599\\nliuc0757 [36] 0.696 0.717 0.503\\nlxflcl66666 [43] 0.606 0.455 0.484\\nfoshan-university-of-guangdong [44] 0.517 0.394 0.352\\nBaseline Predict 1 0.466 0.343 0.320\\nBaseline Predict 0 0.112 0.323 0.346\\nBaseline Random 0.414 0.506 0.495\\nKhan et al. [ 40] in a first step, performed weighted sampling on the data provided to achieve balanced\\nclasses. They then compared RoBERTa, Electra, DeBerta, and Squeeze-Bert models, where RoBERTa was\\nperforming best. To further enhance the performance, they augmented the provided data by swapping\\nall pairs of paragraphs between which no style change was detected and adding these paragraphs to\\nthe training data.\\nThe approach by Sheykhlanet al. [ 41] makes use of fine-tuned transformer models, namely BERT,\\nRoBERTa, and ELECTRA, to detect style changes. They opted to use different combinations of models\\ndepending on the difficulty of the dataset. For the easy dataset, they only used RoBERTa, while for the\\nmedium and hard datasets, they used an ensemble of all three models.\\nSanjesh and Mangai [ 42] base their approach on latent representations of paragraphs by computing\\nembeddings on a set of stylometric features such as TF/IDF for character n-grams, stop word frequency,\\ncharacter and word counts. These embeddings are then fed into a convolutional neural network and\\nBi-directional LSTM layers, which are then combined in a dense layer.\\nLiang and Lei [ 43] use GPT-3.5 as a teacher model that creates a dataset based on the provided\\ndatasets by providing pairs of sentences to the model and then asking questions about the similarity of\\ntopic, style, and vocabulary, and whether the sentences were written by the same author. The student\\nmodel employed is T5-small is then fine-tuned for the multi-author writing style analysis task.\\nLiu, Chen, and Lv [ 44] leverage the Entropy-based Stability-Plasticity (ESP) method to tackle this\\nyear’s task. ESP aims to balance stability and plasticity by restricting changes to the learning rate in\\neach layer based on entropy. As an encoder, the team used BERT.\\n4. Evaluation Results\\nThe results for all of this year’s submissions are shown in Table 1. The best result for each difficulty is\\nhighlighted in bold; note thar the best result for each difficulty was achieved with different approaches.\\nFor the easy dataset, both Ye et al. [ 32] and Huang and Kong [ 34] achieved first place with an F 1of\\n0.991. For the medium dataset, the best result was obtained by Lv et al. [ 30] with an F 1of0.887, while',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper2.pdf', 'page_number': 4}},\n",
              " {'text': 'F1  (medium dataset) F1  (hard dataset)Figure 1: Detection results for the medium (left) and the hard dataset (right) as F 1over the number of authors\\nin a document.\\nthe best result for the hard dataset was obtained by Lin et al. [31] with an F 1of0.863.\\nWhile there is still a clear difference in model performance between the three difficulty levels, the\\nresults have converged significantly again this year, with higher scores for the medium and hard datasets\\ncompared to last year, while the models on the easy dataset are already achieving near perfect scores.\\nWe also checked how the number of authors in a document affects the performance of the submitted\\nmodels for the medium and hard datasets. The results of this can be seen in Figure 1. We confirm the\\nsame observation as in the previous two years: The performance of many submitted models on the hard\\ndataset, including the strongest submitted model, is better for documents written by three authors than\\nfor those written by two authors. Most models then decrease in their performance again on documents\\nwritten by four authors, while the winning model maintains its performance for these documents.\\n5. Conclusion\\nIn the 2024 edition of the multi-author writing style analysis task at PAN, the task was to identify\\nlocations of writing style changes at the paragraph level. We provided participants with three datasets of\\nincreasing thematic homogeneity and therefore difficulty. This year, we received 16 software submissions\\nand 15 working papers. The results obtained again show considerable progress compared to the results\\nof previous years.\\nReferences\\n[1]D. Karaś, M. Śpiewak, P. Sobecki, OPI-JSA at CLEF 2017: Author Clustering and Style Breach\\nDetection—Notebook for PAN at CLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl\\n(Eds.), CLEF 2017 Evaluation Labs and Workshop – Working Notes Papers, CEUR-WS.org, 2017.\\nURL: http://ceur-ws.org/Vol-1866/.\\n[2]J. Khan, Style Breach Detection: An Unsupervised Detection Model—Notebook for PAN at CLEF\\n2017, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.), CLEF 2017 Evaluation Labs and\\nWorkshop – Working Notes Papers, CEUR-WS.org, 2017. URL: http://ceur-ws.org/Vol-1866/.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper2.pdf', 'page_number': 5}},\n",
              " {'text': '[3]E. Stamatatos, Intrinsic Plagiarism Detection Using Character n-gram Profiles, in: B. Stein, P. Rosso,\\nE. Stamatatos, M. Koppel, E. Agirre (Eds.), SEPLN 2009 Workshop on Uncovering Plagiarism,\\nAuthorship, and Social Software Misuse (PAN 09), Universidad Politécnica de Valencia and CEUR-\\nWS.org, 2009, pp. 38–46. URL: http://ceur-ws.org/Vol-502.\\n[4]M. Koppel, J. Schler, S. Argamon, Computational methods in authorship attribution, Journal of\\nthe American Society for Information Science and Technology 60 (2009) 9–26.\\n[5]I. Bensalem, P. Rosso, S. Chikhi, Intrinsic plagiarism detection using n-gram classes, in:\\nProceedings of the 2014 Conference on Empirical Methods in Natural Language Processing\\n(EMNLP), Association for Computational Linguistics, Doha, Qatar, 2014, pp. 1459–1464. URL:\\nhttps://www.aclweb.org/anthology/D14-1153. doi: 10.3115/v1/D14-1153 .\\n[6]D. I. Holmes, The Evolution of Stylometry in Humanities Scholarship, Literary and Linguistic\\nComputing 13 (1998) 111–117.\\n[7]R. Zheng, J. Li, H. Chen, Z. Huang, A Framework for Authorship Identification of Online Mes-\\nsages: Writing-Style Features and Classification Techniques, Journal of the American Society for\\nInformation Science and Technology 57 (2006) 378–393.\\n[8]M. Tschuggnall, G. Specht, Countering Plagiarism by Exposing Irregularities in Authors’ Grammar,\\nin: Proceedings of the European Intelligence and Security Informatics Conference (EISIC), IEEE,\\nUppsala, Sweden, 2013, pp. 15–22.\\n[9]M. Tschuggnall, G. Specht, Automatic decomposition of multi-author documents using grammar\\nanalysis, in: F. Klan, G. Specht, H. Gamper (Eds.), Proceedings of the 26th GI-Workshop Grundlagen\\nvon Datenbanken, volume 1313 of CEUR Workshop Proceedings , CEUR-WS.org, 2014, pp. 17–22.\\nURL: http://ceur-ws.org/Vol-1313.\\n[10] A. Glover, G. Hirst, Detecting Stylistic Inconsistencies in Collaborative Writing, Springer London,\\nLondon, 1996, pp. 147–168. doi: 10.1007/978-1-4471-1482-6_12 .\\n[11] M. Koppel, N. Akiva, I. Dershowitz, N. Dershowitz, Unsupervised decomposition of a document\\ninto authorial components, in: Proceedings of the 49th Annual Meeting of the Association\\nfor Computational Linguistics: Human Language Technologies, Association for Computational\\nLinguistics, Portland, Oregon, USA, 2011, pp. 1356–1364. URL: https://www.aclweb.org/anthology/\\nP11-1136.\\n[12] M. Koppel, N. Akiva, I. Dershowitz, N. Dershowitz, Unsupervised decomposition of a document\\ninto authorial components, in: D. Lin, Y. Matsumoto, R. Mihalcea (Eds.), The 49th Annual Meeting\\nof the Association for Computational Linguistics: Human Language Technologies, Proceedings of\\nthe Conference, 19-24 June, 2011, Portland, Oregon, USA, The Association for Computer Linguistics,\\n2011, pp. 1356–1364. URL: http://www.aclweb.org/anthology/P11-1136.\\n[13] N. Akiva, M. Koppel, Identifying Distinct Components of a Multi-author Document, in: N. Memon,\\nD. Zeng (Eds.), 2012 European Intelligence and Security Informatics Conference, EISIC 2012, IEEE\\nComputer Society, 2012, pp. 205–209. URL: https://doi.org/10.1109/EISIC.2012.16. doi: 10.1109/\\nEISIC.2012.16 .\\n[14] N. Akiva, M. Koppel, A Generic Unsupervised Method for Decomposing Multi-Author Documents,\\nJASIST 64 (2013) 2256–2264. URL: https://doi.org/10.1002/asi.22924. doi: 10.1002/asi.22924 .\\n[15] A. Rexha, S. Klampfl, M. Kröll, R. Kern, Towards a more fine grained analysis of scientific authorship:\\nPredicting the number of authors using stylometric features, in: P. Mayr, I. Frommholz, G. Cabanac\\n(Eds.), Proceedings of the Third Workshop on Bibliometric-enhanced Information Retrieval co-\\nlocated with the 38th European Conference on Information Retrieval (ECIR 2016), volume 1567 of\\nCEUR Workshop Proceedings , CEUR-WS.org, 2016, pp. 26–31. URL: http://ceur-ws.org/Vol-1567.\\n[16] E. Stamatatos, M. Tschuggnall, B. Verhoeven, W. Daelemans, G. Specht, B. Stein, M. Potthast,\\nClustering by Authorship Within and Across Documents, in: Working Notes Papers of the\\nCLEF 2016 Evaluation Labs, CEUR Workshop Proceedings, CLEF and CEUR-WS.org, 2016. URL:\\nhttp://ceur-ws.org/Vol-1609/.\\n[17] M. Tschuggnall, E. Stamatatos, B. Verhoeven, W. Daelemans, G. Specht, B. Stein, M. Potthast,\\nOverview of the Author Identification Task at PAN 2017: Style Breach Detection and Author\\nClustering, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.), Working Notes Papers of the',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper2.pdf', 'page_number': 6}},\n",
              " {'text': 'CLEF 2017 Evaluation Labs, volume 1866 of CEUR Workshop Proceedings , CEUR-WS.org, 2017.\\nURL: http://ceur-ws.org/Vol-1866/.\\n[18] M. Kestemont, M. Tschuggnall, E. Stamatatos, W. Daelemans, G. Specht, B. Stein, M. Potthast,\\nOverview of the Author Identification Task at PAN-2018: Cross-domain Authorship Attribution\\nand Style Change Detection, in: L. Cappellato, N. Ferro, J.-Y. Nie, L. Soulier (Eds.), Working\\nNotes Papers of the CLEF 2018 Evaluation Labs, volume 2125 of CEUR Workshop Proceedings ,\\nCEUR-WS.org, 2018. URL: https://ceur-ws.org/Vol-2125/invited_paper_2.pdf.\\n[19] E. Zangerle, M. Tschuggnall, G. Specht, M. Potthast, B. Stein, Overview of the Style Change\\nDetection Task at PAN 2019, in: L. Cappellato, N. Ferro, D. Losada, H. Müller (Eds.), CLEF 2019\\nLabs and Workshops, Notebook Papers, CEUR-WS.org, 2019. URL: http://ceur-ws.org/Vol-2380/\\npaper_243.pdf.\\n[20] E. Zangerle, M. Mayerl, G. Specht, M. Potthast, B. Stein, Overview of the Style Change Detection\\nTask at PAN 2020, in: L. Cappellato, C. Eickhoff, N. Ferro, A. Névéol (Eds.), CLEF 2020 Labs and\\nWorkshops, Notebook Papers, CEUR-WS.org, 2020. URL: https://ceur-ws.org/Vol-2696/paper_256.\\npdf.\\n[21] E. Zangerle, M. Mayerl, , M. Potthast, B. Stein, Overview of the Style Change Detection Task\\nat PAN 2021, in: G. Faggioli, N. Ferro, A. Joly, M. Maistro, F. Piroi (Eds.), CLEF 2021 Labs and\\nWorkshops, Notebook Papers, CEUR-WS.org, 2021, pp. 1760–1771. URL: https://ceur-ws.org/\\nVol-2936/paper-148.pdf.\\n[22] E. Zangerle, M. Mayerl, M. Potthast, B. Stein, Overview of the Style Change Detection Task at PAN\\n2022, in: G. Faggioli, N. Ferro, A. Hanbury, M. Potthast (Eds.), CLEF 2022 Labs and Workshops,\\nNotebook Papers, CEUR-WS.org, 2022. URL: http://ceur-ws.org/Vol-3180/paper-186.pdf.\\n[23] E. Zangerle, M. Mayerl, M. Potthast, B. Stein, Overview of the Multi-Author Writing Style Analysis\\nTask at PAN 2023, in: M. Aliannejadi, G. Faggioli, N. Ferro, M. Vlachos (Eds.), Working Notes of\\nthe Conference and Labs of the Evaluation Forum (CLEF 2023), volume 3497 of CEUR Workshop\\nProceedings , 2023, pp. 2513–2522. URL: https://ceur-ws.org/Vol-3497/paper-201.pdf.\\n[24] D. Zlatkova, D. Kopev, K. Mitov, A. Atanasov, M. Hardalov, I. Koychev, P. Nakov, An Ensemble-Rich\\nMulti-Aspect Approach for Robust Style Change Detection, in: L. Cappellato, N. Ferro, J.-Y. Nie,\\nL. Soulier (Eds.), CLEF 2018 Evaluation Labs and Workshop – Working Notes Papers, CEUR-WS.org,\\n2018. URL: https://ceur-ws.org/Vol-2125/paper_142.pdf.\\n[25] A. Iyer, S. Vosoughi, Style Change Detection Using BERT—Notebook for PAN at CLEF 2020, in:\\nL. Cappellato, C. Eickhoff, N. Ferro, A. Névéol (Eds.), CLEF 2020 Labs and Workshops, Notebook\\nPapers, CEUR-WS.org, 2020. URL: http://ceur-ws.org/Vol-2696/.\\n[26] Z. Zhang, Z. Han, L. Kong, X. Miao, Z. Peng, J. Zeng, H. Cao, J. Zhang, Z. Xiao, X. Peng, Style Change\\nDetection Based On Writing Style Similarity—Notebook for PAN at CLEF 2021, in: G. Faggioli,\\nN. Ferro, A. Joly, M. Maistro, F. Piroi (Eds.), CLEF 2021 Labs and Workshops, Notebook Papers,\\nCEUR-WS.org, 2021. URL: http://ceur-ws.org/Vol-2936/paper-198.pdf.\\n[27] T.-M. Lin, C.-Y. Chen, Y.-W. Tzeng, L.-H. Lee, Ensemble Pre-trained Transformer Models for Writing\\nStyle Change Detection, in: G. Faggioli, N. Ferro, A. Hanbury, M. Potthast (Eds.), CLEF 2022\\nLabs and Workshops, Notebook Papers, CEUR-WS.org, 2022. URL: http://ceur-ws.org/Vol-3180/\\npaper-210.pdf.\\n[28] H. Chen, Z. Han, Z. Li, Y. Han, A Writing Style Embedding Based on Contrastive Learning for\\nMulti-Author Writing Style Analysis, in: M. Aliannejadi, G. Faggioli, N. Ferro, M. Vlachos (Eds.),\\nWorking Notes of CLEF 2023 - Conference and Labs of the Evaluation Forum, CEUR-WS.org, 2023,\\npp. 2562–2567. URL: https://ceur-ws.org/Vol-3497/paper-206.pdf.\\n[29] M. Potthast, T. Gollub, M. Wiegmann, B. Stein, TIRA Integrated Research Architecture, in: N. Ferro,\\nC. Peters (Eds.), Information Retrieval Evaluation in a Changing World, The Information Retrieval\\nSeries, Springer, Berlin Heidelberg New York, 2019. doi: 10.1007/978-3-030-22948-1_5 .\\n[30] J. Lv, Y. Yi, H. Qi, Team Fosu-stu at PAN: Supervised fine-tuning of large language models for Multi\\nAuthor Writing Style Analysis, in: G. Faggioli, N. Ferro, P. Galuščáková, A. G. S. de Herrera (Eds.),\\nWorking Notes of CLEF 2024 - Conference and Labs of the Evaluation Forum, CEUR-WS.org, 2024.\\n[31] T. Lin, Y. Wu, L. Lee, Team NYCU-NLP at PAN 2024: Integrating Transformers with Similarity',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper2.pdf', 'page_number': 7}},\n",
              " {'text': 'Adjustments for Multi-Author Writing Style Analysis, in: G. Faggioli, N. Ferro, P. Galuščáková,\\nA. G. S. de Herrera (Eds.), Working Notes of CLEF 2024 - Conference and Labs of the Evaluation\\nForum, CEUR-WS.org, 2024.\\n[32] Z. Ye, Y. Zhong, C. Huang, L. Kong, Team no-999 at PAN: Continual Transfer Learning with\\nProgress Prompt for Multi-Author Writing Style Analysis\", in: G. Faggioli, N. Ferro, P. Galuščáková,\\nA. G. S. de Herrera (Eds.), Working Notes of CLEF 2024 - Conference and Labs of the Evaluation\\nForum, CEUR-WS.org, 2024.\\n[33] Z. Huang, L. Kong, Team huangzhijian at PAN: DeBERTa-v3 with R-Drop Regularization for\\nMulti-Author Writing Style Analysis, in: G. Faggioli, N. Ferro, P. Galuščáková, A. G. S. de Herrera\\n(Eds.), Working Notes of CLEF 2024 - Conference and Labs of the Evaluation Forum, CEUR-WS.org,\\n2024.\\n[34] Y. Huang, L. Kong, Team text-understanding-and-analysi at PAN: Utilizing BERT Series Pre-\\ntraining Model for Multi-Author Writing Style Analysis, in: G. Faggioli, N. Ferro, P. Galuščáková,\\nA. G. S. de Herrera (Eds.), Working Notes of CLEF 2024 - Conference and Labs of the Evaluation\\nForum, CEUR-WS.org, 2024.\\n[35] Q. Wu, L. Kong, Z. Ye, Team bingezzzleep at PAN: A Writing Style Change Analysis Model Based\\non RoBERTa Encoding and Contrastive Learning for Multi-Author Writing Style Analysis, in:\\nG. Faggioli, N. Ferro, P. Galuščáková, A. G. S. de Herrera (Eds.), Working Notes of CLEF 2024 -\\nConference and Labs of the Evaluation Forum, CEUR-WS.org, 2024.\\n[36] C. Liu, Z. Han, H. Chen, Q. Hu, Team liuc0757 at PAN: A Writing Style Embedding Method\\nBased on Contrastive Learning for Multi-Author Writing Style Analysis, in: G. Faggioli, N. Ferro,\\nP. Galuščáková, A. G. S. de Herrera (Eds.), Working Notes of CLEF 2024 - Conference and Labs of\\nthe Evaluation Forum, CEUR-WS.org, 2024.\\n[37] E. Ksi e ¸żniak, K. W e ¸cel, M. Sawiński, Team OpenFact at PAN 2024: Fine-Tuning BERT Models with\\nStylometric Enhancements, in: G. Faggioli, N. Ferro, P. Galuščáková, A. G. S. de Herrera (Eds.),\\nWorking Notes of CLEF 2024 - Conference and Labs of the Evaluation Forum, CEUR-WS.org, 2024.\\n[38] Z. Chen, Y. Han, Y. Yi, Team chen at PAN: Integrating R-Drop and Pre-trained Language Model for\\nMulti-author Writing Style Analysis, in: G. Faggioli, N. Ferro, P. Galuščáková, A. G. S. de Herrera\\n(Eds.), Working Notes of CLEF 2024 - Conference and Labs of the Evaluation Forum, CEUR-WS.org,\\n2024.\\n[39] B. Wu, Y. Han, K. Yan, H. Qi, Team baker at PAN: Enhancing Writing Style Change Detection\\nwith Virtual Softmax, in: G. Faggioli, N. Ferro, P. Galuščáková, A. G. S. de Herrera (Eds.), Working\\nNotes of CLEF 2024 - Conference and Labs of the Evaluation Forum, CEUR-WS.org, 2024.\\n[40] A. Khan, M. Rai, K. Khan, S. Shah, F. Alvi, A. Samad, Team Gladiators at PAN: Improving\\nAuthor Identification: A Comparative Analysis of Pre-Trained Transformers for Multi-Author\\nClassification, in: G. Faggioli, N. Ferro, P. Galuščáková, A. G. S. de Herrera (Eds.), Working Notes\\nof CLEF 2024 - Conference and Labs of the Evaluation Forum, CEUR-WS.org, 2024.\\n[41] M. Sheykhlan, S. Abdoljabbar, M. Mahmoudabad, Team karami-sh at PAN: Transformer-based En-\\nsemble Learning for Multi-Author Writing Style Analysis, in: G. Faggioli, N. Ferro, P. Galuščáková,\\nA. G. S. de Herrera (Eds.), Working Notes of CLEF 2024 - Conference and Labs of the Evaluation\\nForum, CEUR-WS.org, 2024.\\n[42] R. Sanjesh, A. Mangai, Team riyasanjesh at PAN: Multi-feature with CNN and Bi-LSTM Neural\\nNetwork approach to Style Change Detection, in: G. Faggioli, N. Ferro, P. Galuščáková, A. G. S.\\nde Herrera (Eds.), Working Notes of CLEF 2024 - Conference and Labs of the Evaluation Forum,\\nCEUR-WS.org, 2024.\\n[43] X. Liang, H. Lei, Team lxflcl66666 at PAN: Fine-Tuned Reasoning for Writing Style Analysis, in:\\nG. Faggioli, N. Ferro, P. Galuščáková, A. G. S. de Herrera (Eds.), Working Notes of CLEF 2024 -\\nConference and Labs of the Evaluation Forum, CEUR-WS.org, 2024.\\n[44] X. Liu, H. Chen, J. Lv, Team foshan-university-of-guangdong at PAN: Adaptive Entropy-\\nBased Stability-Plasticity for Multi-Author Writing Style Analysis, in: G. Faggioli, N. Ferro,\\nP. Galuščáková, A. G. S. de Herrera (Eds.), Working Notes of CLEF 2024 - Conference and Labs of\\nthe Evaluation Forum, CEUR-WS.org, 2024.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper2.pdf', 'page_number': 8}},\n",
              " {'text': 'Overview of the Multi-Author Writing Style Analysis\\nTask at PAN 2023\\nEva Zangerle1, Maximilian Mayerl1, Martin Potthast2and Benno Stein3\\n1University of Innsbruck\\n2Leipzig University and ScaDS.AI\\n3Bauhaus-Universität Weimar\\npan@webis.de https://pan.webis.de\\nAbstract\\nThe analysis of the writing style of multi-authored texts aims at identifying those places where authorship\\nchanges in a document. This task is an important step in reliably identifying the authors of a given text.\\nThis year, we ask participants to solve an intrinsic style change detection task: For a given text, find all\\nplaces where the writing style changes at the paragraph-level. To control for topic information as a style\\nchange signal, we provide participants with data sets with three levels of difficulty and thus different\\nthematic variants. This paper presents the multiple author writing style analysis task, the underlying\\ndata set, the approaches used by participants, and the results obtained.\\n1. Introduction\\nMulti-author writing style analysis aims to identify the positions of authorship changes in a\\ndocument. The task has been part of PAN since 2016, with varying task definitions. In 2016, the\\ngoal was to identify and cluster text segments by author [ 1] and, in 2017, to identify whether a\\ndocument was written by multiple authors [ 2], and, given the case, to identify the exact positions\\nof authorship changes. This task was considered too complex at the time; therefore, at PAN\\n2018, it was relaxed to a binary classification task to distinguish single-author from multi-author\\ndocuments [ 3]. In 2019, the goal was to also predict the number of authors for all detected multi-\\nauthor documents [ 4]. PAN 2020 extended the binary classification task and asked participants\\nto detect style changes at paragraph-level [ 5]. At PAN 2021, the task was to determine whether a\\ngiven document was written by multiple authors and, for multi-author documents, to detect also\\nthe style changes at paragraph-level and to assign authors to paragraphs [6]. In 2022, the task\\nwas further extended to detect changes not only at paragraph-level but even at sentence-level [ 7].\\nThe previously used data sets exhibited a high topical diversity—a fact that allows participants\\nto leverage topic information as a style change signal. In the edition of this year, we hence\\ncarefully control for topical diversity. The core task remained, namely, to find all positions of\\nwriting style change at paragraph-level (i.e., for each pair of consecutive paragraphs, assess\\nwhether there was a style change). However, the simultaneous change of authorship and topic\\nis now explicitly modeled and carefully controlled: We provide participants with data sets at\\nCLEF 2023 – Conference and Labs of the Evaluation Forum, September 18–21, 2023, Thessaloniki, Greece\\n©2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\\nCEUR\\nWorkshop\\nProceedingshttp://ceur-ws.org\\nISSN 1613-0073\\nCEUR Workshop Proceedings (CEUR-WS.org)\\n',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 1}},\n",
              " {'text': 'three levels of difficulty, from documents with paragraphs covering a wide variety topics (easy)\\nto documents in which all paragraphs deal with the same topic (hard).\\nThe remainder of this paper is structured as follows. Section 2 gives an overview of previous\\nstyle change detection approaches. Section 3 presents this year’s style change detection task, the\\ndata sets provided, and our evaluation procedure. Section 4 surveys the participants’ submissions.\\nSection 5 analyzes the achieved results, and Section 6 concludes the paper.\\n2. Related Work\\nIn our setting, identifying the positions of author change requires an intrinsic analysis of writing\\nstyles, i.e., an analysis where no authorship information from other corpora is provided. Such an\\nanalysis has to compute a stylistic fingerprint (or profile) for each text segment. By computing\\nsimilarities between them, the fingerprints are used to detect changes in style which, in turn,\\nindicate a potential authorship change [ 8,9], or to detect outliers [ 10]. The fingerprints can use a\\nvariety of features to capture author writing style such as (1) lexical features (character n-grams\\n(e.g., [ 11,12]), word frequencies (e.g., [ 13]) and average word or sentence lengths (e.g., [ 14])),\\n(2) syntactic features (such as part-of-speech tag frequencies and structures (e.g., [ 15]), or\\ngrammar trees (e.g., [16])), or (3) structural features (e.g., indentation usage (e.g., [14])).\\nGlover and Hirst [ 17] use stylometric features to identify inconsistencies in writing style in\\ncollaborative documents and to detect author boundaries. Meyer zu Eißen and Stein [ 18,19,20]\\nimplement style change detection with word frequency classes to tackle intrinsic plagiarism\\ndetection. Koppel et al. [ 21,22], as well as Akiva and Koppel [ 23,24] perform a clustering step\\non lexical features to decompose multi-authors into authorial threads. Tschuggnall et al. [ 16]\\nleverage grammar tree features for an unsupervised decomposition approach. Rexha et al. [ 25]\\nrely on stylistic features to predict the number of authors of a text. Bensalem et al. [ 26] perform\\nstyle change detection based on 𝑛-grams. Gianella [ 27] segments documents by author using\\nthe Bayesian framework.\\nFor multi-author writing style analysis, we continue to observe a shift from traditional stylistic\\nfeatures mentioned above to pre-trained language models. In 2018, the best results for the task\\nof distinguishing between single- or multi-authored documents were still obtained by a stacking\\nensemble classifier based on (traditional) lexical and syntactical features [ 28]. However, starting\\nfrom 2020, pre-trained models that were fine-tuned on the training data set have achieved the\\nbest results [29, 30, 31].\\n3. Style Change Detection Task\\n3.1. Task Definition\\nThe goal of the multi-author writing style analysis task is to identify positions at which the\\nauthorship of a multi-author document changes. We ask participants to solve the following\\nintrinsic style change detection task: for a given text, find all positions of writing style change\\non the paragraph-level (i.e., for each pair of consecutive paragraphs, assess whether there was a\\nstyle change). The simultaneous change of authorship and topic will be carefully controlled',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 2}},\n",
              " {'text': 'and we will provide participants with data sets of three difficulty levels:\\neasy The document covers a variety of topics (while each paragraph has one topic\\nonly), allowing style change detectors to use topic information to detect authorship\\nchanges between paragraphs.\\nmedium The topical variety of a document is small (though still present), forcing style\\nchange detectors to focus more on style to effectively solve the detection task.\\nhard All paragraphs of a document have the same topic.\\nThe TIRA platform [ 32] allows participants to tune their approaches on the training and\\nvalidation data set. Moreover, participants can evaluate their approach also on the unseen test\\ndata set by either deploying their software on the TIRA platform or by uploading the predictions.\\nBy enabling blind evaluation, TIRA prevents optimization against test data.\\n3.2. Data Set\\nDeviating from the data sets of previous years, the data sets for this year’s edition of the\\nMulti-Author Writing Style Analysis task are based on user posts on Reddit.1In an effort to\\ngenerate both realistic and diverse text for the data sets, we selected parts of Reddit (called\\nsubreddits) that tend to generate longer and more meaningful discussions from users to extract\\nour data from. The following subreddits were selected: r/worldnews ,r/politics ,r/askhistorians ,\\nandr/legaladvice .\\nAs in previous years, we performed several cleanup steps to ensure that the documents\\ncreated for the task consisted of well-formed text. Citations, all forms of Markdown, multiple\\nline breaks or spaces, commonly used emojis, hyperlinks, and trailing and leading spaces were\\nremoved.\\nSubsequently, the collected user contributions were divided into paragraphs, and documents\\nfor the datasets were created from the paragraphs of a single Reddit post. This was done to\\nensure at least basic tpoical coherence of all paragraphs in the final document. To insert style\\nchanges, a random set of authors for the given post was chosen, and paragraphs written by\\nthose authors were concatenated to form the final document. This year, for the first time, the\\ncompilation of paragraphs in the documents was not done arbitrarily, but a newly developed\\nprocedure was applied, which allows us (1) to generate more topically and stylistically coherent\\ndocuments and (2) to tweak the difficulty of the produced data set. To this end, both semantic\\nand stylistic properties of the paragraphs were analyzed, and the paragraphs were then shuffled\\nbased on the similarity of these properties, configuring these similarities to be (1) “large” for\\ntheeasy data set, (2) “moderate” for the medium data set, and (3) “small” for the hard data set.\\nAll documents created are authored by two to four authors, with the number of authors\\nevenly distributed across the documents. In total, each data set consists of 6,000 documents. As\\nin previous years, training, test, and validation splits are provided for all three data sets, with\\nthe test sets held back until the evaluation phase of the competition. The training sets contain\\n70% of the documents in each data set, while the test and validation sets each contain 15%.\\n1https://www.reddit.com/',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 3}},\n",
              " {'text': '3.3. Performance Measures\\nTo evaluate the submitted approaches and compare the obtained results, the submitted eval-\\nuated using the 𝐹𝛼-Measure for each document, where 𝛼= 1 equally weights the harmonic\\nmean between precision and recall. Across all documents, the macro-averaged 𝐹1-Measure is\\ncalculated. The submissions for the three data sets are evaluated independently.\\n4. Survey of Submissions\\nIn total, six teams submitted both software and a working notes paper for the 2023 edition of the\\nMulti-Author Writing Style Analysis task. Unlike last year, all of these approaches are intrinsic\\nin nature. The following is a brief description of the approaches submitted.\\nYe at al. [ 33] apply the pre-trained large language model DeBERTaV3 [ 34] to solve the\\ntask. They combine DeBERTaV3 with two additional components. For the classification of\\nstyle changes, contrastive learning is used. This is realized as a dense neural network using\\na specialized contrastive learning loss for training. Their approach is prompt-based, i.e., the\\nauthors synthesize a prompt essentially asking the language model whether two paragraphs\\nare written by the same author or not. This prompt is not constructed manually, but learned\\nautomatically by their system.\\nChen et al. [ 35] apply also an approach based on contrastive learning, using the original\\nDeBERTa model [ 36]. Unlike the other teams, they create additional paragraph pairs for training\\nfrom non-adjacent paragraphs in the training documents.\\nKucukkaya et al. [ 37] apply the DeBERTaV3 pre-trained language model and frame the\\ndetection task as a natural language inference problem. For two consecutive paragraphs, they\\nconstruct an input to their model which consists of 256 tokens per paragraph, separated by\\na separator token. They use a classifier token as prefix, which tells the model to perform\\nbinary classification if both paragraphs are written by the same author. Since the length of\\neach paragraph is limited to 256 tokens, they devise two methods for choosing these tokens for\\nlonger paragraphs. The first method uses the first 256 tokens per paragraph and is applied for\\nthe hard data set. For the easy and medium data sets, however, the authors propose a method\\nwhich they call “transition-focused truncation”, which takes the tokens around a potential style\\nchange point (i.e., the last 256 tokens resp. the first 256 tokens from two adjacent paragraphs).\\nHuang et al. [ 38] apply the mT0-xl pre-trained language model as a basis [ 39]. Unlike other\\napproaches, they use knowledge distillation to train a smaller student model, and thus their\\napproach requires fewer computational resources than other approaches. They are the only\\nteam that has chosen to include additional training data besides the data provided specifically\\nfor the task, namely the PAN 2020 authorship verification data set.\\nJacobo et al. [ 40] frame the task as an authorship verification problem and apply classical\\nmethods from the field of authorship verification. As feature representations of adjacent\\nparagraphs they apply both a term-document matrix and prediction partial matching (PPM).\\nThese features are fed into a support vector machine and a logistic regression classifier to\\ndetermine if two neighboring paragraphs are written by the same author. For the easy and\\nmedium data sets, PPM with logistic regression is used, while a term-document matrix with a\\nsupport vector machine is used for the hard data set.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 4}},\n",
              " {'text': 'Table 1\\nOverall results for the style change detection task. The best result for each data set is given in bold.\\nParticipant Easy F 1 Medium F 1 Hard F 1\\nChen et al. [35] 0.914 0.820 0.676\\nHashemi et al. [41] 0.984 0.843 0.812\\nHuang et al. [38] 0.968 0.806 0.769\\nJacobo et al. [40] 0.793 0.591 0.498\\nKucukkaya et al. [37] 0.982 0.810 0.772\\nYe et al. [33] 0.983 0.830 0.821\\nHashemi et al. [ 41] apply the BERT [ 42], the RoBERTa [ 43], and the ELECTRA [ 44] pre-trained\\nlanguage models which they combine with a binary classification layer. Moreover, similar to\\nChen et al. [ 35], they also apply data augmentation strategies to generate additional training\\ndata: non-adjacent paragraphs pairs and paragraph pairs generated by mirroring. The authors\\nalso experiment with ensembles of models, which are trained on the three provided data sets.\\n5. Evaluation Results\\nThe results for the six submitted approaches are shown in Table 1 and Figure 1. The best result\\nfor each data set is highlighted in bold. For the easy and medium data sets, the best performance\\nwas achieved by Hashemi et al. [ 41], while Ye et al. [ 33] managed to get the best results for the\\nhard data set.\\nLooking at the overall results, there is a clear difference between the three data sets. Most\\napproaches succeed in achieving high F 1values for the easy data set; for the medium data set,\\nthe values drop significantly. For the hard data set, there is another significant—but smaller—\\ndecrease. We can conclude that our goal of creating data sets with different levels of difficulty\\nwas successful. Moreover, the result shows that topical signals indeed mask the detection of\\nauthorship style changes.\\nWe also looked at how the performance of participants’ contributions changes as a function\\nof the number of authors in a document. The results for this are shown in Figure 2. Since the\\nachieved performance was high in the easy data set, we focus here on the medium and hard data\\nsets. Interestingly, this continues a trend we observed last year [ 7]: at least on the hard data set\\n(as well as on the medium one in the case of Jacobo et al. [ 40]), performance initially increases\\nfor documents written by three authors compared to those written by only two authors. It\\nthen decreases slightly from three to four authors. This suggests that the methods used by\\nparticipants to solve this task are slightly biased towards documents authored by more than\\ntwo authors.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 5}},\n",
              " {'text': 'easy medium hard\\nData Set0.00.20.40.60.81.0ScoreOverall Scores\\nchen\\nhashemihuang\\njacobokucukkaya\\nyeFigure 1: Overall results for the Multi-Author Writing Style task at PAN 2023.\\n2 3 4\\nNumber of Authors0.00.20.40.60.81.0ScoreT ask 2 F1-Score Over Number of Authors\\nparticipant\\nchen\\nhashemi\\nhuang\\njacobo\\nkucukkaya\\nye\\n2 3 4\\nNumber  of Authors0.00.20.40.60.81.0ScoreT ask 3 F1-Score Over Number of Authors\\nchen\\nhashemi\\nhuangjacobo\\nkucukkaya\\nye\\nFigure 2: Results depending on the number of authors in a document.\\n6. Conclusion\\nIn the Multi-Author Writing Style Analysis task at PAN 2023, participants were asked to identify\\nthe places in a document where the author changes. For this task, participants were provided\\nwith three data sets of varying difficulty, developed by carefully controlling for topical and\\nstylistic consistency across author changes. Six papers were submitted for the task, all but one',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 6}},\n",
              " {'text': 'of which used a pre-trained language model as its core.\\nAltogether, the results obtained by this year’s participants show a marked improvement over\\nlast year’s results, indicating that good progress is being made in this field.\\nReferences\\n[1]E. Stamatatos, M. Tschuggnall, B. Verhoeven, W. Daelemans, G. Specht, B. Stein, M. Potthast,\\nClustering by Authorship Within and Across Documents, in: Working Notes Papers of\\nthe CLEF 2016 Evaluation Labs, CEUR Workshop Proceedings, CLEF and CEUR-WS.org,\\n2016. URL: http://ceur-ws.org/Vol-1609/.\\n[2]M. Tschuggnall, E. Stamatatos, B. Verhoeven, W. Daelemans, G. Specht, B. Stein, M. Potthast,\\nOverview of the Author Identification Task at PAN 2017: Style Breach Detection and\\nAuthor Clustering, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.), Working Notes\\nPapers of the CLEF 2017 Evaluation Labs, volume 1866 of CEUR Workshop Proceedings ,\\nCEUR-WS.org, 2017. URL: http://ceur-ws.org/Vol-1866/.\\n[3]M. Kestemont, M. Tschuggnall, E. Stamatatos, W. Daelemans, G. Specht, B. Stein, M. Pot-\\nthast, Overview of the Author Identification Task at PAN-2018: Cross-domain Authorship\\nAttribution and Style Change Detection, in: L. Cappellato, N. Ferro, J.-Y. Nie, L. Soulier\\n(Eds.), Working Notes Papers of the CLEF 2018 Evaluation Labs, volume 2125 of CEUR\\nWorkshop Proceedings , CEUR-WS.org, 2018. URL: http://ceur-ws.org/Vol-2125/.\\n[4]E. Zangerle, M. Tschuggnall, G. Specht, M. Potthast, B. Stein, Overview of the Style\\nChange Detection Task at PAN 2019, in: L. Cappellato, N. Ferro, D. Losada, H. Müller\\n(Eds.), CLEF 2019 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2019. URL:\\nhttp://ceur-ws.org/Vol-2380/.\\n[5]E. Zangerle, M. Mayerl, G. Specht, M. Potthast, B. Stein, Overview of the Style Change\\nDetection Task at PAN 2020, in: L. Cappellato, C. Eickhoff, N. Ferro, A. Névéol (Eds.), CLEF\\n2020 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2020. URL: http://ceur-ws.\\norg/Vol-2696/.\\n[6]E. Zangerle, M. Mayerl, , M. Potthast, B. Stein, Overview of the Style Change Detection\\nTask at PAN 2021, in: G. Faggioli, N. Ferro, A. Joly, M. Maistro, F. Piroi (Eds.), CLEF 2021\\nLabs and Workshops, Notebook Papers, CEUR-WS.org, 2021.\\n[7]E. Zangerle, M. Mayerl, M. Potthast, B. Stein, Overview of the Style Change Detection\\nTask at PAN 2022, in: G. Faggioli, N. Ferro, A. Hanbury, M. Potthast (Eds.), CLEF 2022 Labs\\nand Workshops, Notebook Papers, CEUR-WS.org, 2022. URL: http://ceur-ws.org/Vol-3180/\\npaper-186.pdf.\\n[8]D. Karaś, M. Śpiewak, P. Sobecki, OPI-JSA at CLEF 2017: Author Clustering and Style\\nBreach Detection—Notebook for PAN at CLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot,\\nT. Mandl (Eds.), CLEF 2017 Evaluation Labs and Workshop – Working Notes Papers, CEUR-\\nWS.org, 2017. URL: http://ceur-ws.org/Vol-1866/.\\n[9]J. Khan, Style Breach Detection: An Unsupervised Detection Model—Notebook for PAN at\\nCLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.), CLEF 2017 Evaluation\\nLabs and Workshop – Working Notes Papers, CEUR-WS.org, 2017. URL: http://ceur-ws.\\norg/Vol-1866/.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 7}},\n",
              " {'text': '[10] K. Safin, R. Kuznetsova, Style Breach Detection with Neural Sentence Embeddings—\\nNotebook for PAN at CLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.),\\nCLEF 2017 Evaluation Labs and Workshop – Working Notes Papers, CEUR-WS.org, 2017.\\nURL: http://ceur-ws.org/Vol-1866/.\\n[11] E. Stamatatos, Intrinsic Plagiarism Detection Using Character $n$-gram Profiles, in:\\nB. Stein, P. Rosso, E. Stamatatos, M. Koppel, E. Agirre (Eds.), SEPLN 2009 Workshop on\\nUncovering Plagiarism, Authorship, and Social Software Misuse (PAN 09), Universidad\\nPolitécnica de Valencia and CEUR-WS.org, 2009, pp. 38–46. URL: http://ceur-ws.org/\\nVol-502.\\n[12] M. Koppel, J. Schler, S. Argamon, Computational methods in authorship attribution,\\nJournal of the American Society for Information Science and Technology 60 (2009) 9–26.\\n[13] D. I. Holmes, The Evolution of Stylometry in Humanities Scholarship, Literary and\\nLinguistic Computing 13 (1998) 111–117.\\n[14] R. Zheng, J. Li, H. Chen, Z. Huang, A Framework for Authorship Identification of Online\\nMessages: Writing-Style Features and Classification Techniques, Journal of the American\\nSociety for Information Science and Technology 57 (2006) 378–393.\\n[15] M. Tschuggnall, G. Specht, Countering Plagiarism by Exposing Irregularities in Authors’\\nGrammar, in: Proceedings of the European Intelligence and Security Informatics Confer-\\nence (EISIC), IEEE, Uppsala, Sweden, 2013, pp. 15–22.\\n[16] M. Tschuggnall, G. Specht, Automatic decomposition of multi-author documents using\\ngrammar analysis, in: F. Klan, G. Specht, H. Gamper (Eds.), Proceedings of the 26th\\nGI-Workshop Grundlagen von Datenbanken, volume 1313 of CEUR Workshop Proceedings ,\\nCEUR-WS.org, 2014, pp. 17–22. URL: http://ceur-ws.org/Vol-1313.\\n[17] A. Glover, G. Hirst, Detecting Stylistic Inconsistencies in Collaborative Writing, Springer\\nLondon, London, 1996, pp. 147–168. doi: 10.1007/978-1-4471-1482-6_12 .\\n[18] S. Meyer zu Eißen, B. Stein, Intrinsic Plagiarism Detection, in: M. Lalmas, A. MacFarlane,\\nS. Rüger, A. Tombros, T. Tsikrika, A. Yavlinsky (Eds.), Advances in Information Retrieval.\\n28th European Conference on IR Research (ECIR 2006), volume 3936 of Lecture Notes in\\nComputer Science , Springer, Berlin Heidelberg New York, 2006, pp. 565–569. doi: 10.1007/\\n11735106_66 .\\n[19] B. Stein, S. Meyer zu Eißen, Intrinsic Plagiarism Analysis with Meta Learning, in:\\nB. Stein, M. Koppel, E. Stamatatos (Eds.), 1st Workshop on Plagiarism Analysis, Authorship\\nIdentification, and Near-Duplicate Detection (PAN 2007) at SIGIR, 2007, pp. 45–50. URL:\\nhttp://ceur-ws.org/Vol-276.\\n[20] B. Stein, N. Lipka, P. Prettenhofer, Intrinsic Plagiarism Analysis, Language Resources and\\nEvaluation (LRE) 45 (2011) 63–82. doi: 10.1007/s10579-010-9115-y .\\n[21] M. Koppel, N. Akiva, I. Dershowitz, N. Dershowitz, Unsupervised decomposition of a\\ndocument into authorial components, in: Proceedings of the 49th Annual Meeting of the\\nAssociation for Computational Linguistics: Human Language Technologies, Association\\nfor Computational Linguistics, Portland, Oregon, USA, 2011, pp. 1356–1364. URL: https:\\n//www.aclweb.org/anthology/P11-1136.\\n[22] M. Koppel, N. Akiva, I. Dershowitz, N. Dershowitz, Unsupervised decomposition of a\\ndocument into authorial components, in: D. Lin, Y. Matsumoto, R. Mihalcea (Eds.), The\\n49th Annual Meeting of the Association for Computational Linguistics: Human Language',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 8}},\n",
              " {'text': 'Technologies, Proceedings of the Conference, 19-24 June, 2011, Portland, Oregon, USA,\\nThe Association for Computer Linguistics, 2011, pp. 1356–1364. URL: http://www.aclweb.\\norg/anthology/P11-1136.\\n[23] N. Akiva, M. Koppel, Identifying Distinct Components of a Multi-author Document, in:\\nN. Memon, D. Zeng (Eds.), 2012 European Intelligence and Security Informatics Conference,\\nEISIC 2012, IEEE Computer Society, 2012, pp. 205–209. URL: https://doi.org/10.1109/EISIC.\\n2012.16. doi: 10.1109/EISIC.2012.16 .\\n[24] N. Akiva, M. Koppel, A Generic Unsupervised Method for Decomposing Multi-Author\\nDocuments, JASIST 64 (2013) 2256–2264. URL: https://doi.org/10.1002/asi.22924. doi: 10.\\n1002/asi.22924 .\\n[25] A. Rexha, S. Klampfl, M. Kröll, R. Kern, Towards a more fine grained analysis of scientific\\nauthorship: Predicting the number of authors using stylometric features, in: P. Mayr,\\nI. Frommholz, G. Cabanac (Eds.), Proceedings of the Third Workshop on Bibliometric-\\nenhanced Information Retrieval co-located with the 38th European Conference on Infor-\\nmation Retrieval (ECIR 2016), volume 1567 of CEUR Workshop Proceedings , CEUR-WS.org,\\n2016, pp. 26–31. URL: http://ceur-ws.org/Vol-1567.\\n[26] I. Bensalem, P. Rosso, S. Chikhi, Intrinsic plagiarism detection using n-gram classes, in:\\nProceedings of the 2014 Conference on Empirical Methods in Natural Language Processing\\n(EMNLP), Association for Computational Linguistics, Doha, Qatar, 2014, pp. 1459–1464.\\nURL: https://www.aclweb.org/anthology/D14-1153. doi: 10.3115/v1/D14-1153 .\\n[27] C. Giannella, An Improved Algorithm for Unsupervised Decomposition of a Multi-Author\\nDocument, JASIST 67 (2016) 400–411. URL: https://doi.org/10.1002/asi.23375. doi: 10.\\n1002/asi.23375 .\\n[28] D. Zlatkova, D. Kopev, K. Mitov, A. Atanasov, M. Hardalov, I. Koychev, P. Nakov, An\\nEnsemble-Rich Multi-Aspect Approach for Robust Style Change Detection, in: L. Cap-\\npellato, N. Ferro, J.-Y. Nie, L. Soulier (Eds.), CLEF 2018 Evaluation Labs and Workshop –\\nWorking Notes Papers, CEUR-WS.org, 2018. URL: http://ceur-ws.org/Vol-2125/.\\n[29] A. Iyer, S. Vosoughi, Style Change Detection Using BERT, in: L. Cappellato, N. Ferro,\\nA. Névéol, C. Eickhoff (Eds.), CLEF 2020 Labs and Workshops, Notebook Papers, CEUR-\\nWS.org, 2020.\\n[30] Z. Zhang, X. Miao, Z. Peng, J. Zeng, H. Cao, J. Zhang, Z. Xiao, X. Peng, Z. Chen, Using\\nSingle BERT For Three Tasks Of Style Change Detection, in: G. Faggioli, N. Ferro, A. Joly,\\nM. Maistro, F. Piroi (Eds.), CLEF 2021 Labs and Workshops, Notebook Papers, CEUR-WS.org,\\n2021.\\n[31] T.-M. Lin, C.-Y. Chen, Y.-W. Tzeng, L.-H. Lee, Ensemble Pre-trained Transformer Models\\nfor Writing Style Change Detection, in: CLEF 2022 Labs and Workshops, Notebook Papers,\\nCEUR-WS.org, 2022.\\n[32] M. Potthast, T. Gollub, M. Wiegmann, B. Stein, TIRA Integrated Research Architecture,\\nin: N. Ferro, C. Peters (Eds.), Information Retrieval Evaluation in a Changing World, The\\nInformation Retrieval Series, Springer, Berlin Heidelberg New York, 2019. doi: 10.1007/\\n978-3-030-22948-1_5 .\\n[33] Z. Ye, C. Zhong, H. Qi, Y. Han, Supervised Contrastive Learning for Multi-Author Writing\\nStyle Analysis, in: M. Aliannejadi, G. Faggioli, N. Ferro, M. Vlachos (Eds.), Working Notes\\nof CLEF 2023 - Conference and Labs of the Evaluation Forum, CEUR-WS.org, 2023.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 9}},\n",
              " {'text': '[34] P. He, J. Gao, W. Chen, Debertav3: Improving deberta using electra-style pre-training with\\ngradient-disentangled embedding sharing, in: The Eleventh International Conference on\\nLearning Representations, 2022.\\n[35] H. Chen, Z. Han, Z. Li, Y. Han, A Writing Style Embedding Based on Contrastive Learning\\nfor Multi-Author Writing Style Analysis, in: M. Aliannejadi, G. Faggioli, N. Ferro, M. Vla-\\nchos (Eds.), Working Notes of CLEF 2023 - Conference and Labs of the Evaluation Forum,\\nCEUR-WS.org, 2023.\\n[36] P. He, X. Liu, J. Gao, W. Chen, Deberta: Decoding-enhanced bert with disentangled\\nattention, in: International Conference on Learning Representations, 2020.\\n[37] I. E. Kucukkaya, U. Sahin, C. Toraman, ARC-NLP at PAN 23: Transition-Focused Natural\\nLanguage Inference for Writing Style Detection, in: M. Aliannejadi, G. Faggioli, N. Ferro,\\nM. Vlachos (Eds.), Working Notes of CLEF 2023 - Conference and Labs of the Evaluation\\nForum, CEUR-WS.org, 2023.\\n[38] M. Huang, Z. Huang, L. Kong, Encoded Classifier Using Knowledge Distillation for Multi-\\nAuthor Writing Style Analysis, in: M. Aliannejadi, G. Faggioli, N. Ferro, M. Vlachos\\n(Eds.), Working Notes of CLEF 2023 - Conference and Labs of the Evaluation Forum,\\nCEUR-WS.org, 2023.\\n[39] N. Muennighoff, T. Wang, L. Sutawika, A. Roberts, S. Biderman, T. L. Scao, M. S. Bari,\\nS. Shen, Z.-X. Yong, H. Schoelkopf, et al., Crosslingual generalization through multitask\\nfinetuning, arXiv preprint arXiv:2211.01786 (2022).\\n[40] G. Jacobo, V. Dehesa, D. Rojas, H. Gómez-Adorno, Authorship verification machine\\nlearning methods for Style Change Detection in texts, in: M. Aliannejadi, G. Faggioli,\\nN. Ferro, M. Vlachos (Eds.), Working Notes of CLEF 2023 - Conference and Labs of the\\nEvaluation Forum, CEUR-WS.org, 2023.\\n[41] A. Hashemi, W. Shi, Enhancing Writing Style Change Detection using Transformer-based\\nModels and Data Augmentation, in: M. Aliannejadi, G. Faggioli, N. Ferro, M. Vlachos\\n(Eds.), Working Notes of CLEF 2023 - Conference and Labs of the Evaluation Forum,\\nCEUR-WS.org, 2023.\\n[42] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep bidirectional\\ntransformers for language understanding, arXiv preprint arXiv:1810.04805 (2018).\\n[43] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer,\\nV. Stoyanov, RoBERTa: A Robustly Optimized BERT Pretraining Approach, arXiv preprint\\narXiv:1907.11692 (2019).\\n[44] K. Clark, M.-T. Luong, Q. V. Le, C. D. Manning, Electra: Pre-training text encoders as\\ndiscriminators rather than generators, arXiv preprint arXiv:2003.10555 (2020).',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper3.pdf', 'page_number': 10}},\n",
              " {'text': 'Overview of the Style Change Detection Task at PAN\\n2022\\nEvaZangerle1,Maximilian Mayerl1,MartinPotthast2andBennoStein3\\n1Universität Innsbruck\\n2Leipzig University\\n3Bauhaus-Universität Weimar\\npan@webis.de https://pan.webis.de\\nAbstract\\nStyle change detection means to identify positions at which the authorship in a multi-author document\\nchanges. Reliably detecting these positions is key for multi-author document analyses, and it is a\\npreliminary step for authorship identification. This year style change detection task at PAN features\\nthreeconnectedsubtasks: (1)Foratextwrittenbytwoauthors,whichcontainsasinglestylechangeonly,\\nfindthepositionofthischange,i.e.,cutthetextintothetwoauthors’textsontheparagraph-level. (2)For\\natextwrittenbytwoormoreauthors,findallpositionsofwritingstylechange,i.e.,assignallparagraphs\\nofthetextuniquelytosomeauthoroutofthenumberofauthorsassumedforthemulti-authordocument.\\n(3) For a text written by two or more authors, find all positions of writing style change. In particular,\\nstyle changes may occur both between paragraphs but also at sentence level. The task is evaluated\\nonadatasetcompiledfromanEnglishQ&Aplatform. Thepaperinhandintroducesthestylechange\\ndetectiontask,theunderlyingdataset,theapproachesemployedbytheparticipants,andtheachieved\\nresults.\\n1. Introduction\\nThe goal of the style change detection task is to identify the positions in a document where\\nauthorship changes. Previous editions of the style change detection task at PAN included\\ncertain variants of this task: In 2016, the identification and clustering of text segments\\nby author [ 1]. In 2017, to first detect whether a given document was written by multiple\\nauthors [ 2], and, given the case, to identify the exact positions at which authorship\\nchanges. The (weak) results showed that this task was beyond the state-of-the-art at that\\ntime. Hence, at PAN 2018, the task was relaxed to a binary classification task, namely, to\\ndistinguish single-author from multi-author documents [ 3]. PAN 2019 extended the task\\nand asked participants to also predict the number of authors for all detected multi-author\\ndocuments [ 4]. Similarly, PAN 2020 focused on binary classification (single versus multiple\\nauthors) and to determine the positions of style changes at paragraph level [ 5]. At PAN\\n2021, the participants were asked to determine whether a given document was written by\\nmultiple authors and, given the case, to detect the style changes at paragraph level and\\nto assign authors to paragraphs [ 6].\\nCLEF 2022 – Conference and Labs of the Evaluation Forum, September 5–8, 2022, Bologna, Italy\\n©2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 Inter-\\nnational (CC BY 4.0).\\nCEUR\\nWorkshop\\nProceedingshttp://ceur-ws.org\\nISSN 1613-0073\\nCEUR Workshop Proceedings ( CEUR-WS.org )\\n',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 1}},\n",
              " {'text': 'This year, we again advanced the field of multi-author analysis by increasing the\\ncomplexity of the identification problem. Specifically, participants were asked (1) to find\\nthe position of a style change in documents with a single style change (at the paragraph\\nlevel), (2) to find all style changes in a document written by up to five authors at the\\nparagraph level, and (3) to find the positions of style changes at the sentence level.\\nThe remainder of this paper is structured as follows. Section 2discusses previous style\\nchange detection approaches. Section 3introduces this year’s style change detection task\\nand its subtasks, along with the datasets and the used evaluation (performance) measures.\\nSection 4surveys the participants’ submissions. Section 5analyzes and compares the\\nachieved results and Section 6concludes the paper.\\n2. Related Work\\nStyle change detection requires an “intrinsic document analysis”, in contrast to an analysis\\nthat can use knowledge from other corpora. An intrinsic analysis includes the computation\\nof a stylistic profile for each sentence or paragraph, which is used to spot style change\\npositions by either comparing similarities [ 7,8] or by an outlier detection analysis [ 9].\\nStylistic profiles may comprise lexical features such as character n-grams (e.g., [ 10,11]),\\nword frequencies (e.g., [ 12]) and average word or sentence lengths (e.g., [ 13]), syntactic\\nfeatures such as part-of-speech tag frequencies and structures (e.g., [ 14]), grammar trees\\n(e.g., [ 15]), or structural features such as indentation usage (e.g., [ 13]).\\nBy analyzing stylometric features, Glover and Hirst [ 16] identify inconsistencies in\\nwriting style in collaborative documents by detecting author boundaries. Meyer zu\\nEißen and Stein [ 17,18,19] analyze intrinsic plagiarism detection based on style change\\ndetection using word frequency classes. Koppel et al. [ 20,21], as well as Akiva and\\nKoppel [ 22,23] use clustering based on lexical features to decompose multi-authors\\ninto authorial threads. The approach by Tschuggnall et al. [ 15] relies on grammar tree\\nfeatures for an unsupervised decomposition approach. Rexha et al. [ 24] use stylistic\\nfeatures to predict the number of authors who wrote a text. Bensalem et al. [ 25] use\\n𝑛-grams to identify author style changes, while Gianella [ 26] employs Bayesian modeling\\nto decompose a document by author.\\nTo this end, we observe at PAN a shift from the use of traditional stylistic features to\\npre-trained language models for characterizing paragraphs or sentences. For instance, in\\n2018, the best binary classification results (distinguish between single- or multi-authored\\ndocument) were obtained by a stacking ensemble classifier based on lexical and syntactical\\nfeatures extracted via multiple sliding window approaches [ 27]. In 2020 and 2021, pre-\\ntrained BERT models that were fine-tuned on the training dataset have shown to achieve\\nthe best results [ 28,29].\\n3. Style Change Detection Task\\nThis section presents the style change detection task and its subtasks, the dataset\\nunderlying the task, and the used evaluation (performance) measures.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 2}},\n",
              " {'text': 'Duisautemveleumiriuredolorinhendreritinvulputate\\nvelitessemoles�econsequat,velillumdoloreeufeugiat\\nnullafacilisisatveroerosetaccum sanetiustoodio\\ndignissimquiblanditpraesentluptatumzzrildelenit\\naugueduisdoloretefeugaitnullafacilisi.Loremipsum\\ndolorsitamet,consectetueradipiscingelit,seddiam\\nnonummynibheuismod�nciduntutlaoreetdolore\\nmagnaaliquam eratvolutpat.\\nUtwisienimadminimveniam,quisnostrudexerci\\nta�onullamcorpersuscipitlobor�snislutaliquipexea\\ncommodoconsequat.Duisautemveleumiriuredolorin\\nhendreritinvulputatevelitessemoles�econsequat,vel\\nillumdoloreeufeugiatnullafacilisisatveroeroset\\naccumsanetiustoodiodignissimquiblanditpraesent\\nluptatumzzrildelenitaugueduisdoloretefeugaitnulla\\nfacilisi.\\nNamlibertemporcum solutanobiseleifendop�on\\nconguenihilimperdietdomingidquodmazimplacerat\\nfacerpossimassum.Loremipsumdolorsitamet,\\nconsectetueradipiscingelit,seddiamnonummy nibh\\neuismod�nciduntutlaoreetdoloremagnaaliquamerat\\nvolutpat.Loremipsumdolorsitamet,consecteturadipiscingelit,\\nseddoeiusmodtemporincididuntutlaboreetdolore\\nmagnaaliqua.Miproinsedliberoenimsed.Elit\\npellentesque habitantmorbitris�quesenectus.\\nVenena�slectusmagnafringillaurnapor�torrhoncus\\ndolorpurus.Duisutdiamquamnullapor�tor.Estsit\\nametfacilisismagnae�amtempororci.\\nFringillautmorbi�nciduntaugueinterdumvelit\\neuismodinpellentesque.Nisilacussedviverratellusin.\\nEstultriciesintegerquisauctor.Ullamcorpervelitsed\\nullamcorpermorbi�nciduntornaremassa.Orcieu\\nlobor�selementumnibh.Risusnec feugiatin\\nfermentumposuereurnanec�nciduntpraesent.Quam\\npellentesque necnamaliquamsemet.Odioeufeugiat\\npre�umnibhipsumconsequat.Fringillaestullamcorper\\negetnullafacilisie�amdignissimdiamquis.Arcudui\\nvivamusarcufelisbibendum ut.\\nPoten�nullamactortorvitaepurusfaucibus ornare.\\nUllamcorperdignissimcras�nciduntlobor�s.Habitant\\nmorbitris�que senectuset.Utornarelectussitamet.\\nAmetconsecteturadipiscingelitutaliqua mpurussit.\\nNibhnislcondimentumidvenena�sacondimentum\\nvitaesapien.Adipiscingenimeuturpisegestaspre�um.\\nEgestasintegeregetaliquetnibhpraesenttris�que.\\nGravidaquisblanditturpiscursus.Nuncidcursusmetus\\naliqua meleifend.Exampl eDocumen tA ExampleDocumen tB\\nAuthor1\\nAuthor2\\nAuthor2Author1\\nAuthor2\\nAuthor2\\nAuthor3\\nTask 1: [1,0]\\nTask 2: [1,2,2]Task 1: [1,0,1]\\nTask 2: [1,2,2,3]Loremipsumdolorsitamet,consecteturadipiscingelit,\\nseddoeiusmodtemporincididuntutlaboreetdolore\\nmagnaaliqua.Quisimperdietmassa�nciduntnunc\\npulvinarsapienet.Sitametrisusnullamegetfelis,fusce\\nutplaceratorcinulla.Atintellusintegerfeugiat\\nscelerisquevariusmorbienim.Aliquetnecullamcorper\\nsitametrisusnullameget,fermentumleovelorciporta.\\nMoles�eaiaculis aterat.Massa�nciduntduiutornare\\nlectus,vitaepurusfaucibusornaresuspendissesednisi\\nlacussed.Cursusegetnunc scelerisque viverramauris\\nin.Faucibus turpisineumibibendumnequeegestas\\nconguequisque.Plateadictumstves�bulumrhoncus\\nest.Loremsedrisusultriciestris�quenullaaliquetenim\\ntortorat.Sedvelitdignissimsodalesuteuseminteger\\nvitae.Ma�snunc sedblanditlibero.\\nActurpisegestassedtempusurnaetpharetrapharetra\\nmassa.Nibhnislcondimentumidvenena�sa\\ncondimentum.Fringillautmorbi�nciduntaugue\\ninterdumvelit.Enimeuturpisegestaspre�umaenean\\npharetramagna.Turpisineumibibendum.Leoduisut\\ndiamquamnulla por�tormassa idneque.A\\npellentesque sitametpor�toreget.Lectusurnaduis\\nconvallisconvallistellusidinterdum.Lectusproinnibh\\nnislcondimentumidvenena�s.Netusetmalesuada\\nfamesacturpisegestasintegereget.Egetvelitaliquet\\nsagi�sid.Tris�queetegestasquisipsumsuspendisse\\nultricesgravida.Sapienfaucibusetmoles�eacfeugiat\\nsedlectusves�bulumma�s.Nunc scelerisqueviverra\\nmaurisinaliqua msemfringillautmorbi.Exampl eDocumen tC\\nAuthor1\\nAuthor2\\nAuthor3\\nTask 3: [0,0,1,0,0,0,0,0,0,1,....]Figure1: Sample documents that illustrate different style change situations and the expected solution.\\nFromlefttoright: singlestylechange(Subtask1),multiplestylechangesandattribution(Subtask2),\\nand multiple style changes on the sentence level (Subtask 3).\\n3.1. Task Definition\\nThe goal of the style change detection task is to identify positions at which the authorship\\nof a multi-author document changes. We study the following subtasks in this regard:\\nStyle Change Basic For a text written by two authors that contains a single style change\\nonly, find the position of this change, i.e., cut the text into the two authors texts\\nat the paragraph-level.\\nStyle Change Advanced For a text written by two or more authors, find all positions of\\nwriting style change, i.e., assign all paragraphs of the text uniquely to some author\\nout of the number of authors assumed for the multi-author document.\\nStyle Change Real-World For a text written by two or more authors, find all positions\\nof writing style change, where style changes now not only occur between paragraphs\\nbut at the sentence level.\\nFigure 1illustrates three example documents and the expected outcome for the three\\nsubtasks. Document A has a single style change between the first and second paragraph,\\nDocument B contains two style changes on the paragraph level and was authored by\\nthree different authors, and Document C contains two style changes on the sentence level\\nand was authored by three authors.\\nParticipants either deployed their software on the TIRA platform [ 30] or uploaded\\ntheir predictions. TIRA allows participants to tune their approaches on the training and\\nvalidation dataset, as well as to self-evaluate their software on the unseen test dataset.\\nBy enabling blind evaluation, TIRA prevents optimization against test data.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 3}},\n",
              " {'text': '3.2. Dataset\\nThe datasets that we provided for this task have been created from posts on the popular\\nStackExchange network of Q&A sites. Based on a dump of questions and answers from\\nthe StackExchange network, we extracted a subset of broad topics (so-called sites).1The\\ncleansing of this raw data included the removal of questions and answers that were edited\\nafter they were originally posted, as well as the removal of images, URLs, code snippets,\\nblock quotes, and bullet lists.\\nThe procedure for forming datasets works as follows. All questions and answers are\\nsplit into paragraphs, where paragraphs with less than 100 characters are discarded.\\nThen, artificial documents are synthesized by drawing paragraphs from a single question\\nthread to ensure that topic changes cannot be exploited for detecting style changes. The\\nnumber of authors for each artificial document is picked randomly between one and five.\\nWe randomly chose a corresponding number of authors from the set of authors who\\ncontributed to the question thread we are drawing paragraphs from. In the next step, we\\ntake the paragraphs written by the selected authors and shuffle them to obtain the final\\ndocuments. If a resulting document has fewer than two paragraphs or is shorter than\\n1,000 characters or longer than 10,000 characters, we discard it.\\nWe applied this procedure with slightly different parameters to generate a separate\\ndataset for each of this year’s three subtasks. For the dataset of Subtask 1, we ensured\\nthat every generated document features exactly one style change. For the dataset of\\nSubtask 2, we used the procedure as outlined above. For the dataset of Subtask 3, we\\nchanged the procedure to operate on sentences instead of on paragraphs. The three\\ndatasets that we obtained in this way contain 2,000 ,10,000 , and10,000 documents\\nrespectively. All datasets are split into training, test, and validation sets in the ratio\\n70:15:15.\\n3.3. Performance Measures\\nThe three subtasks are evaluated independently. As a primary evaluation metric, we\\ncompute the macro-averaged F1-score across all documents for all three subtasks. To get\\na deeper understanding of the performance of the authorship attribution in Subtask 2,\\nwe employ two additional measures, borrowed from the field of text transcription and\\nspeaker diarization. Transferred to the style change detection task, these measures\\nessentially capture the fraction of text that is not correctly attributed to an author. The\\nDiarization Error Rate (DER) measure [ 31] captures the fraction of wrongly attributed\\nsegments. The Jaccard Error Rate (JER) [ 32] gives equal weight to each author. For each\\nreference author 𝑟𝑒𝑓𝑎, we compare the set of segments authored by 𝑟𝑒𝑓𝑎(either paragraph\\nor sentence, depending on the subtask) against the set of predicted authors 𝑝𝑟𝑒𝑑𝑎for\\nthese segments. Based on the Jaccard Error Rate, we compute the ratio between the\\nsizes of the intersections and unions of the two sets of segments (see Equation 1). The\\n1The following StackExchange sites were used: Code Review, Computer Graphics, CS Educators, CS\\nTheory, Data Science, DBA, DevOps, GameDev, Network Engineering, Raspberry Pi, Superuser, and\\nServer Fault.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 4}},\n",
              " {'text': 'final JER results from the average of the author-specific Jaccard Error Rates.\\n𝐽𝐸𝑅(𝑎) = 1.0−|𝑟𝑒𝑓𝑎∩𝑝𝑟𝑒𝑑𝑎|\\n|𝑟𝑒𝑓𝑎∪𝑝𝑟𝑒𝑑𝑎|(1)\\n4. Survey of Submissions\\nFor the 2022 edition of the style change detection task, we received nine submissions;\\neight of which used intrinsic approaches and one used an extrinsic approach. We briefly\\ndescribe the approaches proposed by the participants in the following.\\nAlshamasi and Menai [ 33] rely on a set of lexical and syntactic features that are extracted\\non the sentence- and on the paragraph level. Based on these text representations, the\\nauthors apply 𝑘-means clustering, where the number of clusters 𝑘is evaluated using\\nthe within-cluster sum-of-squares error. This method aims to assign all paragraphs\\n(sentences) of an author to a single cluster. For Subtask 1, where only a single style\\nchange is contained in the input documents, 𝑘is set to 2 in order to derive the potential\\nauthors of individual paragraphs and detect candidate positions for the switches. Finally,\\nthe pair of paragraphs with the highest cosine distance is chosen. For Subtask 2 and\\nSubtask 3, the assignments of the individual paragraphs to the 𝑘clusters is used for the\\nprediction based on the extracted paragraph or sentence vectors.\\nLao et al. [ 34] rely on a pre-trained Bidirectional Encoder Representations from\\nTransformers (BERT) [ 35] model that is fine-tuned based on the provided dataset.\\nThe output of the BERT model is then fed into a one-dimensional convolution that\\nallows obtaining dense feature representations of individual sentences/paragraphs. These\\nrepresentations are then the input to a max-pooling layer to arrive at a binary class\\ncapturing whether there is a style change between two paragraphs (sentences) or not.\\nThis binary output can directly be used for the subtasks 1 and 3. For Subtask 2, the\\nparagraph representations are used to compute pair-wise similarities among paragraphs\\nto compute the number of authors and the assignments of authors.\\nJiang et al. [ 36] also apply transformer-based neural networks. However, they relied\\non the Electra model [ 37], which has been shown to be more efficient in training than\\nmasked-language modeling training as used in BERT. The authors chose to utilize three\\npre-trained Electra models for the three subtasks, depending on subtask complexity and\\nthe amount of data available.\\nZi et al. [ 38] also apply BERT to compute word representations using masked-language\\nmodeling (MLM) training. These representations are fed into a Bi-LSTM (Bidirectional\\nLong Short-term Memory) to enhance the representations with context information. The\\nrepresentations are then fed to a convolution and a max-pooling layer to compute a more\\ndense representation. A fully connected layer is used to compute the final predictions.\\nRodríguez-Losada and Castro [ 39] apply a mixture of approaches for the three subtasks.\\nTo represent the given texts as features, they use transformer models, the frequency of\\npunctuation marks, and the frequency of discourse markers. For Subtask 1, they compute\\nthe similarity between all consecutive paragraphs in a given document and predict a style\\nchange at the paragraph boundary with the lowest similarity. For the subtasks 2 and 3,',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 5}},\n",
              " {'text': 'they compute similarities for each of the three feature categories and define a similarity\\nthreshold for each category. They predict a style change if either (a) all similarities are\\nunder the threshold or (b) if two of the three similarities were under the threshold.\\nZhang et al. [ 40] utilize a prompt-based model to determine the similarity in writing\\nstyle between two adjacent paragraphs or sentences. They train a BERT model to learn\\nhow to fill in the blank in a text of the form ’They are the [blank] writing style: {First\\nParagraph} and {Second Paragraph}’. For ’[blank]’ they use a vocabulary of possible\\nterms that cover a range of similarities, including terms such as ’same’, ’equal’, ’different’,\\n’unlike’ etc. These predictions are then used to solve all three tasks.\\nLin et al. [ 41] apply an ensemble model to solve this year’s tasks. They trained three\\nseparate classifiers for determining whether a given pair of paragraphs or sentences is\\nwritten by the same author or not. Each of these classifiers is based on a different pre-\\ntrained language model for feature extraction: one on BERT [ 35], one on RoBERTa [ 42],\\nand one on ALBERT [ 43]. The three classifiers are combined in a majority voting\\nensemble to make a final prediction.\\nAlvi et al. [ 44] apply a set of handcrafted discourse markers to characterize the writing\\nstyle for a paragraph or sentence. For Sutask 1, they identify conversational patterns\\nto predict the position of the author change. For the Sutasks 2 and 3, they extract\\noccurrence counts for their set of discourse markers to first determine the number of\\nauthors in a document via a random forest model, and then use 𝑘-means clustering to\\ncluster paragraphs or sentences into author clusters.\\n5. Evaluation Results\\nThe summary of the evaluation results for the nine submissions to the Style Change\\nDetection task at PAN 2022, as well as a baseline, is shown in Table 1.\\nThe baseline approach uses uniformly distributed random predictions to assign para-\\ngraphs to authors, and then infers style change locations based on these, predicting\\na style change between all paragraphs or sentences that have a different author label.\\nThe random author assignments take into account that authors must be labelled with\\nincreasing identifiers depending on the order in which they first appear in a document.\\nIn other words, the first author appearing in the document is assigned label 1, the second\\nauthor label 2, etc. As can be seen in Table 1, all submitted approaches outperformed\\nthe baseline for Subtask 1 and Subtask 3 in terms of F 1score. For Subtask 2, only\\nthe approach submitted by Al-Shamasi and Menai [ 33] achieved a lower F 1score than\\nthe baseline. A similar picture emerges for the JER and DER scores, where the same\\nsubmission is the only one that has a higher JER than the baseline.\\nIn terms of submitted approaches, this year (and for the first time) we received not\\nonly submissions with intrinsic approaches, but also a single submission with an extrinsic\\napproach to style change detection. In Table 1, these approaches are shown separated\\nsince they are inherently not comparable. The extrinsic approach, graner22, clearly\\noutperforms all other approaches due to its use of external information. In the following,\\nwe will therefore focus our discussions on the submitted intrinsic approaches. For these,',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 6}},\n",
              " {'text': 'Table 1\\nOverallresultsforthestylechangedetectiontask,rankedbyaverageF 1performanceacrossallthree\\nsubtasks (ST). The best (intrinsic) score for each metric is highlighted in bold.\\nParticipant ST1 F 1ST2 F1ST3 F1ST3 DER ST3 JER\\nIntrinsic Approaches\\ntzumilin22 0.7540 0.5100 0.7156 0.1941 0.3095\\nxinyin22 0.7346 0.4687 0.6720 0.2380 0.3138\\nqidilao22 0.7471 0.4170 0.6314 0.2636 0.3641\\nzhang22 0.7162 0.4174 0.6581 0.2886 0.3556\\nyang22 0.6690 0.4011 0.6483 0.2964 0.3677\\nalvi22 0.7052 0.3213 0.5636 0.3924 0.5218\\ncastro22a 0.5661 0.2735 0.5565 0.4035 0.5771\\nalshmasy22 0.5272 0.2207 0.4995 0.4240 0.6444\\nExtrinsic Approaches\\ngraner22 0.9932 0.9855 0.9929 0.0040 0.0040\\nBaseline\\nRandom 0.3222 0.2651 0.4809 0.4568 0.5938\\nthe overall best results were achieved by Lin et al. [ 41], whose approach achieved the\\nbest scores across all the metrics we considered. Some of the other approaches achieved\\na similar, albeit slightly reduced performance, especially those of Jiang et al. [ 36] and\\nLao et al. [ 34].\\nIn addition to the overall scores given in Table 1, we also analyzed how the participant’s\\nsystems performed depending on the true number of authors in a document. This is\\nshown only done for Subtask 2 and Subtask 3, since all documents for Subtask 1 were\\nwritten by exactly two authors. First, we considered single-author versus multi-author\\ntask2 task3\\nMetric0.00.20.40.60.81.0ScoreOverall Scores For Single-Author Documents\\nalshmasy\\nalvi\\ncastroqidilao\\ntzumilin\\nxinyinyang\\nzhang\\n(a)Single-author documents\\ntask2 task3\\nMetric0.00.20.40.60.81.0ScoreOverall Scores For Multi-Author Documents\\nalshmasy\\nalvi\\ncastroqidilao\\ntzumilin\\nxinyinyang\\nzhang (b)Multi-author documents\\nFigure 2: Scores (F 1) for the subtasks 2 and 3 separately for single-author (left) and multi-author\\ndocuments (righ).',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 7}},\n",
              " {'text': '1 2 3 4 5\\nNumber of Authors0.00.20.40.60.81.0ScoreT ask 2 F1-Score Over Number of Authors\\nparticipant\\nalshmasy\\nalvi\\ncastro\\nqidilao\\ntzumilin\\nxinyin\\nyang\\nzhang(a)Task 2\\n1 2 3 4 5\\nNumber  of Authors0.00.20.40.60.81.0ScoreT ask 3 F1-Score Over Number of Authors\\nalshmasy\\nalvi\\ncastro\\nqidilaotzumilin\\nxinyin\\nyang\\nzhang (b)Task 3\\nFigure 3: Scores (F 1) for Task 2 and Task 3, depending on the true number of authors in a document.\\ndocuments. The results of this analysis are shown in Figure 2. The first interesting\\nobservation that we can make here is that all systems perform better if a document\\nwas written by multiple authors. We can also see that the ranking of the systems is\\npretty stable, with only small changes, such as the approaches by Rodríguez-Losada\\nand Castro [ 39] and Lao et al. [ 34] outperforming the approach submitted by Alvi et\\nal. [44] for multi-author documents. We also looked at how the performance of all systems\\nchanged with the concrete number of authors (see Figure 3). For Subtask 2, we observe\\nan performance increase for all systems until the number of three authors is reached in a\\ndocument. When confronted with more authors, the systems behave differently: Some\\nsystems show a continued performance increase up to five authors (which is the maximum\\nnumber of authors in a document in our datasets), while other systems show a drop in\\nperformance. For Subtask 3, we can see that almost all systems have a performance\\npeak at two authors, with a sharp increase when going from single-author documents to\\ntwo-author documents, followed by a slow decline as the number of authors grows.\\nFinally, we took a look at how the JER and DER scores for task 2 changed depending\\n1 2 3 4 5\\nNumber of Authors0.00.20.40.60.81.0ScoreT ask 2 JER Over Number of Authors\\nalshmasy\\nalvi\\ncastro\\nqidilaotzumilin\\nxinyin\\nyang\\nzhang\\n(a)JER\\n1 2 3 4 5\\nNumber of Authors0.00.20.40.60.81.0ScoreT ask 2 DER Over Number of Authors\\nalshmasy\\nalvi\\ncastro\\nqidilaotzumilin\\nxinyin\\nyang\\nzhang (b)DER\\nFigure 4: Scores (JER and DER) for Task 2, depending on the true number of authors in a document.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 8}},\n",
              " {'text': 'on the number of authors. The result for this are given in Figure 4. Here, performance\\ngenerally seems to decrease the more authors are in a document.\\n6. Conclusion\\nIn the 2022 edition of the Style Change Detection task at PAN, we asked participants\\nto detect style changes on the paragraph and sentence level (subtasks 1 and 3) and to\\nassign paragraphs to authors based on the detected style changes (Subtask 2). We have\\nreceived nine submissions by participants. The best results were obtained by utilizing\\npre-trained language models (BERT or Electra) to compute semantic representations of\\nthe texts across all three tasks. Altogether, we consider the achieved performance values\\nas solid and promising.\\nReferences\\n[1]E. Stamatatos, M. Tschuggnall, B. Verhoeven, W. Daelemans, G. Specht, B. Stein,\\nM. Potthast, Clustering by Authorship Within and Across Documents, in: Working\\nNotes Papers of the CLEF 2016 Evaluation Labs, CEUR Workshop Proceedings,\\nCLEF and CEUR-WS.org, 2016. URL: http://ceur-ws.org/Vol-1609/ .\\n[2]M. Tschuggnall, E. Stamatatos, B. Verhoeven, W. Daelemans, G. Specht, B. Stein,\\nM. Potthast, Overview of the Author Identification Task at PAN 2017: Style Breach\\nDetection and Author Clustering, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl\\n(Eds.), Working Notes Papers of the CLEF 2017 Evaluation Labs, volume 1866\\nof CEUR Workshop Proceedings, CEUR-WS.org, 2017. URL: http://ceur-ws.org/\\nVol-1866/ .\\n[3]M. Kestemont, M. Tschuggnall, E. Stamatatos, W. Daelemans, G. Specht, B. Stein,\\nM. Potthast, Overview of the Author Identification Task at PAN-2018: Cross-domain\\nAuthorship Attribution and Style Change Detection, in: L. Cappellato, N. Ferro,\\nJ.-Y. Nie, L. Soulier (Eds.), Working Notes Papers of the CLEF 2018 Evaluation\\nLabs, volume 2125 of CEUR Workshop Proceedings, CEUR-WS.org, 2018. URL:\\nhttp://ceur-ws.org/Vol-2125/ .\\n[4]E. Zangerle, M. Tschuggnall, G. Specht, M. Potthast, B. Stein, Overview of the\\nStyle Change Detection Task at PAN 2019, in: L. Cappellato, N. Ferro, D. Losada,\\nH. Müller (Eds.), CLEF 2019 Labs and Workshops, Notebook Papers, CEUR-WS.org,\\n2019. URL: http://ceur-ws.org/Vol-2380/ .\\n[5]E. Zangerle, M. Mayerl, G. Specht, M. Potthast, B. Stein, Overview of the Style\\nChange Detection Task at PAN 2020, in: L. Cappellato, C. Eickhoff, N. Ferro,\\nA. Névéol (Eds.), CLEF 2020 Labs and Workshops, Notebook Papers, CEUR-WS.org,\\n2020. URL: http://ceur-ws.org/Vol-2696/ .\\n[6]E. Zangerle, M. Mayerl, , M. Potthast, B. Stein, Overview of the Style Change\\nDetection Task at PAN 2021, in: G. Faggioli, N. Ferro, A. Joly, M. Maistro, F. Piroi\\n(Eds.), CLEF 2021 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2021.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 9}},\n",
              " {'text': '[7]D. Karaś, M. Śpiewak, P. Sobecki, OPI-JSA at CLEF 2017: Author Clustering\\nand Style Breach Detection—Notebook for PAN at CLEF 2017, in: L. Cappellato,\\nN. Ferro, L. Goeuriot, T. Mandl (Eds.), CLEF 2017 Evaluation Labs and Workshop\\n– Working Notes Papers, CEUR-WS.org, 2017. URL: http://ceur-ws.org/Vol-1866/ .\\n[8]J. Khan, Style Breach Detection: An Unsupervised Detection Model—Notebook\\nfor PAN at CLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.),\\nCLEF 2017 Evaluation Labs and Workshop – Working Notes Papers, CEUR-WS.org,\\n2017. URL: http://ceur-ws.org/Vol-1866/ .\\n[9]K. Safin, R. Kuznetsova, Style Breach Detection with Neural Sentence Embeddings—\\nNotebook for PAN at CLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl\\n(Eds.), CLEF 2017 Evaluation Labs and Workshop – Working Notes Papers, CEUR-\\nWS.org, 2017. URL: http://ceur-ws.org/Vol-1866/ .\\n[10]E. Stamatatos, Intrinsic Plagiarism Detection Using Character $n$-gram Profiles,\\nin: B. Stein, P. Rosso, E. Stamatatos, M. Koppel, E. Agirre (Eds.), SEPLN 2009\\nWorkshop on Uncovering Plagiarism, Authorship, and Social Software Misuse (PAN\\n09), Universidad Politécnica de Valencia and CEUR-WS.org, 2009, pp. 38–46. URL:\\nhttp://ceur-ws.org/Vol-502 .\\n[11] M. Koppel, J. Schler, S. Argamon, Computational methods in authorship attribution,\\nJournal of the American Society for Information Science and Technology 60 (2009)\\n9–26.\\n[12] D. I. Holmes, The Evolution of Stylometry in Humanities Scholarship, Literary and\\nLinguistic Computing 13 (1998) 111–117.\\n[13] R. Zheng, J. Li, H. Chen, Z. Huang, A Framework for Authorship Identification of\\nOnline Messages: Writing-Style Features and Classification Techniques, Journal of\\nthe American Society for Information Science and Technology 57 (2006) 378–393.\\n[14]M. Tschuggnall, G. Specht, Countering Plagiarism by Exposing Irregularities in\\nAuthors’ Grammar, in: Proceedings of the European Intelligence and Security\\nInformatics Conference (EISIC), IEEE, Uppsala, Sweden, 2013, pp. 15–22.\\n[15]M. Tschuggnall, G. Specht, Automatic decomposition of multi-author documents\\nusing grammar analysis, in: F. Klan, G. Specht, H. Gamper (Eds.), Proceedings of the\\n26th GI-Workshop Grundlagen von Datenbanken, volume 1313 of CEUR Workshop\\nProceedings, CEUR-WS.org, 2014, pp. 17–22. URL: http://ceur-ws.org/Vol-1313 .\\n[16]A. Glover, G. Hirst, Detecting Stylistic Inconsistencies in Collaborative Writing,\\nSpringer London, London, 1996, pp. 147–168. doi: 10.1007/978-1-4471-1482-6_12 .\\n[17]S. Meyer zu Eißen, B. Stein, Intrinsic Plagiarism Detection, in: M. Lalmas,\\nA. MacFarlane, S. Rüger, A. Tombros, T. Tsikrika, A. Yavlinsky (Eds.), Advances\\nin Information Retrieval. 28th European Conference on IR Research (ECIR 2006),\\nvolume 3936 of Lecture Notes in Computer Science, Springer, Berlin Heidelberg\\nNew York, 2006, pp. 565–569. doi: 10.1007/11735106_66 .\\n[18] B. Stein, S. Meyer zu Eißen, Intrinsic Plagiarism Analysis with Meta Learning, in:\\nB. Stein, M. Koppel, E. Stamatatos (Eds.), 1st Workshop on Plagiarism Analysis,\\nAuthorship Identification, and Near-Duplicate Detection (PAN 2007) at SIGIR, 2007,\\npp. 45–50. URL: http://ceur-ws.org/Vol-276 .\\n[19]B. Stein, N. Lipka, P. Prettenhofer, Intrinsic Plagiarism Analysis, Language',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 10}},\n",
              " {'text': 'Resources and Evaluation (LRE) 45 (2011) 63–82. doi: 10.1007/s10579-010-9115-y .\\n[20]M. Koppel, N. Akiva, I. Dershowitz, N. Dershowitz, Unsupervised decomposition\\nof a document into authorial components, in: Proceedings of the 49th Annual\\nMeeting of the Association for Computational Linguistics: Human Language Tech-\\nnologies, Association for Computational Linguistics, Portland, Oregon, USA, 2011,\\npp. 1356–1364. URL: https://www.aclweb.org/anthology/P11-1136 .\\n[21] M. Koppel, N. Akiva, I. Dershowitz, N. Dershowitz, Unsupervised decomposition of a\\ndocument into authorial components, in: D. Lin, Y. Matsumoto, R. Mihalcea (Eds.),\\nThe 49th Annual Meeting of the Association for Computational Linguistics: Human\\nLanguage Technologies, Proceedings of the Conference, 19-24 June, 2011, Portland,\\nOregon, USA, The Association for Computer Linguistics, 2011, pp. 1356–1364. URL:\\nhttp://www.aclweb.org/anthology/P11-1136 .\\n[22] N. Akiva, M. Koppel, Identifying Distinct Components of a Multi-author Document,\\nin: N. Memon, D. Zeng (Eds.), 2012 European Intelligence and Security Informatics\\nConference, EISIC 2012, IEEE Computer Society, 2012, pp. 205–209. URL: https:\\n//doi.org/10.1109/EISIC.2012.16 . doi:10.1109/EISIC.2012.16 .\\n[23]N. Akiva, M. Koppel, A Generic Unsupervised Method for Decomposing Multi-\\nAuthor Documents, JASIST 64 (2013) 2256–2264. URL: https://doi.org/10.1002/\\nasi.22924 . doi:10.1002/asi.22924 .\\n[24]A. Rexha, S. Klampfl, M. Kröll, R. Kern, Towards a more fine grained analysis of\\nscientific authorship: Predicting the number of authors using stylometric features,\\nin: P. Mayr, I. Frommholz, G. Cabanac (Eds.), Proceedings of the Third Workshop\\non Bibliometric-enhanced Information Retrieval co-located with the 38th European\\nConference on Information Retrieval (ECIR 2016), volume 1567 of CEUR Workshop\\nProceedings, CEUR-WS.org, 2016, pp. 26–31. URL: http://ceur-ws.org/Vol-1567 .\\n[25]I. Bensalem, P. Rosso, S. Chikhi, Intrinsic plagiarism detection using n-gram\\nclasses, in: Proceedings of the 2014 Conference on Empirical Methods in Natural\\nLanguage Processing (EMNLP), Association for Computational Linguistics, Doha,\\nQatar, 2014, pp. 1459–1464. URL: https://www.aclweb.org/anthology/D14-1153 .\\ndoi:10.3115/v1/D14-1153 .\\n[26] C. Giannella, An Improved Algorithm for Unsupervised Decomposition of a Multi-\\nAuthor Document, JASIST 67 (2016) 400–411. URL: https://doi.org/10.1002/asi.\\n23375 . doi:10.1002/asi.23375 .\\n[27] D. Zlatkova, D. Kopev, K. Mitov, A. Atanasov, M. Hardalov, I. Koychev, P. Nakov,\\nAn Ensemble-Rich Multi-Aspect Approach for Robust Style Change Detection,\\nin: L. Cappellato, N. Ferro, J.-Y. Nie, L. Soulier (Eds.), CLEF 2018 Evaluation\\nLabs and Workshop – Working Notes Papers, CEUR-WS.org, 2018. URL: http:\\n//ceur-ws.org/Vol-2125/ .\\n[28]A. Iyer, S. Vosoughi, Style Change Detection Using BERT, in: L. Cappellato,\\nN. Ferro, A. Névéol, C. Eickhoff (Eds.), CLEF 2020 Labs and Workshops, Notebook\\nPapers, CEUR-WS.org, 2020.\\n[29] Z. Zhang, X. Miao, Z. Peng, J. Zeng, H. Cao, J. Zhang, Z. Xiao, X. Peng, Z. Chen,\\nUsing Single BERT For Three Tasks Of Style Change Detection, in: G. Faggioli,\\nN. Ferro, A. Joly, M. Maistro, F. Piroi (Eds.), CLEF 2021 Labs and Workshops,',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 11}},\n",
              " {'text': 'Notebook Papers, CEUR-WS.org, 2021.\\n[30]M. Potthast, T. Gollub, M. Wiegmann, B. Stein, TIRA Integrated Research\\nArchitecture, in: N. Ferro, C. Peters (Eds.), Information Retrieval Evaluation in a\\nChanging World, The Information Retrieval Series, Springer, Berlin Heidelberg New\\nYork, 2019. doi: 10.1007/978-3-030-22948-1_5 .\\n[31] J. G. Fiscus, J. Ajot, M. Michel, J. S. Garofolo, The rich transcription 2006 spring\\nmeeting recognition evaluation, in: International Workshop on Machine Learning\\nfor Multimodal Interaction, Springer, 2006, pp. 309–322.\\n[32] N. Ryant, K. Church, C. Cieri, A. Cristia, J. Du, S. Ganapathy, M. Liberman, The\\nsecond dihard diarization challenge: Dataset, task, and baselines, arXiv preprint\\narXiv:1906.07839 (2019).\\n[33] S. Al-Shamasi, M. Menai, Ensemble-Based Clustering for Writing Style Change De-\\ntection in Multi-Authored Textual Documents, in: CLEF 2022 Labs and Workshops,\\nNotebook Papers, CEUR-WS.org, 2022.\\n[34]Q. Lao, L. Ma, W. Yang, Y. Zexian, D. Yuan, Z. Tan, L. Liang, Style Change\\nDetection Based On Bert And Conv1d, in: CLEF 2022 Labs and Workshops,\\nNotebook Papers, CEUR-WS.org, 2022.\\n[35]J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, BERT: Pre-training of deep\\nbidirectional transformers for language understanding, in: Proceedings of the\\n2019 Conference of the North American Chapter of the Association for Compu-\\ntational Linguistics: Human Language Technologies, Volume 1 (Long and Short\\nPapers), Association for Computational Linguistics, Minneapolis, Minnesota, 2019,\\npp. 4171–4186. URL: https://aclanthology.org/N19-1423 . doi:10.18653/v1/N19-1423 .\\n[36] X. Jiang, H. Qi, Z. Zhang, Style Change Detection: Method Based On Pre-trained\\nModel And Similarity Recognition, in: CLEF 2022 Labs and Workshops, Notebook\\nPapers, CEUR-WS.org, 2022.\\n[37] K. Clark, M.-T. Luong, Q. V. Le, C. D. Manning, Electra: Pre-training text encoders\\nas discriminators rather than generators, arXiv preprint arXiv:2003.10555 (2020).\\n[38]J. Zi, L. Zhou, Z. Liu, Style Change Detection Based On Bi-LSTM And Bert, in:\\nCLEF 2022 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2022.\\n[39] C. A. R. Losada, D. C. Castro, Three style similarity: sentence-embedding, auxiliary\\nwords, punctuation, in: CLEF 2022 Labs and Workshops, Notebook Papers, CEUR-\\nWS.org, 2022.\\n[40]Z. Zhang, Z. Han, L. Kong, Style Change Detection based on Prompt, in: CLEF\\n2022 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2022.\\n[41] T.-M. Lin, C.-Y. Chen, Y.-W. Tzeng, L.-H. Lee, Ensemble Pre-trained Transformer\\nModels for Writing Style Change Detection, in: CLEF 2022 Labs and Workshops,\\nNotebook Papers, CEUR-WS.org, 2022.\\n[42]Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettle-\\nmoyer, V. Stoyanov, RoBERTa: A Robustly Optimized BERT Pretraining Approach,\\narXiv preprint arXiv:1907.11692 (2019).\\n[43]Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, R. Soricut, Albert: A Lite\\nBERT for Self-supervised Learning of Language Representations, arXiv preprint\\narXiv:1909.11942 (2019).',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 12}},\n",
              " {'text': '[44] F. Alvi, H. Algafri, N. Alqahtani, Style Change Detection using Discourse Markers,\\nin: CLEF 2022 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2022.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper4.pdf', 'page_number': 13}},\n",
              " {'text': 'Overview of PAN 2021: Authorship Veriﬁcation,\\nProﬁling Hate Speech Spreaders on Twitter,\\nand Style Change Detection\\nJanek Bevendorff,1BERTa Chulvi,2Gretel Liz De La Peña Sarracén,2\\nMike Kestemont,3Enrique Manjavacas,3Ilia Markov,3Maximilian Mayerl,4\\nMartin Potthast,5Francisco Rangel,6Paolo Rosso,2Efstathios Stamatatos,7\\nBenno Stein,1Matti Wiegmann,1Magdalena Wolska,1and Eva Zangerle4\\n1Bauhaus-Universität Weimar, Germany\\n2Universitat Politècnica de València, Spain\\n3University of Antwerp, Belgium\\n4University of Innsbruck, Austria\\n5Leipzig University, Germany\\n6Symanto Research, Germany\\n7University of the Aegean, Greece\\npan@webis.de https://pan.webis.de\\nAbstract The paper gives a brief overview of the three shared tasks organized\\nat the PAN 2021 lab on digital text forensics and stylometry hosted at the CLEF\\nconference. The tasks include authorship veriﬁcation across domains, author pro-\\nﬁling for hate speech spreaders, and style change detection for multi-author doc-\\numents. In part the tasks are new and in part they continue and advance past\\nshared tasks, with the overall goal of advancing the state of the art, providing for\\nan objective evaluation on newly developed benchmark datasets.\\n1 Introduction\\nThe PAN workshop series has been organized since 2007 and has included shared\\ntasks on speciﬁc computational challenges related to authorship analysis, computational\\nethics, and determining the originality of a piece of writing. Over the years, the respec-\\ntive organizing committees of the 51 shared tasks have assembled evaluation resources\\nfor the aforementioned research disciplines that amount to 48 datasets plus nine datasets\\ncontributed by the community.1Each new dataset introduced new variants of author\\nidentiﬁcation, proﬁling, and author obfuscation tasks as well as multi-author analysis\\nand determining the morality, quality, or originality of a text. The 2021 edition of PAN\\ncontinues in the same vein, introducing new resources and previously unconsidered\\nproblems to the community. As in earlier editions, PAN is committed to reproducible\\nresearch in IR and NLP and all shared tasks will ask for software submissions on our\\nTIRA platform [22]. The following sections outline the task deﬁnitions and summarize\\nthe participants’ results.\\n1https://pan.webis.de/data.html',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 1}},\n",
              " {'text': '2 Authors Suppressed Due to Excessive Length\\n2 Author Proﬁling\\nAuthor proﬁling is the problem of distinguishing between classes of authors by study-\\ning how language is shared by people. This helps in identifying authors’ individual\\ncharacteristics, such as age, gender, and language variety, among others. During the\\nyears 2013-2020 we addressed several of these aspects in the shared tasks organised at\\nPAN.2In 2013 the aim was to identify gender and age in social media texts for English\\nand Spanish [31]. In 2014 we addressed age identiﬁcation from a continuous perspec-\\ntive (without gaps between age classes) in the context of several genres, such as blogs,\\nTwitter, and reviews (in Trip Advisor), both in English and Spanish [28]. In 2015, apart\\nfrom age and gender identiﬁcation, we addressed also personality recognition on Twit-\\nter in English, Spanish, Dutch and Italian [33]. In 2016, we addressed the problem of\\ncross-genre gender and age identiﬁcation (training on Twitter data and testing on blogs\\nand social media data) in English, Spanish, and Dutch [34]. In 2017, we addressed\\ngender and language variety identiﬁcation in Twitter in English, Spanish, Portuguese,\\nand Arabic [32]. In 2018, we investigated gender identiﬁcation in Twitter from a mul-\\ntimodal perspective, considering also the images linked within tweets; the dataset was\\ncomposed of English, Spanish, and Arabic tweets [30]. In 2019 the focus was on pro-\\nﬁling bots and discriminating bots from humans on the basis of textual data only [27].\\nWe used Twitter data both in English and Spanish. Bots play a key role in spreading\\ninﬂammatory content and also fake news. Advanced bots that generated human-like\\nlanguage, also with metaphors, were the most difﬁcult to proﬁle. It is interesting to note\\nthat when bots were proﬁled as humans, they were mostly confused with males. In 2020\\nwe focused on proﬁling fake news spreaders [25]. The easiness of publishing content\\nin social media has led to an increase in the amount of disinformation that is published\\nand shared. The goal was to proﬁle those authors who have shared some fake news in\\nthe past. Early identiﬁcation of possible fake news spreaders on Twitter should be the\\nﬁrst step towards preventing fake news from further dissemination.\\nAuthor proﬁling at PAN’21: Hate speech spreaders on Twitter Having previously\\nproﬁled bots and fake news spreaders, at PAN’21 we have focused on PROFILING HATE\\nSPEECH SPREADERS in social media, more speciﬁcally on Twitter, addressing the prob-\\nlem both in English and Spanish, as we did in the previous author proﬁling tasks. The\\ngoal has been to identify those Twitter users that can be considered haters, depending\\non the number of tweets with hateful content that they had spread.\\nHate speech (HS) is commonly deﬁned as any communication that disparages a\\nperson or a group on the basis of some characteristic, such as race, colour, ethnicity,\\ngender, sexual orientation, nationality, religion, or others [20]. Given the huge amount\\nof user-generated content on the Web and, in particular, on social media, the problem\\nof detecting and, if possible, contrasting the HS diffusion, is becoming fundamental,\\nfor instance, in the ﬁght against misogyny and xenophobia [1]. While most of the ap-\\nproaches focus on detecting whether a text is hateful or not, few works focus on the\\nuser account level detection. In [17] the authors studied the ﬂow of posts generated\\n2To generate the datasets, we have followed a methodology that complies with the EU General\\nData Protection Regulation [26].',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 2}},\n",
              " {'text': 'Title Suppressed Due to Excessive Length 3\\nby users on Gab, analysing the proﬁles and network of hateful and non-hateful users,\\nfocusing on the diffusion dynamics of hateful users. The observations suggested that\\nhateful content propagates farther, wider and faster. Unlike this work, where the anal-\\nysis was carried out statically, in [18] dynamic graphs were employed to investigate\\nthe temporal effects of hate speech. In [4] the authors presented a comparative study of\\nhate speech users on Twitter. They investigated the distinctive characteristics of hateful\\nusers and targeted users in terms of their proﬁle, activities, and online visibility. They\\nfound that hateful users can be more popular and that participating in hate speech can\\nresult in a greater online visibility. In [35] the focus was also on users for hate speech\\ndetection on Twitter. This study used a methodology to obtain a graph given the entire\\nproﬁle of users, and investigated the difference between hateful users and normal ones\\nin terms of activity patterns, word usage and network structure. The authors observed\\nthat hateful users are densely connected, thus they focused on exploiting the network of\\nconnections. In [23] the authors proposed a model that considers intra-user and inter-\\nuser representation learning for hate speech detection. In [6] the focus was on studying\\nthe use of emojis in white nationalist conversation on Twitter. A difference between the\\n‘pro’ and ‘anti’ nationalist was observed.\\nDataset and task As an evaluation setup, we have created a collection that contains\\nSpanish and English tweets posted by users on Twitter. To build the PAN-AP-2021\\ncorpus3we have proceeded as follows. Firstly, we have looked for users considered\\npotential haters. To do so, we have followed two approaches: (1) a keyword-based one\\n(e.g. searching for hateful words towards women or immigrants); and (2) a user-based\\none, by inspecting users known as haters (e.g. users appearing in reports and/or press)\\nand following their networks (followers and followees). Secondly, for the identiﬁed\\nusers, we have collected their timelines and manually annotated those tweets conveying\\nhate. Thirdly, we have labelled as “keen to spread hate speech” those users with more\\nthan ten hateful tweets. Finally, we have collected two hundred tweets per Twitter user\\nto build up the ﬁnal dataset. This dataset consists of three hundred users per language,\\nwith two hundred tweets per user. Two hundred users per language have been provided\\nfor training purposes, keeping the remaining one hundred for testing purposes. The\\ndataset is completely balanced per class (hater vs. not hater) as well as by the number\\nof tweets per user.\\nThe goal in the task is to classify the user as hater or not hater (binary classiﬁcation).\\nGiven that we have a balanced dataset (even though this is not a realistic scenario,4\\n3We should highlight that we are aware of the legal and ethical issues related to collecting,\\nanalysing and proﬁling social media data [26] and that we are committed to legal and ethical\\ncompliance in our scientiﬁc research and its outcomes. For instance, we have anonymised the\\nuser name, masked all the user mentions and also the class has been changed in order to avoid\\nany explicit mention.\\n4In a realistic scenario, we would need to know a priori the distribution of haters vs non-haters;\\ndepending on the study, the number of hatred messages in Twitter ranges from 1% [21] to\\n10%-15% [39], although when the target are communities such as the LGBT, up to 78% of\\nrespondents had experienced online anti-LGBT and hate speech in the last 5 years (https:\\n//www.report-it.org.uk/ﬁles/online-crime-2020_0.pdf). Furthermore, one of the aims of this',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 3}},\n",
              " {'text': '4 Authors Suppressed Due to Excessive Length\\nTable 1. Baselines performance in terms of accuracy on the PAN-AP-2021 dataset on Hate\\nSpeech Spreaders identiﬁcation.\\nBaseline English Spanish Average\\nLDSE 70.0 82.0 76.0\\nSVM + charn-grams 69.0 83.0 76.0\\nNN + wordn-grams 65.0 83.0 74.0\\nUSE-LSTM 56.0 79.0 67.5\\nXLMR-LSTM 62.0 73.0 67.5\\nMBERT-LSTM 59.0 75.0 67.0\\nTFIDF-LSTM 61.0 51.0 56.0\\nwe balance the dataset to prevent machine/deep learning models from being skewed\\ntowards the majority class) we use accuracy as the evaluation metric for the binary\\nclassiﬁcation. Then, we average both accuracies for English and Spanish to come up\\nwith the ﬁnal ranking.\\nEvaluation and results We have had a total number of 66 participants. The best per-\\nforming team has used a 100-dimension word embedding representation to feed a Con-\\nvolutional Neural Network. We have also run seven baselines covering the different\\ntechnologies our participants usually use:\\n–LDSE [29]: This method represents documents based on the probability distribu-\\ntion of the occurrence of their words in the different classes. The key concept of\\nLDSE is a weight representing the probability of a term to belong to one of the\\ntwo categories: hate speech spreader / non hate speech spreader. The distribution of\\nweights for a given document should be closer to the weights of its corresponding\\ncategory;\\n–Charactern-grams with nranging from 2 to 6 and a SVM;\\n–Wordn-grams with nranging from 1 to 3 and a Neural Network (NN);\\n–Universal Sentence Encoder (USE) feeding up a BiLSTM;\\n–XLM-Roberta (XLMR) transformer feeding up a BiLSTM;\\n–Multilingual BERT (MBERT) transformer to feed up a BiLSTM;\\n–TFIDF vectors representing each user’s text to feed up a BiLSTM.\\nThe baseline results are shown in Table 1. Out of the 66 participants only 7 outper-\\nformed LDSE and SVM with char n-grams baselines, further 7 participants also out-\\nperformed the NN with word n-grams baseline, and only one was worse than the\\nTFIDF+LSTM baseline. Only 4 teams participated just in English. More details will\\nbe available in the overview paper [24].\\n3 Authorship Veriﬁcation\\nAuthor identiﬁcation is concerned with the automated identiﬁcation of the individual(s)\\nwho authored an anonymous document on the basis of text-internal properties related\\nshared task is to foster research on proﬁling haters in order to address this problem automat-\\nically.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 4}},\n",
              " {'text': 'Title Suppressed Due to Excessive Length 5\\nto language and writing style [37, 9, 16]. Computational author identiﬁcation has been\\na long-running subtask at PAN with a reasonably steady number of participants over\\nthe years. While authorship has been studied via quantitative means for several decades\\nby now, the academic and industrial interest in this task shows no signs of abating.\\nThe history of this ﬁeld is characterized by a number of interesting developments and\\nthe seminal application of machine learning to the problem has been a clear landmark\\nnear the end of the previous century.5Today, machine learning can be considered the\\ndominant paradigm in the ﬁeld, though certain otherwise ubiquitous methods have been\\nslow to gain a foothold. Deep learning via neural networks, for example, has become the\\ndominant form of machine learning in many ﬁelds, yet has remained relatively uncom-\\nmon in recent editions of the authorship track at PAN and in the ﬁeld of computational\\nauthorship studies in general. In the past, we tentatively ascribed this absence to (1) the\\nlack of large-scale training resources in this ﬁeld and (2) the increased infrastructural\\nchallenges that come with the hardware requirements of large neural networks [14].\\nThis problem is exacerbated by our requirement for participants to submit fully-ﬂedged\\nsoftware systems to the TIRA platform [22] instead of only their ﬁnished runs. This has\\nbeen a clear incentive for us to try scaling up the training resources that we can make\\navailable to participants\\nScaling up resources for authorship veriﬁcation at PAN’21 With the view to bench-\\nmarking authorship systems at a much larger scale, our tasks in recent years [14, 12]\\nhave focused on transformative literature, so-called “fanﬁction” [8], a text variety that is\\nnowadays abundantly available on the internet [5] with rich metadata and in many lan-\\nguages. Additionally, fanﬁction is an excellent source of material for studies of cross-\\ndomain scenarios, since users often publish “ﬁcs” ranging over multiple topical do-\\nmains (“fandoms”), such as Harry Potter, Twilight, or Marvel comics. The datasets we\\nprovided for our tasks at PAN’20 and PAN’21 were crawled from the long-established\\nfanﬁction community fanfiction.net . Access to the data can be requested on Zen-\\nodo.6\\nDataset and task The 2021 edition of the authorship veriﬁcation task built upon last\\nyear’s edition [10] with the same task layout and training data, yet with a conceptually\\ndifferent test set. The basic task remained authorship veriﬁcation, the most fundamental\\nand generally more demanding setup in the ﬁeld, where one is to approximate the target\\nfunction\\x1e: (Dk;du)! fT;Fg,Dkbeing a set of documensets of known authorship\\nby the same author and dubeing a document of unknown or disputed authorship. If\\n\\x1e(Dk;du) =T, then the author of Dkis also the author of duand if\\x1e(Dk;du) =F,\\nthen the author of Dkis not the same as the author of du. In our case, Dkcontains only\\na single document, since our datasets consist of document pairs . For the 2021 edition,\\nwe adopted a cross-domain setting in which Dkanddudo not share the topic or genre,\\nwhich was accomplished by sampling the texts from different fandoms.\\n5Machine learning emerged as a methodology in authorship attribution in the 1990s. The ﬁrst\\npaper to apply a text classiﬁcation approach in this domain is [19] to the best of our knowledge.\\n6https://zenodo.org/record/3716403',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 5}},\n",
              " {'text': '6 Authors Suppressed Due to Excessive Length\\nThe training resources were identical to those from last year and came in the form\\nof a “small” and “large” dataset. The large dataset contains 148,000 same-author and\\n128,000 different-authors pairs across 1,600 fandoms. Each single author has written in\\nat least two, but not more than six fandoms. The small training set is a subset of the large\\ntraining set with 28,000 same-author and 25,000 different-author pairs from the same\\n1,600 fandoms. The test set, however (19,999 text pairs in total) is conceptually differ-\\nent. While the overall sampling strategy remained the same, we shifted to an “open-set”\\nveriﬁcation scenario. Whereas last year’s “closed-set” test problems included only texts\\nfrom fandoms and authors that were already present in the training data, this year’s\\ntest set included only fresh and previously unseen authors and fandoms. This setup\\nforces participants into a “true” veriﬁcation problem, while the previous “closed-set”\\ntask (in principle) could have also been re-cast as an attribution task (although this was\\nnot known to the participants beforehand). The pure veriﬁcation task is generally con-\\nsidered more difﬁcult than attribution because of the stylistic idiosyncrasies of human\\nauthors which often require bespoke ad-hoc models.\\nEvaluation and results For each of the 19,999 problems (or text pairs) in the test set,\\nthe systems had to produce a scalar score ai(in the [0;1]range) indicating the (scaled)\\nprobability that the pair was written by the same author ( ai>0:5) or different authors\\n(ai<0:5). Systems could choose to leave problems too difﬁcult to answer undecided\\nby submitting a score of precisely ai= 0:5which is rewarded by some metrics. For this\\nyear’s evaluation, we used the same four evaluations metrics as last year (A UC-ROC,\\nF1,C@1 and F0:5u), to allow for a diverse assessment of the submitted systems. As a\\nresult of discussions at last year’s workshop, we also included the complement of the\\nBRIER score [3] as an additional metric.7The submitted systems are ranked by their\\nmean performance across all 5 metrics. Two baseline systems were made available to\\nthe participants: a compression-based approach [7] and a naive distance-based, ﬁrst-\\norder bag-of-words model [13]. We use a short-text variant of Koppel and Schler’s\\nunmasking [2, 15] as a third baseline whose source code is also freely available, but\\nwhich was not given explicitly to the participants. The overall results can be found in\\nTable 2. As in previous years, we also carried out pair-wise signiﬁcance tests (based on\\napproximate randomization, with the score as a reference metric) to be able to assess\\nwhether the answers between systems were considered signiﬁcantly different according\\nto conventional statistics. The outcome of this procedure is summarized in Table 3.\\nAs can be seen, most of the submitted systems reach an excellent performance\\n(many scoring >0:9for multiple metrics) in spite of the anticipated difﬁculty of the\\ntest set in comparison to last year. Last year’s best performing team again tops the list,\\nthough interestingly, the runner-up is a ﬁrst-time participant. Most systems produced\\nsigniﬁcantly differing set of answers, with the exception of the dense cohort following\\nthe system in ﬁrst place. Like last year, it is striking that systems calibrated on the large\\ndataset invariably and signiﬁcantly outperform their counterparts trained on the smaller\\ndataset indicating that these systems are capable of harnessing the increased size of the\\ncalibration resources well. Most systems outperform the three baselines, which encour-\\n7Thanks to Fabrizio Sebastiani (Consiglio Nazionale delle Ricerche, Italy) for this suggestion.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 6}},\n",
              " {'text': 'Title Suppressed Due to Excessive Length 7\\nTable 2. Final results for the cross-domain, open-set authorship veriﬁcation task at PAN’21.\\nSubmitted systems are ranked by their mean performance across ﬁve evaluation metrics. Best\\nresult per column is shown in bold. Participants were allowed to make one submission for both\\nthe small and the large calibration datasets.\\nSystem Dataset AUC-ROC C @1 F1 F0:5u BRIER Overall\\nboenninghoff21 large 0.9869 0.9502 0.9524 0.9378 0.9452 0.9545\\nembarcaderoruiz21 large 0.9697 0.9306 0.9342 0.9147 0.9305 0.9359\\nweerasinghe21 large 0.9719 0.9172 0.9159 0.9245 0.9340 0.9327\\nweerasinghe21 small 0.9666 0.9103 0.9071 0.9270 0.9290 0.9280\\nmenta21 large 0.9635 0.9024 0.8990 0.9186 0.9155 0.9198\\npeng21 small 0.9172 0.9172 0.9167 0.9200 0.9172 0.9177\\nembarcaderoruiz21 small 0.9470 0.8982 0.9040 0.8785 0.9072 0.9070\\nmenta21 small 0.9385 0.8662 0.8620 0.8787 0.8762 0.8843\\nrabinovits21 small 0.8129 0.8129 0.8094 0.8186 0.8129 0.8133\\nikae21 small 0.9041 0.7586 0.8145 0.7233 0.8247 0.8050\\nunmasking21 small 0.8298 0.7707 0.7803 0.7466 0.7904 0.7836\\ntyo21 large 0.8275 0.7594 0.7911 0.7257 0.8123 0.7832\\nnaive21 small 0.7956 0.7320 0.7856 0.6998 0.7867 0.7600\\ncompressor21 small 0.7896 0.7282 0.7609 0.7027 0.8094 0.7581\\nfutrzynski21 large 0.7982 0.6632 0.8324 0.6682 0.7957 0.7516\\nliaozhihao21 small 0.4962 0.4962 0.0067 0.0161 0.4962 0.3023\\nagingly demonstrates how the ﬁeld is making progress. More details on the results will\\nbe available in the overview paper [11].\\n4 Multi-Author Writing Style Analysis\\nThe goal of the style change detection task is to identify – based on an intrinsic style\\nanalysis – the text positions at which the author switches within a given multi-author\\ndocument. Detecting these positions is a crucial part of the authorship identiﬁcation\\nprocess and multi-author document analysis, but multi-author documents have been\\nlargely understudied in general.\\nThis task has been part of PAN since 2016 with varying task deﬁnitions, datasets,\\nand evaluation procedures. In 2016, participants were asked to identify and group frag-\\nments of a given document that correspond to individual authors [36]. In 2017, we\\nasked participants to detect whether a given document is multi-authored and, if this is\\nindeed the case, to determine the positions at which authorship changes [38]. Since this\\ntask was deemed as highly complex, its complexity was reduced in 2018 to asking par-\\nticipants only to predict whether a given document is single- or multi-authored [14].\\nFollowing the promising results, participants were asked in the 2019 task installment to\\nﬁrst detect whether a document was single- or multi-authored and then, if it was indeed\\nwritten by multiple authors, to predict the number of authors [42]. In 2020, based on\\nthe advances made over the previous years, we decided to go back towards the original\\ndeﬁnition of the task, i.e., ﬁnding the positions in a text where authorship changes. Par-\\nticipants ﬁrst had to determine whether a document was written by one or by multiple\\nauthors and – in the case of a multi-author document – to detect at which paragraphs\\nthe author changes [41].',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 7}},\n",
              " {'text': '8 Authors Suppressed Due to Excessive Length\\nTable 3. Pairwise signiﬁcance tests for approximate randomization with 10,000 bootstrap iter-\\nations, using F1as reference metric. Symbols: ‘=’ (not signiﬁcantly different with p > 0:5),\\n‘*’, ‘**’, ‘***’ (signiﬁcantly different with p < 0:05,p < 0:01,p < 0:001). Only the top-\\nperforming systems are shown here: a full comparison will be offered in the detailed overview\\npaper.\\nembarcaderoruiz21-large\\nweerasinghe21-large\\nweerasinghe21-small\\nmenta21-large\\npeng21-small\\nboenninghoff21-large *** *** *** *** ***\\nembarcaderoruiz21-large * = *** **\\nweerasinghe21-large *** *** =\\nweerasinghe21-small ** ***\\nmenta21-large ***\\nStyle change detection at PAN’21 For style change detection, a fundamental question\\nis the following: If multiple authors wrote a text together, can we ﬁnd evidence of this\\nfact, e.g., do we have a means to detect variations in the writing style? Answering this\\nquestion is one of the most difﬁcult and most interesting challenges in author identiﬁ-\\ncation and represents the only means to detecting plagiarism in a document if no other\\ntexts are given for comparison. Likewise, it can help to uncover “gifted authorship”,\\nto verify a claimed authorship, or to develop new technologies for writing assistance.\\nWe tackle this challenge by providing three style change detection tasks in increasing\\ndifﬁculty: (1) Single vs. Multiple Authors: given a text, ﬁnd out whether the text was\\nwritten by a single author or by multiple authors, (2) Style Change Basic: given a text\\nwritten by two authors that contains only a single style change, ﬁnd the position of this\\nchange, i.e., cut the text into two based on stylometric information (note that this task\\ncorresponds to authorship veriﬁcation where the two authors are responsible only for\\nthe ﬁrst and the remaining part of a text, respectively), (3) Style Change “Real-World”:\\ngiven a text written by two or more authors, ﬁnd all positions of writing style changes,\\ni.e., assign all paragraphs of a text uniquely to exactly one of all the authors you deem\\nresponsible for the multi-author document.\\nDataset and evaluation As in previous years, a novel dataset was created from posts\\nfrom the popular StackExchange network of Q&A sites. To generate the documents for\\nthe task, we used a dump of questions and answers from the StackExchange network\\nas our data source, of which we used a subset of communities8. We cleaned the data by\\nremoving questions and answers that were edited after they were originally posted and\\nby removing images, URLs, code snippets, block quotes and bullet lists from all ques-\\n8The following StackExchange sites were used: Code Review, Computer Graphics, CS Educa-\\ntors, CS Theory, Data Science, DBA, DevOps, GameDev, Network Engineering, Raspberry Pi,\\nSuperuser, and Server Fault.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 8}},\n",
              " {'text': 'Title Suppressed Due to Excessive Length 9\\nTable 4. Overall results for the style change detection task, ranked by average performance across\\nall three tasks.\\nParticipant Task1 F 1Task2 F 1Task3 F 1\\nZhang et al. 0.753 0.751 0.501\\nStrøm 0.795 0.707 0.424\\nSingh et al. 0.634 0.657 0.432\\nDeibel et al. 0.621 0.669 0.263\\nNath 0.704 0.647 —\\nBaseline 0.457 0.470 0.329\\ntions and answers. Subsequently, we split all questions and answers into paragraphs,\\ndropping all paragraphs with fewer than 100 characters. To reduce the potential impact\\nof topic changes, each document was generated from a single question thread this year.\\nHence, for each document, we pick a question thread to draw paragraphs from. Then,\\nwe decided randomly how many authors the document should have, settling a number\\nbetween one and four authors per case. Following that, we randomly chose a corre-\\nsponding number of authors from the authors who contributed to the question thread\\nwe were drawing paragraphs from. We then took all the paragraphs written by those au-\\nthors and shufﬂed them to create the ﬁnal documents. If a document created in this way\\nhad fewer than two paragraphs, or was fewer than 1,000 or more than 10,000 characters\\nlong, we discarded it. Applying this procedure, we created a total of 16,000 documents.\\nWe split the resulting set of documents into a training, a test and a validation set; the\\ntraining set consisted of 70% of all generated documents whereas the test and validation\\nset each consisted of 15% of all documents. Submissions were evaluated using the F\\x0b\\nmeasure for each task and for each document, with \\x0bset to 1.\\nResults The style change detection task received ﬁve software submissions. Table 4\\npresents the individual results achieved by the participants. We list the F1measures for\\nall three tasks. The approach by Strøm achieved the highest score for Task 1, whereas\\nZhang et al. achieved the highest score for Tasks 2 and 3. All of the submitted ap-\\nproaches outperformed the random baseline. Further details on the approaches taken\\ncan be found in the overview paper [40].\\nAcknowledgments\\nThe work of the researchers from Universitat Politècnica de València was partially\\nfunded by the Spanish MICINN under the project MISMIS-FAKEnHATE on MIS-\\ninformation and MIScommunication in social media: FAKE news and HATE speech\\n(PGC2018-096212-B-C31), and by the Generalitat Valenciana under the project Deep-\\nPattern (PROMETEO/2019/121). This article is also based upon work from the Dig-\\nForAsp COST Action 17124 on Digital Forensics: evidence analysis via intelligent sys-\\ntems and practices, supported by European Cooperation in Science and Technology.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 9}},\n",
              " {'text': '10 Authors Suppressed Due to Excessive Length\\nBibliography\\n[1] Basile, V ., Bosco, C., Fersini, E., Nozza, D., Patti, V ., Rangel, F., Rosso, P., Sanguinetti,\\nM.: SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and\\nWomen in Twitter. In: Proc. of the 13th Int. Workshop on Semantic Evaluation\\n(SemEval-2019), co-located with the Annual Conference of the North American Chapter\\nof the Association for Computational Linguistics: Human Language Technologies\\n(NAACL-HLT 2019) (2019)\\n[2] Bevendorff, J., Stein, B., Hagen, M., Potthast, M.: Generalizing Unmasking for Short\\nTexts. In: Burstein, J., Doran, C., Solorio, T. (eds.) 14th Conference of the North American\\nChapter of the Association for Computational Linguistics: Human Language Technologies\\n(NAACL 2019), pp. 654–659, Association for Computational Linguistics (Jun 2019), URL\\nhttps://www.aclweb.org/anthology/N19-1068\\n[3] BRIER, G.W.: Veriﬁcation of forecasts expressed in terms of probability. Monthly Weather\\nReview 78(1), 1 – 3 (1950),\\nhttps://doi.org/10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2, URL\\nhttps://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_\\nvofeit_2_0_co_2.xml\\n[4] ElSherief, M., Nilizadeh, S., Nguyen, D., Vigna, G., Belding, E.: Peer to Peer Hate: Hate\\nSpeech Instigators and Their Targets. In: Proceedings of the International AAAI\\nConference on Web and Social Media, vol. 12 (2018)\\n[5] Fathallah, J.: Fanﬁction and the Author. How FanFic Changes Popular Cultural Texts.\\nAmsterdam University Press (2017)\\n[6] Hagen, L., Falling, M., Lisnichenko, O., Elmadany, A.A., Mehta, P., Abdul-Mageed, M.,\\nCostakis, J., Keller, T.E.: Emoji use in Twitter White Nationalism Communication. In:\\nConference Companion Publication of the 2019 on Computer Supported Cooperative\\nWork and Social Computing, pp. 201–205 (2019)\\n[7] Halvani, O., Graner, L.: Cross-domain authorship attribution based on compression:\\nNotebook for PAN at CLEF 2018. In: Cappellato, L., Ferro, N., Nie, J., Soulier, L. (eds.)\\nWorking Notes of CLEF 2018 - Conference and Labs of the Evaluation Forum, Avignon,\\nFrance, September 10-14, 2018, CEUR Workshop Proceedings, vol. 2125, CEUR-WS.org\\n(2018), URL http://ceur-ws.org/V ol-2125/paper\\\\_90.pdf\\n[8] Hellekson, K., Busse, K. (eds.): The Fan Fiction Studies Reader. University of Iowa Press\\n(2014)\\n[9] Juola, P.: Authorship attribution. Foundations and Trends in Information Retrieval 1(3),\\n233–334 (2006)\\n[10] Kestemont, M., Manjavacas, E., Markov, I., Bevendorff, J., Wiegmann, M., Stamatatos, E.,\\nPotthast, M., Stein, B.: Overview of the cross-domain authorship veriﬁcation task at PAN\\n2020. In: Cappellato, L., Eickhoff, C., Ferro, N., Névéol, A. (eds.) Working Notes of\\nCLEF 2020 - Conference and Labs of the Evaluation Forum, Thessaloniki, Greece,\\nSeptember 22-25, 2020, CEUR Workshop Proceedings, vol. 2696, CEUR-WS.org (2020),\\nURL http://ceur-ws.org/V ol-2696/paper\\\\_264.pdf\\n[11] Kestemont, M., Markov, I., Stamatatos, E., Manjavacas, E., Bevendorff, J., Potthast, M.,\\nStein, B.: Overview of the Authorship Veriﬁcation Task at PAN 2021. In: Faggioli, G.,\\nFerro, N., Joly, A., Maistro, M., Piroi, F. (eds.) CLEF 2021 Labs and Workshops,\\nNotebook Papers, CEUR-WS.org (2021)\\n[12] Kestemont, M., Stamatatos, E., Manjavacas, E., Daelemans, W., Potthast, M., Stein, B.:\\nOverview of the Cross-domain Authorship Attribution Task at PAN 2019. In: CLEF 2019\\nLabs and Workshops, Notebook Papers (2019)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 10}},\n",
              " {'text': 'Title Suppressed Due to Excessive Length 11\\n[13] Kestemont, M., Stover, J.A., Koppel, M., Karsdorp, F., Daelemans, W.: Authenticating the\\nwritings of julius caesar. Expert Systems with Applications 63, 86–96 (2016),\\nhttps://doi.org/10.1016/j.eswa.2016.06.029, URL\\nhttps://doi.org/10.1016/j.eswa.2016.06.029\\n[14] Kestemont, M., Tschuggnall, M., Stamatatos, E., Daelemans, W., Specht, G., Stein, B.,\\nPotthast, M.: Overview of the author identiﬁcation task at PAN 2018: Cross-domain\\nauthorship attribution and style change detection. In: CLEF 2018 Labs and Workshops,\\nNotebook Papers (2018)\\n[15] Koppel, M., Schler, J.: Authorship veriﬁcation as a one-class classiﬁcation problem. In:\\nBrodley, C.E. (ed.) Machine Learning, Proceedings of the Twenty-ﬁrst International\\nConference (ICML 2004), Banff, Alberta, Canada, July 4-8, 2004, ACM International\\nConference Proceeding Series, vol. 69, ACM (2004),\\nhttps://doi.org/10.1145/1015330.1015448\\n[16] Koppel, M., Schler, J., Argamon, S.: Computational methods in authorship attribution.\\nJournal of the American Society for Information Science and Technology 60(1), 9–26\\n(2009)\\n[17] Mathew, B., Dutt, R., Goyal, P., Mukherjee, A.: Spread of Hate Speech in Online Social\\nMedia. In: Proceedings of the 10th ACM conference on web science, pp. 173–182 (2019)\\n[18] Mathew, B., Illendula, A., Saha, P., Sarkar, S., Goyal, P., Mukherjee, A.: Hate Begets Hate:\\nA Temporal Study of Hate Speech. Proceedings of the ACM on Human-Computer\\nInteraction 4(CSCW2), 1–24 (2020)\\n[19] MATTHEWS, R.A.J., MERRIAM, T.V .N.: Neural Computation in Stylometry I: An\\nApplication to the Works of Shakespeare and Fletcher. Literary and Linguistic Computing\\n8(4), 203–209 (01 1993), ISSN 0268-1145, https://doi.org/10.1093/llc/8.4.203\\n[20] Nockleby, J.T.: Hate speech. In: Encyclopedia of the American Constitution (2nd ed.,\\nedited by Leonard W. Levy, Kenneth L. Karst et al., New York: Macmillan), pp.\\n1277–1279 (2000)\\n[21] Pereira-Kohatsu, J.C., Quijano-Sánchez, L., Liberatore, F., Camacho-Collados, M.:\\nDetecting and monitoring hate speech in twitter. Sensors 19(21), 4654 (2019)\\n[22] Potthast, M., Gollub, T., Wiegmann, M., Stein, B.: TIRA Integrated Research Architecture.\\nIn: Ferro, N., Peters, C. (eds.) Information Retrieval Evaluation in a Changing World,\\nSpringer (2019), https://doi.org/10.1007/978-3-030-22948-1_5\\n[23] Qian, J., ElSherief, M., Belding, E.M., Wang, W.Y .: Leveraging Intra-user and Inter-user\\nRepresentation Learning for Automated Hate Speech Detection. arXiv preprint\\narXiv:1804.03124 (2018)\\n[24] Rangel, F., De-La-Peña-Sarracén, G.L., Chulvi, B., Fersini, E., Rosso, P.: Proﬁling Hate\\nSpeech Spreaders on Twitter Task at PAN 2021. In: Faggioli, G., Ferro, N., Joly, A.,\\nMaistro, M., Piroi, F. (eds.) CLEF 2021 Labs and Workshops, Notebook Papers,\\nCEUR-WS.org (2021)\\n[25] Rangel, F., Giachanou, A., Ghanem, B., Rosso, P.: Overview of the 8th Author Proﬁling\\nTask at PAN 2019: Proﬁling Fake News Spreaders on Twitter. In: CLEF 2020 Labs and\\nWorkshops, Notebook Papers. CEUR Workshop Proceedings (2020)\\n[26] Rangel, F., Rosso, P.: On the implications of the general data protection regulation on the\\norganisation of evaluation tasks. Language and Law / Linguagem e Direito 5(2), 95–117\\n(2019)\\n[27] Rangel, F., Rosso, P.: Overview of the 7th author proﬁling task at pan 2019: Bots and\\ngender proﬁling. In: CLEF 2019 Labs and Workshops, Notebook Papers (2019)\\n[28] Rangel, F., Rosso, P., Chugur, I., Potthast, M., Trenkmann, M., Stein, B., Verhoeven, B.,\\nDaelemans, W.: Overview of the 2nd author proﬁling task at PAN 2014. In: CLEF 2014\\nLabs and Workshops, Notebook Papers (2014)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 11}},\n",
              " {'text': '12 Authors Suppressed Due to Excessive Length\\n[29] Rangel, F., Rosso, P., Franco-Salvador, M.: A low dimensionality representation for\\nlanguage variety identiﬁcation. In: In 17th International Conference on Intelligent Text\\nProcessing and Computational Linguistics, CICLing’16. Springer-Verlag, LNCS(9624),\\npp. 156–169 (2018)\\n[30] Rangel, F., Rosso, P., Montes-y-Gómez, M., Potthast, M., Stein, B.: Overview of the 6th\\nAuthor Proﬁling Task at PAN 2018: Multimodal Gender Identiﬁcation in Twitter. In:\\nCLEF 2019 Labs and Workshops, Notebook Papers (2018)\\n[31] Rangel, F., Rosso, P., Moshe Koppel, M., Stamatatos, E., Inches, G.: Overview of the\\nauthor proﬁling task at PAN 2013. In: CLEF 2013 Labs and Workshops, Notebook Papers\\n(2013)\\n[32] Rangel, F., Rosso, P., Potthast, M., Stein, B.: Overview of the 5th author proﬁling task at\\nPAN 2017: Gender and language variety identiﬁcation in Twitter. Working Notes Papers of\\nthe CLEF (2017)\\n[33] Rangel, F., Rosso, P., Potthast, M., Stein, B., Daelemans, W.: Overview of the 3rd author\\nproﬁling task at PAN 2015. In: CLEF 2015 Labs and Workshops, Notebook Papers (2015)\\n[34] Rangel, F., Rosso, P., Verhoeven, B., Daelemans, W., Potthast, M., Stein, B.: Overview of\\nthe 4th author proﬁling task at PAN 2016: Cross-genre evaluations. In: CLEF 2016 Labs\\nand Workshops, Notebook Papers (Sep 2016), ISSN 1613-0073\\n[35] Ribeiro, M., Calais, P., Santos, Y ., Almeida, V ., Meira Jr, W.: Characterizing and Detecting\\nHateful Users on Twitter. In: Proceedings of the International AAAI Conference on Web\\nand Social Media, vol. 12 (2018)\\n[36] Rosso, P., Rangel, F., Potthast, M., Stamatatos, E., Tschuggnall, M., Stein, B.: Overview of\\nPAN’16—New Challenges for Authorship Analysis: Cross-genre Proﬁling, Clustering,\\nDiarization, and Obfuscation. In: Experimental IR Meets Multilinguality, Multimodality,\\nand Interaction. 7th International Conference of the CLEF Initiative (CLEF 16) (2016)\\n[37] Stamatatos, E.: A survey of modern authorship attribution methods. JASIST 60(3),\\n538–556 (2009), https://doi.org/10.1002/asi.21001, URL https://doi.org/10.1002/asi.21001\\n[38] Tschuggnall, M., Stamatatos, E., Verhoeven, B., Daelemans, W., Specht, G., Stein, B.,\\nPotthast, M.: Overview of the author identiﬁcation task at PAN 2017: style breach\\ndetection and author clustering. In: CLEF 2017 Labs and Workshops, Notebook Papers\\n(2017)\\n[39] Waseem, Z.: Are you a racist or am I seeing things? annotator inﬂuence on hate speech\\ndetection on Twitter. In: Proceedings of the First Workshop on NLP and Computational\\nSocial Science, pp. 138–142, Association for Computational Linguistics, Austin, Texas\\n(Nov 2016), https://doi.org/10.18653/v1/W16-5618, URL\\nhttps://www.aclweb.org/anthology/W16-5618\\n[40] Zangerle, E., Mayerl, M., , Potthast, M., Stein, B.: Overview of the Style Change\\nDetection Task at PAN 2021. In: Faggioli, G., Ferro, N., Joly, A., Maistro, M., Piroi, F.\\n(eds.) CLEF 2021 Labs and Workshops, Notebook Papers, CEUR-WS.org (2021)\\n[41] Zangerle, E., Mayerl, M., Specht, G., Potthast, M., Stein, B.: Overview of the Style\\nChange Detection Task at PAN 2020. In: CLEF 2020 Labs and Workshops, Notebook\\nPapers (2020)\\n[42] Zangerle, E., Tschuggnall, M., Specht, G., Stein, B., Potthast, M.: Overview of the Style\\nChange Detection Task at PAN 2019. In: CLEF 2019 Labs and Workshops, Notebook\\nPapers (2019)',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper5.pdf', 'page_number': 12}},\n",
              " {'text': 'Overview of the Style Change Detection Task at PAN\\n2021\\nEva Zangerle1, Maximilian Mayerl1, Martin Potthast2and Benno Stein3\\n1Universität Innsbruck\\n2Leipzig University\\n3Bauhaus-Universität Weimar\\npan@webis.de http://pan.webis.de\\nAbstract\\nStyle change detection means to identify text positions within a multi-author document at which the\\nauthor changes. Detecting these positions is considered a key enabling technology for all tasks involving\\nmulti-author documents as well as a preliminary step for reliable authorship identification. In this\\nyear’s PAN style change detection task, we asked the participants to answer the following questions:\\n(1) Given a document, was it written by a single or by multiple authors? (2) For each pair of consecutive\\nparagraphs in a given document, is there a style change between these paragraphs? (3) Find all positions\\nof writing style change, i.e., assign all paragraphs of a text uniquely to some author, given the list of\\nauthors assumed for the multi-author document. The outlined task is performed and evaluated on a\\ndataset that has been compiled from an English Q&A platform. The style change detection task, the\\nunderlying dataset, a survey of the participants’ approaches, as well as the results are presented in this\\npaper.\\n1. Introduction\\nStyle change detection is a multi-author writing style analysis to determine for a given document\\nboth the number of authors and the positions of authorship changes. Previous editions of PAN\\nfeatured already multi-author writing style analysis tasks: in 2016, participants were asked to\\nidentify and cluster text segments by author [ 1]. In 2017, the task was two-fold, namely, to\\ndetect whether a given document was written by multiple authors, and, if this was the case,\\nto identify the positions at which authorship changes [ 2]. At PAN 2018, the task was relaxed\\nto a binary classification task that aimed at distinguishing between single- and multi-author\\ndocuments [ 3]. The PAN edition in 2019 broadened the task and additionally asked participants\\nto predict the number of authors for all detected multi-author documents [ 4]. In 2020 the\\nparticipants were asked to detect whether a document was written by a single or by multiple\\nauthors, and to determine the positions of style changes at the paragraph level. This year we\\nasked participants (1) to find out whether the text is written by a single author or by multiple\\nauthors, (2) to detect the position of the changes on the paragraph-level, and (3) to assign all\\nparagraphs of the text uniquely to some author out of the number of authors they assume for\\nthe multi-author document.\\nCLEF 2021 – Conference and Labs of the Evaluation Forum, September 21–24, 2021, Bucharest, Romania\\n©2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\\nCEUR\\nWorkshop\\nProceedingshttp://ceur-ws.org\\nISSN 1613-0073\\nCEUR Workshop Proceedings (CEUR-WS.org)\\n',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 1}},\n",
              " {'text': 'The remainder of this paper is structured as follows. Section 2 discusses previous approaches\\nto style change detection. Section 3 introduces the PAN 2021 style change detection task,\\nthe underlying dataset, and the evaluation procedure. Section 4 summarizes the received\\nsubmissions, and Section 5 analyzes and compares the achieved results.\\n2. Related Work\\nStyle change detection is related to problems from the fields of stylometry, intrinsic plagiarism\\ndetection, and authorship attribution. Solutions typically create stylistic fingerprints of authors,\\nwhich may rely on lexical features such as character n-grams [ 5,6], or word frequencies [ 7],\\nsyntactic features such as part-of-speech tags [ 8], or structural features such as the use of\\nindentation [ 9]. By computing such fingerprints on the sentence- or paragraph-level, style\\nchanges at the respective boundaries can be detected by computing pairwise similarities [ 10,11],\\nclustering [ 1,12], or by applying outlier detection [ 13]. Recently, also deep learning models\\nhave been employed for these tasks [14, 15, 16, 17].\\nOne of the first works on identifying inconsistencies of writing style was presented by Glover\\nand Hirst [ 18]. Notably, Stamatatos [ 19] utilized 𝑛-grams to create stylistic fingerprints for\\nquantifying variations in writing style. The task of intrinsic plagiarism detection was first tackled\\nby Meyer zu Eißen and Stein [ 20,21,22]. Koppel et al. [ 23,24] and Akiva and Koppel [ 25,26]\\nproposed to use lexical features as input for clustering methods to decompose documents into\\nauthorial threads. Tschuggnall et al. [ 27] proposed an unsupervised decomposition approach\\nbased on grammar tree representations. Gianella [ 28] utilizes Bayesian modeling to split a\\ndocument into segments, followed by a clustering approach to cluster segments by author.\\nDauber et al. [ 29] presented an approach to tackle authorship attribution on multi-author\\ndocuments based on multi-label classification on linguistic features. Aldebei et al. [ 30] and\\nSarwar et al. [ 31] used hidden Markov models and basic stylometric features to build a so-called\\nco-authorship graph. Rexha et al. [ 32] predicted the number of authors of a text using stylistic\\nfeatures.\\n3. Style Change Detection Task\\nThis section details the style change detection task, the dataset constructed for the task, and the\\nemployed performance measures.\\n3.1. Task Definition\\nGoal of the style change detection task is to identify text positions within a given multi-author\\ndocument at which the author switches, and to assign each paragraph to an author. In a first\\nstep we suggest to check the document in question for writing style changes; the result is then\\nused as predictor for single- or multi-authorship. If a document is considered a multi-author\\ndocument, the exact positions at which the writing style (and probably the authorship changes)\\nare to be determined, and, finally, paragraphs may be assigned to their alleged author.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 2}},\n",
              " {'text': 'Lorem ipsum dolor sitamet ,consetetur sadipscing elitr,\\nsed diam nonumy eirmod tempor invidunt utlabore et\\ndolore magna aliquyam erat,seddiam voluptua .Atvero\\neos etaccusam etjusto duo dolores etearebum .Stet\\nclita kasd gubergren ,noseatakimata sanctus estLorem\\nipsum dolor sitamet .Lorem ipsum dolor sitamet ,\\nconsetetur sadipscing elitr,sed diam nonumy eirmod\\ntempor invidunt utlabore etdolore magna aliquyam\\nerat,seddiam voluptua .Atvero eosetaccusam etjusto\\nduo dolores etearebum .Stet clita kasd gubergren ,no\\nsea takimata sanctus estLorem ipsum dolor sitamet .\\nLorem ipsum dolor sitamet ,consetetur sadipscing elitr,\\nsed diam nonumy eirmod tempor invidunt utlabore et\\ndolore magna aliquyam erat,seddiam voluptua .Atvero\\neos etaccusam etjusto duo dolores etearebum .Stet\\nclita kasd gubergren ,noseatakimata sanctus estLorem\\nipsum dolor sitamet .\\nDuis autem veleum iriure dolor inhendrerit invulputate\\nvelit esse molestie consequat ,vel illum dolore eu\\nfeugiat nulla facilisis atvero eros etaccumsan etiusto\\nodio dignissim qui blandit praesent luptatum zzril\\ndelenit augue duis dolore tefeugait nulla facilisi .Lorem\\nipsum dolor sitamet ,consectetuer adipiscing elit,sed\\ndiam nonummy nibh euismod tincidunt utlaoreet\\ndolore magna aliquam erat volutpat .Author 1Duis autem veleum iriure dolor inhendrerit invulputate\\nvelit esse molestie consequat ,velillum dolore eufeugiat\\nnulla facilisis atvero eros etaccumsan etiusto odio\\ndignissim qui blandit praesent luptatum zzril delenit\\naugue duis dolore tefeugait nulla facilisi .Lorem ipsum\\ndolor sitamet ,consectetuer adipiscing elit,sed diam\\nnonummy nibh euismod tincidunt utlaoreet dolore\\nmagna aliquam erat volutpat .\\nUtwisi enim adminim veniam ,quis nostrud exerci\\ntation ullamcorper suscipit lobortis nislutaliquip exea\\ncommodo consequat .Duis autem veleum iriure dolor in\\nhendrerit invulputate velit esse molestie consequat ,vel\\nillum dolore eufeugiat nulla facilisis atvero eros et\\naccumsan etiusto odio dignissim quiblandit praesent\\nluptatum zzril delenit augue duis dolore tefeugait nulla\\nfacilisi .\\nNam liber tempor cum soluta nobis eleifend option\\ncongue nihil imperdiet doming idquod mazim placerat\\nfacer possim assum .Lorem ipsum dolor sitamet ,\\nconsectetuer adipiscing elit,sed diam nonummy nibh\\neuismod tincidunt utlaoreet dolore magna aliquam erat\\nvolutpat .Duis autem veleum iriure dolor inhendrerit invulputate\\nvelit esse molestie consequat ,velillum dolore eufeugiat\\nnulla facilisis atvero eros etaccumsan etiusto odio\\ndignissim qui blandit praesent luptatum zzril delenit\\naugue duis dolore tefeugait nulla facilisi .Lorem ipsum\\ndolor sitamet ,consectetuer adipiscing elit,sed diam\\nnonummy nibh euismod tincidunt utlaoreet dolore\\nmagna aliquam erat volutpat .\\nUtwisi enim adminim veniam ,quis nostrud exerci\\ntation ullamcorper suscipit lobortis nislutaliquip exea\\ncommodo consequat .Duis autem veleum iriure dolor in\\nhendrerit invulputate velit esse molestie consequat ,vel\\nillum dolore eufeugiat nulla facilisis atvero eros et\\naccumsan etiusto odio dignissim quiblandit praesent\\nluptatum zzril delenit augue duis dolore tefeugait nulla\\nfacilisi .\\nNam liber tempor cum soluta nobis eleifend option\\ncongue nihil imperdiet doming idquod mazim placerat\\nfacer possim assum .Lorem ipsum dolor sitamet ,\\nconsectetuer adipiscing elit,sed diam nonummy nibh\\neuismod tincidunt utlaoreet dolore magna aliquam erat\\nvolutpat .Utwisi enim adminim veniam ,quis nostrud\\nexerci tation ullamcorper suscipit lobortis nislutaliquip\\nexeacommodo consequat .\\nDuis autem veleum iriure dolor inhendrerit invulputate\\nvelit esse molestie consequat ,velillum dolore eufeugiat\\nnulla facilisis .Example Document A Example Document B Example Document C\\nAuthor 1Author 1\\nAuthor 2\\nAuthor 2Author 1\\nAuthor 2\\nAuthor 2\\nAuthor 3\\nTask 1 \\nTask 2\\nTask 3 no(0)\\n[0]\\n[1,1]yes(1)\\n[1,0]\\n[1,2,2]yes(1)\\n[1,0,1]\\n[1,2,2,3]Figure 1: Documents that illustrate different style change situations and the expected solution for\\nTask 1 (single vs. multiple), Task 2 (change positions), and Task 3 (author attribution).\\nGiven a document, we ask participants to answer the following three questions:\\n•Single vs. Multiple. Given a text, determine whether the text is written by a single author\\nor by multiple authors (Task 1).\\n•Change Positions. Given a text, determine all positions within that text where the writing\\nstyle changes (Task 2). For this task, such changes can only occur between paragraphs.\\n•Author Attribution. Given a text, assign all its paragraphs to some author out of the set of\\nauthors participants assume for the given text (Task 3).\\nFigure 1 shows documents and the results of the three tasks for these documents. Document A\\nis written by a single author and does not contain any style changes. Document B contains\\na single style change between the Paragraphs 1 and 2, and Document C contains two style\\nchanges. As indicated in Figure 1, Task 1 is a binary classification task determining whether the\\ndocument was written by multiple authors. For Task 2 we ask participants to provide a binary\\nvalue indicating whether there is a change in authorship between each pair of consecutive\\nparagraphs for each document. For Task 3 we ask participants to assign each paragraph uniquely\\nto an author from a list of authors in question.\\nAll documents are written in English and consist of paragraphs each of which written by a\\nsingle author out of a set of four authors. A document can contain a number of style changes\\nbetween paragraphs but no style changes within a paragraph.\\nWe asked participants to deploy their software on the TIRA platform [ 33]. This allows\\nparticipants to test their software on the available training and validation dataset, as well as\\nto self-evaluate their software on the unseen dataset. TIRA enables blind evaluation, thus\\nforeclosing optimization against the test data.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 3}},\n",
              " {'text': 'Table 1\\nParameters for constructing the style change detection dataset.\\nParameter Configurations\\nNumber of collaborating authors 1-4\\nDocument length 1,000-10,000\\nMinimum paragraph length 100\\nMinimum number of paragraphs 2\\nChange positions between paragraphs\\nDocument language English\\n3.2. Dataset Construction\\nThe dataset for the Style Change Detection task was created from posts taken from the popular\\nStackExchange network of Q&A sites. This ensures that results are comparable with past\\neditions of the tasks, which rely on the same data source [ 4,34]. In the following, we outline\\nthe dataset creation process.\\nThe dataset for this year’s task consists of 16,000 documents. The text were drawn from a dump\\nof questions and answers from various sites in the StackExchange network. To ensure topical\\ncoherence of the dataset, the considered sites revolve around topics focusing on technology.\\n1We cleaned all questions and answers from these sites by removing questions and answers\\nthat were edited after they were originally submitted, and by removing images, URLs, code\\nsnippets, block quotes as well as bullet lists. Afterward, the questions and answers were split\\ninto paragraphs, dropping all paragraphs with fewer than 100 characters. Since one of the\\ngoals for this year’s edition of the task was to reduce the impact of topic changes within a\\ndocument, which could inadvertently make the task easier, we constructed documents from\\nthese paragraphs by only taking paragraphs belonging to the same question/answer thread\\nwithin a single document: we randomly chose a question/answer thread and also randomly\\nchose a number 𝑛∈ {1,2,3,4}, denoting how many authors the resulting document should\\nhave. Following that, we took a random subset of size 𝑛of all the authors that contributed\\nto the chosen question/answer thread that we wanted to draw paragraphs from. We took all\\nparagraphs written by this subset of authors, shuffled them, and concatenated them together to\\nform a document. If a generated document consisted of one paragraph only, or if it was fewer\\nthan 1,000 or more than 10,000 characters long, it was discarded.\\nWe ensured that the number of authors was equally distributed across the documents—i.e.,\\nthere are as many single-author documents as documents with two authors, three authors,\\nand four authors. We split the resulting set of documents into a training set, a test set, and a\\nvalidation set. The training set consists of 70% of all documents (11,200), and the test set and the\\nvalidation set consist of 15% of all documents each (2,400). The parameters used for creating the\\ndataset are given in Table 1, and an overview of the three dataset splits can be seen in Table 2.\\n1Code Review, Computer Graphics, CS Educators, CS Theory, Data Science, DBA, DevOps, GameDev, Network\\nEngineering, Raspberry Pi, Superuser, and Server Fault.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 4}},\n",
              " {'text': 'Table 2\\nDataset overview. Text length is measured as average number of tokens per document.\\nDataset #Docs Documents / #Authors Length / #Authors\\n1 2 3 4 1 2 3 4\\nTrain 11,2002,800 2,800 2,800 2,8001,519 1,592 1,795 2,05925% 25% 25% 25%\\nValid. 2,400600 600 600 6001,549 1,599 1,785 2,03925% 25% 25% 25%\\nTest 2,400600 600 600 6001,512 1,564 1,793 2,08125% 25% 25% 25%\\n3.3. Performance Measures\\nTo evaluate the submitted approaches and to compare the obtained results, submissions are\\nevaluated by the 𝐹𝛼-Measure for each document, where 𝛼= 1equally weighs the harmonic\\nmean between precision and recall. Across all documents, we compute the macro-averaged\\n𝐹𝛼-Measure. The three tasks are evaluated independently based on the obtained accuracy\\nmeasures.\\n4. Survey of Submissions\\nFor the 2021 edition of the style change detection task we received five submissions, which are\\ndescribed in the following.\\n4.1. Style Change Detection on Real-World Data using LSTM-powered\\nAttribution Algorithm\\nDeibel and Löfflad [ 35] propose the use of multi-layer perceptrons and bidirectional LSTMs for\\nthe style change detection task. The approach relies on textual features widely used in authorship\\nattribution (mean sentence length in words, mean word length, or corrected type-token ratio) and\\npretrained fastText word embeddings. For Task 1, the approach uses a multi-layer perceptron,\\nwith three hidden, fully connected feed forward layers with per-document embeddings as input.\\nFor Task 2, the authors employ a two-layered bidirectional LSTM. Based on the style change\\npredictions for Task 1 and Task 2, the approach iterates for Task 3 over all pairs of paragraphs\\nto attribute each paragraph to an author. If no style change is detected between paragraphs, the\\ncurrent paragraph is attributed to the author of the previous paragraph. For an alleged style\\nchange between paragraphs the current paragraph is compared to all previously attributed\\nparagraphs in order to either assign it to an already known author or to attribute it to a new\\nauthor.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 5}},\n",
              " {'text': '4.2. Style Change Detection using Siamese Neural Networks\\nThe approach proposed by Nath [ 36] utilizes Siamese neural networks to compute paragraph\\nsimilarities for the detection of style changes. Paragraphs are transformed into numerical vectors\\nby lowercasing, removing all punctuation, tokenizing each paragraph and then, representing\\neach vocabulary word as an integer id. For the pairwise similarity comparison of paragraphs\\nthe vector representation of the two paragraphs and the label (style change or not) are used\\nas input. The Siamese network features a GloVe embedding layer, a bidirectional LSTM layer,\\ndistance measure layer, and a dense layer with sigmoid activation to compute the actual final\\nlabel.\\n4.3. Writing Style Change Detection on Multi-Author Documents\\nThe approach by Singh et al. [ 37] is based on an approach for authorship verification submitted\\nto PAN 2020 by Weerasinghe et al. [ 38]. The core of the approach hence is an authorship\\nverification model which the authors use to determine whether two given paragraphs are\\nwritten by the same author. In this regard they extract features for both paragraphs, including\\ntf-idf features, n-grams of part of speech tags, and vocabulary richness measures among others.\\nThen, the difference between the feature vectors for both paragraphs and take the magnitude\\nof the resulting difference vector is computed. This magnitude is fed into a logistic regression\\nclassifier to determine whether both paragraphs have the same author. They then use this\\nmodel to answer the three tasks posed in this year’s style change detection task as follows.\\nFor Task 1, they use their verification model to predict whether all consecutive paragraphs\\nin the document were written by the same author. If the average of the classifier scores for\\nall consecutive paragraphs in a document is greater than 0.5, the document is classified as\\nmulti-author document. For Task 2, the author again use their verification model on each\\nconsecutive pair of paragraphs, and predict a style change between all paragraphs for which\\nthe model determines that they were not written by the same author. Finally, for Task 3, they\\nran their verification model on all pairs of paragraphs in a document, and used hierarchical\\nclustering on a distance matrix created from classifier scores to group paragraphs written by\\nthe same author together.\\n4.4. Multi-label Style Change Detection by Solving a Binary Classification\\nProblem\\nThe approach developed by Strøm [ 39] is based on BERT embedding features and stylistic\\nfeatures previously proposed by Zlatkova et al. [ 40]. The embeddings are generated on a\\nsentence-level and subsequently, sentence embeddings are aggregated to the paragraph-level\\nby adding the sentence embeddings of each paragraph. Text features are extracted on the\\nparagraph-level. To identify style changes between two paragraphs to solve tasks 1 and 2,\\nbinary classification via a stacking ensemble is performed. This ensemble uses a meta-learner\\ntrained on the predictions computed by base level classifiers for stylistic and embedding features.\\nFor the multi-label classification for Task 3, the author proposes a recursive strategy that is\\nbased on the predictions for Task 1 and Task 2. The algorithm iterates over all paragraphs,\\nand computes the probability that each pair of paragraphs was written by the same author. If',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 6}},\n",
              " {'text': 'this probability exceeds the threshold of 0.5, the paragraphs are attributed to the same author;\\notherwise to different authors.\\n4.5. Using Single BERT For Three Tasks Of Style Change Detection\\nZhang et al. [ 41] rely on a pretrained BERT model (specifically, BERT-Base as provided by\\nGoogle). They model Task 3 as a binary classification task. Therefore, for each paragraph and\\neach of its preceding paragraphs, they compute whether there is a style change to augment the\\namount of training data. These labels are used for fine-tuning the BERT model. The resulting\\nweights are then saved and used for the actual predictions for the tasks 1–3. Labels for Task 2\\nand Task 3 are predicted, and the results for Task 1 are inferred from the results of Task 2.\\n5. Evaluation Results\\nTable 3 shows the evaluation results of all submitted approaches as well as a baseline in form\\nof F 1scores. The baseline approach uses a uniformly random prediction for Task 3, and infers\\nthe results for Tasks 1 and 2 from the predictions for Task 3. The predictions for Task 3 take\\ninto account that authors must be labeled with increasing author identifiers. As can be seen, all\\napproaches significantly outperform the baseline on all tasks, except for the approach by Deibel\\net al. [ 35] for Task 3, which scores lower than the baseline. The best performance for Task 1—\\ndetermining whether a document has one or multiple authors—was achieved by Strøm [ 39],\\nwhereas the best performance for the actual style change detection tasks, Task 2 and Task 3,\\nwas achieved by Zhang et al. [ 41]. In all cases, the best performing approach substantially\\noutperforms all other submitted approaches.\\nTable 3\\nOverall results for the style change detection task, ranked by average performance across all three tasks.\\nParticipant Task1 F 1Task2 F 1Task3 F 1\\nZhang et al. 0.753 0.751 0.501\\nStrøm 0.795 0.707 0.424\\nSingh et al. 0.634 0.657 0.432\\nDeibel et al. 0.621 0.669 0.263\\nNath 0.704 0.647 —\\nBaseline 0.457 0.470 0.329\\nIn addition to the overall evaluation given in Table 3, we further analyzed the performance of\\nall submitted approaches separately for single-author and multi-author documents. The results\\nfor this analysis are given in Figure 2. There are a number of observations we can make from\\nthose results. For Task 1, the approach submitted by Singh et al. has the best performance out\\nof all approaches for single-author documents, but the worst performance for multi-author\\ndocuments. Looking at the results for Task 2, we can see that all approaches show almost\\nthe same performance for single-author documents. This means that the difference in overall\\nperformance between those approaches stems only from multi-author documents. A similar\\nobservation, though not quite as pronounced, can be made for Task 3.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 7}},\n",
              " {'text': 'task1 task2 task3\\nMetric0.00.20.40.60.81.0ScoreOverall Scores For Single-Author Documents\\nnath\\nsinghstrom\\nzhangdeibel(a) Single-author documents\\ntask1 task2 task3\\nMetric0.00.20.40.60.81.0ScoreOverall Scores For Multi-Author Documents\\nnath\\nsinghstrom\\nzhangdeibel (b) Multi-author documents\\nFigure 2: Scores (F 1) for all tasks separately for single-author and multi-author documents.\\n1 2 3 4\\nNumber  of Authors0.00.20.40.60.81.0ScoreT ask 2 Score Over Number of Authors\\nparticipant\\nnath\\nsingh\\nstrom\\nzhang\\ndeibel\\n(a) Task 2\\n1 2 3 4\\nNumber  of Authors0.00.20.40.60.81.0ScoreT ask 23 Score Over Number of Authors\\nparticipant\\nnath\\nsingh\\nstrom\\nzhang\\ndeibel (b) Task 3\\nFigure 3: Scores (F 1) for all Task 2 and Task 3, depending on the true number of authors in a document.\\nFinally, we looked at how the performance of the submitted approaches changes depending\\non the true number of authors per document. We performed this analysis for Task 2 and Task 3.\\nThe results can be seen in Figure 3. Looking at the results, we can see that the performance\\nfor Task 2 peaks at two authors for all approaches. In other words, all submitted approaches\\nare best at determining style changes between paragraphs when the document was written by\\ntwo authors. A different picture presents itself for Task 3. For two of the submitted approaches\\n(Zhang et al. and Singh et al.), the performance keeps increasing with a growing number of\\nauthors. They perform best if the document was written by four authors. This suggests it may\\nbe interesting to increase the maximum number of authors per document for a future edition of\\nthe task.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 8}},\n",
              " {'text': '6. Conclusion\\nFor the style change detection task at PAN 2021, we asked participants to determine (1) whether\\na document was in fact written by several authors, (2) style changes between consecutive\\nparagraphs (3) the most likely author for a paragraph. Altogether five participants submitted\\ntheir approaches. For Task 1, the best performing approach relies on BERT embeddings and\\nstylistic features, utilizing a stacking ensemble. For Task 2 and Task 3, the highest 𝐹𝛼-Measure\\nwas obtained by fine-tuning pretrained BERT embeddings based on augmented data gained\\nfrom permuting the paragraphs of each document.\\nReferences\\n[1]E. Stamatatos, M. Tschuggnall, B. Verhoeven, W. Daelemans, G. Specht, B. Stein, M. Potthast,\\nClustering by Authorship Within and Across Documents, in: Working Notes Papers of\\nthe CLEF 2016 Evaluation Labs, CEUR Workshop Proceedings, CLEF and CEUR-WS.org,\\n2016. URL: http://ceur-ws.org/Vol-1609/.\\n[2]M. Tschuggnall, E. Stamatatos, B. Verhoeven, W. Daelemans, G. Specht, B. Stein, M. Potthast,\\nOverview of the Author Identification Task at PAN 2017: Style Breach Detection and\\nAuthor Clustering, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.), Working Notes\\nPapers of the CLEF 2017 Evaluation Labs, volume 1866 of CEUR Workshop Proceedings ,\\nCEUR-WS.org, 2017. URL: http://ceur-ws.org/Vol-1866/.\\n[3]M. Kestemont, M. Tschuggnall, E. Stamatatos, W. Daelemans, G. Specht, B. Stein, M. Pot-\\nthast, Overview of the Author Identification Task at PAN-2018: Cross-domain Authorship\\nAttribution and Style Change Detection, in: L. Cappellato, N. Ferro, J.-Y. Nie, L. Soulier\\n(Eds.), Working Notes Papers of the CLEF 2018 Evaluation Labs, volume 2125 of CEUR\\nWorkshop Proceedings , CEUR-WS.org, 2018. URL: http://ceur-ws.org/Vol-2125/.\\n[4]E. Zangerle, M. Tschuggnall, G. Specht, M. Potthast, B. Stein, Overview of the Style\\nChange Detection Task at PAN 2019, in: L. Cappellato, N. Ferro, D. Losada, H. Müller\\n(Eds.), CLEF 2019 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2019. URL:\\nhttp://ceur-ws.org/Vol-2380/.\\n[5]E. Stamatatos, Intrinsic Plagiarism Detection Using Character n-gram Profiles, in: Note-\\nbook Papers of the 5th Evaluation Lab on Uncovering Plagiarism, Authorship and Social\\nSoftware Misuse (PAN), Amsterdam, The Netherlands, 2011.\\n[6]M. Koppel, J. Schler, S. Argamon, Computational methods in authorship attribution,\\nJournal of the American Society for Information Science and Technology 60 (2009) 9–26.\\n[7]D. I. Holmes, The Evolution of Stylometry in Humanities Scholarship, Literary and\\nLinguistic Computing 13 (1998) 111–117.\\n[8]M. Tschuggnall, G. Specht, Countering Plagiarism by Exposing Irregularities in Authors’\\nGrammar, in: Proceedings of the European Intelligence and Security Informatics Confer-\\nence (EISIC), IEEE, Uppsala, Sweden, 2013, pp. 15–22.\\n[9]R. Zheng, J. Li, H. Chen, Z. Huang, A Framework for Authorship Identification of Online\\nMessages: Writing-Style Features and Classification Techniques, Journal of the American\\nSociety for Information Science and Technology 57 (2006) 378–393.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 9}},\n",
              " {'text': '[10] J. Khan, Style Breach Detection: An Unsupervised Detection Model—Notebook for PAN at\\nCLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.), CLEF 2017 Evaluation\\nLabs and Workshop – Working Notes Papers, CEUR-WS.org, 2017. URL: http://ceur-ws.\\norg/Vol-1866/.\\n[11] D. Karaś, M. Śpiewak, P. Sobecki, OPI-JSA at CLEF 2017: Author Clustering and Style\\nBreach Detection—Notebook for PAN at CLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot,\\nT. Mandl (Eds.), CLEF 2017 Evaluation Labs and Workshop – Working Notes Papers, CEUR-\\nWS.org, 2017. URL: http://ceur-ws.org/Vol-1866/.\\n[12] S. Nath, UniNE at PAN-CLEF 2019: Style Change Detection by Threshold Based and\\nWindow Merge Clustering Methods, in: L. Cappellato, N. Ferro, D. Losada, H. Müller\\n(Eds.), CLEF 2019 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2019.\\n[13] K. Safin, R. Kuznetsova, Style Breach Detection with Neural Sentence Embeddings—\\nNotebook for PAN at CLEF 2017, in: L. Cappellato, N. Ferro, L. Goeuriot, T. Mandl (Eds.),\\nCLEF 2017 Evaluation Labs and Workshop – Working Notes Papers, CEUR-WS.org, 2017.\\nURL: http://ceur-ws.org/Vol-1866/.\\n[14] N. Graham, G. Hirst, B. Marthi, Segmenting Documents by Stylistic Character, Natural\\nLanguage Engineering 11 (2005) 397–415. URL: https://doi.org/10.1017/S1351324905003694.\\ndoi:10.1017/S1351324905003694 .\\n[15] A. Iyer, S. Vosoughi, Style Change Detection Using BERT, in: L. Cappellato, N. Ferro,\\nA. Névéol, C. Eickhoff (Eds.), CLEF 2020 Labs and Workshops, Notebook Papers, CEUR-\\nWS.org, 2020.\\n[16] M. Hosseinia, A. Mukherjee, A Parallel Hierarchical Attention Network for Style Change\\nDetection—Notebook for PAN at CLEF 2018, in: L. Cappellato, N. Ferro, J.-Y. Nie, L. Soulier\\n(Eds.), CLEF 2018 Evaluation Labs and Workshop – Working Notes Papers, CEUR-WS.org,\\n2018.\\n[17] C. Zuo, Y. Zhao, R. Banerjee, Style Change Detection with Feedforward Neural Networks\\nNotebook for PAN at CLEF 2019 , in: L. Cappellato, N. Ferro, D. Losada, H. Müller (Eds.),\\nCLEF 2019 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2019.\\n[18] A. Glover, G. Hirst, Detecting Stylistic Inconsistencies in Collaborative Writing, Springer\\nLondon, London, 1996, pp. 147–168. doi: 10.1007/978-1-4471-1482-6_12 .\\n[19] E. Stamatatos, Intrinsic Plagiarism Detection Using Character $n$-gram Profiles, in:\\nB. Stein, P. Rosso, E. Stamatatos, M. Koppel, E. Agirre (Eds.), SEPLN 2009 Workshop on\\nUncovering Plagiarism, Authorship, and Social Software Misuse (PAN 09), Universidad\\nPolitécnica de Valencia and CEUR-WS.org, 2009, pp. 38–46. URL: http://ceur-ws.org/\\nVol-502.\\n[20] S. Meyer zu Eißen, B. Stein, Intrinsic Plagiarism Detection, in: M. Lalmas, A. MacFarlane,\\nS. Rüger, A. Tombros, T. Tsikrika, A. Yavlinsky (Eds.), Advances in Information Retrieval.\\n28th European Conference on IR Research (ECIR 2006), volume 3936 of Lecture Notes in\\nComputer Science , Springer, Berlin Heidelberg New York, 2006, pp. 565–569. doi: 10.1007/\\n11735106_66 .\\n[21] B. Stein, S. Meyer zu Eißen, Intrinsic Plagiarism Analysis with Meta Learning, in:\\nB. Stein, M. Koppel, E. Stamatatos (Eds.), 1st Workshop on Plagiarism Analysis, Authorship\\nIdentification, and Near-Duplicate Detection (PAN 2007) at SIGIR, 2007, pp. 45–50. URL:\\nhttp://ceur-ws.org/Vol-276.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 10}},\n",
              " {'text': '[22] B. Stein, N. Lipka, P. Prettenhofer, Intrinsic Plagiarism Analysis, Language Resources and\\nEvaluation (LRE) 45 (2011) 63–82. doi: 10.1007/s10579-010-9115-y .\\n[23] M. Koppel, N. Akiva, I. Dershowitz, N. Dershowitz, Unsupervised decomposition of a\\ndocument into authorial components, in: Proceedings of the 49th Annual Meeting of the\\nAssociation for Computational Linguistics: Human Language Technologies, Association\\nfor Computational Linguistics, Portland, Oregon, USA, 2011, pp. 1356–1364. URL: https:\\n//www.aclweb.org/anthology/P11-1136.\\n[24] M. Koppel, N. Akiva, I. Dershowitz, N. Dershowitz, Unsupervised decomposition of a\\ndocument into authorial components, in: D. Lin, Y. Matsumoto, R. Mihalcea (Eds.), The\\n49th Annual Meeting of the Association for Computational Linguistics: Human Language\\nTechnologies, Proceedings of the Conference, 19-24 June, 2011, Portland, Oregon, USA,\\nThe Association for Computer Linguistics, 2011, pp. 1356–1364. URL: http://www.aclweb.\\norg/anthology/P11-1136.\\n[25] N. Akiva, M. Koppel, Identifying Distinct Components of a Multi-author Document, in:\\nN. Memon, D. Zeng (Eds.), 2012 European Intelligence and Security Informatics Conference,\\nEISIC 2012, IEEE Computer Society, 2012, pp. 205–209. URL: https://doi.org/10.1109/EISIC.\\n2012.16. doi: 10.1109/EISIC.2012.16 .\\n[26] N. Akiva, M. Koppel, A Generic Unsupervised Method for Decomposing Multi-Author\\nDocuments, JASIST 64 (2013) 2256–2264. URL: https://doi.org/10.1002/asi.22924. doi: 10.\\n1002/asi.22924 .\\n[27] M. Tschuggnall, G. Specht, Automatic decomposition of multi-author documents using\\ngrammar analysis, in: F. Klan, G. Specht, H. Gamper (Eds.), Proceedings of the 26th\\nGI-Workshop Grundlagen von Datenbanken, volume 1313 of CEUR Workshop Proceedings ,\\nCEUR-WS.org, 2014, pp. 17–22. URL: http://ceur-ws.org/Vol-1313/paper_4.pdf.\\n[28] C. Giannella, An Improved Algorithm for Unsupervised Decomposition of a Multi-Author\\nDocument, JASIST 67 (2016) 400–411. URL: https://doi.org/10.1002/asi.23375. doi: 10.\\n1002/asi.23375 .\\n[29] E. Dauber, R. Overdorf, R. Greenstadt, Stylometric Authorship Attribution of Collaborative\\nDocuments, in: S. Dolev, S. Lodha (Eds.), Cyber Security Cryptography and Machine\\nLearning - First International Conference, CSCML 2017, Proceedings, volume 10332 of\\nLecture Notes in Computer Science , Springer, 2017, pp. 115–135. URL: https://doi.org/10.\\n1007/978-3-319-60080-2_9. doi: 10.1007/978-3-319-60080-2_9 .\\n[30] K. Aldebei, X. He, W. Jia, W. Yeh, SUDMAD: Sequential and Unsupervised Decomposition\\nof a Multi-Author Document Based on a Hidden Markov Model, JASIST 69 (2018) 201–214.\\nURL: https://doi.org/10.1002/asi.23956. doi: 10.1002/asi.23956 .\\n[31] R. Sarwar, C. Yu, S. Nutanong, N. Urailertprasert, N. Vannaboot, T. Rakthanmanon,\\nA scalable framework for stylometric analysis of multi-author documents, in: J. Pei,\\nY. Manolopoulos, S. W. Sadiq, J. Li (Eds.), Database Systems for Advanced Appli-\\ncations - 23rd International Conference, DASFAA 2018, Proceedings, Part I, volume\\n10827 of Lecture Notes in Computer Science , Springer, 2018, pp. 813–829. doi: 10.1007/\\n978-3-319-91452-7_52 .\\n[32] A. Rexha, S. Klampfl, M. Kröll, R. Kern, Towards a more fine grained analysis of scientific\\nauthorship: Predicting the number of authors using stylometric features, in: P. Mayr,\\nI. Frommholz, G. Cabanac (Eds.), Proceedings of the Third Workshop on Bibliometric-',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 11}},\n",
              " {'text': 'enhanced Information Retrieval co-located with the 38th European Conference on Infor-\\nmation Retrieval (ECIR 2016), volume 1567 of CEUR Workshop Proceedings , CEUR-WS.org,\\n2016, pp. 26–31. URL: http://ceur-ws.org/Vol-1567/paper3.pdf.\\n[33] M. Potthast, T. Gollub, M. Wiegmann, B. Stein, TIRA Integrated Research Architecture,\\nin: N. Ferro, C. Peters (Eds.), Information Retrieval Evaluation in a Changing World, The\\nInformation Retrieval Series, Springer, Berlin Heidelberg New York, 2019. doi: 10.1007/\\n978-3-030-22948-1_5 .\\n[34] E. Zangerle, M. Mayerl, G. Specht, M. Potthast, B. Stein, Overview of the Style Change\\nDetection Task at PAN 2020, in: L. Cappellato, C. Eickhoff, N. Ferro, A. Névéol (Eds.), CLEF\\n2020 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2020. URL: http://ceur-ws.\\norg/Vol-2696/.\\n[35] R. Deibel, D. Löfflad, Style Change Detection on Real-World Data using LSTM-powered\\nAttribution Algorithm, in: G. Faggioli, N. Ferro, A. Joly, M. Maistro, F. Piroi (Eds.), CLEF\\n2021 Labs and Workshops, Notebook Papers, CEUR-WS.org, 2021.\\n[36] S. Nath, Style Change Detection using Siamese Neural Networks, in: G. Faggioli, N. Ferro,\\nA. Joly, M. Maistro, F. Piroi (Eds.), CLEF 2021 Labs and Workshops, Notebook Papers,\\nCEUR-WS.org, 2021.\\n[37] R. Singh, J. Weerasinghe, R. Greenstadt, Writing Style Change Detection on Multi-Author\\nDocuments, in: G. Faggioli, N. Ferro, A. Joly, M. Maistro, F. Piroi (Eds.), CLEF 2021 Labs\\nand Workshops, Notebook Papers, CEUR-WS.org, 2021.\\n[38] J. Weerasinghe, R. Greenstadt, Feature Vector Difference based Neural Network and\\nLogistic Regression Models for Authorship Verification—Notebook for PAN at CLEF 2020,\\nin: L. Cappellato, C. Eickhoff, N. Ferro, A. Névéol (Eds.), CLEF 2020 Labs and Workshops,\\nNotebook Papers, CEUR-WS.org, 2020. URL: http://ceur-ws.org/Vol-2696/.\\n[39] E. Strøm, Multi-label Style Change Detection by Solving a Binary Classification Problem,\\nin: G. Faggioli, N. Ferro, A. Joly, M. Maistro, F. Piroi (Eds.), CLEF 2021 Labs and Workshops,\\nNotebook Papers, CEUR-WS.org, 2021.\\n[40] D. Zlatkova, D. Kopev, K. Mitov, A. Atanasov, M. Hardalov, I. Koychev, P. Nakov, An\\nEnsemble-Rich Multi-Aspect Approach for Robust Style Change Detection, in: L. Cap-\\npellato, N. Ferro, J.-Y. Nie, L. Soulier (Eds.), CLEF 2018 Evaluation Labs and Workshop –\\nWorking Notes Papers, CEUR-WS.org, 2018. URL: http://ceur-ws.org/Vol-2125/.\\n[41] Z. Zhang, X. Miao, Z. Peng, J. Zeng, H. Cao, J. Zhang, Z. Xiao, X. Peng, Z. Chen, Using\\nSingle BERT For Three Tasks Of Style Change Detection, in: G. Faggioli, N. Ferro, A. Joly,\\nM. Maistro, F. Piroi (Eds.), CLEF 2021 Labs and Workshops, Notebook Papers, CEUR-WS.org,\\n2021.',\n",
              "  'metadata': {'pdf_name': 'pdfs/paper6.pdf', 'page_number': 12}}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
        "texts = [doc['text'] for doc in documents]\n",
        "embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "print(f\"Generated embeddings with shape: {embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543,
          "referenced_widgets": [
            "71f384587e0b4553b07d885350a48dea",
            "c4de613495504628bee804881b3d8c74",
            "1ec69d6519a143d99d5972c56743a6a7",
            "570ee34a791443cfba0870b23b61f7c9",
            "2d059c89edb540c0a822642348478c47",
            "63969a2f79ad49d99e291e0494c33daf",
            "50c2cdcb6e8f4fc683115f4f28cb2a93",
            "e4631ec49221494b8f3c70e826bbe06f",
            "b6b0f94b8e1342ae8a4a81b84b790bd3",
            "7596d07653a34bcba67a2deb5563c42c",
            "ce8f28275db74aacbdefa85168e94a47",
            "c1ea5a6c8cf44bf3aa972e42a6f89449",
            "41da6c085aa042b48f23081e1bf543c9",
            "492068c601f541019acc0ea2213202af",
            "7a6aa7e1b33047819d7c398b0b3152de",
            "f0bc60c16de64998a5952b3b964aab49",
            "36673e4d1726400c98e36f6182d00977",
            "70ee57e7aba24b0f9695dafd2d775237",
            "847f8467da7944b4b69454ff3e573241",
            "cb3e9db95d7c4a2da6ea15fca94b00ee",
            "f0078407ed9c455dbd40bf63353a66ca",
            "2a63d4a922804af0a3fecfc79187ff93",
            "9423016dd66d4058ae6a98283b87e777",
            "9a2064f0a92d43c783af421bae64024d",
            "4755aa8144ff4898b80a364211bfbeed",
            "e9dec7c4e29041d8a36267bd53ea0ffc",
            "b471f07e0e0f4856920f378bc1919333",
            "e4f086ceeec049c69eb8a2dde5fb2906",
            "8dba3258797845d085e7cd80e2c0f89b",
            "5022eade0e7b4079afd0533d92dd785a",
            "841e592303f744489b5c25617e171314",
            "e490c1742c58427da4bf7300834c0ef3",
            "3a9bb727b1d244be89a978b18f2cc02a",
            "9801e816e89f4c15983cbbcef1ce42e7",
            "293c966312ee41739743ad863baabc44",
            "8f9e79c0fc284b52a4324f2ae060058a",
            "9633f4341e694cad869d8d57cd85b522",
            "f6ca572f8f5e41e3a7a838f8de5f8a9c",
            "9e55702a99ee4a538e7415e74eefe277",
            "3c06e87dc8c24731bc487203e8a8ab66",
            "5b822d32639d4ce284b951eba119c1e4",
            "ddf2ef4809d4408ca1bf48586572ab74",
            "d72ca3aad3634036885bcf053535b5cb",
            "779efa90c47c43a38a3c61b0266d04d8",
            "4b510b5c7fe14913a12107cda36f18f0",
            "fc9731119c9549409cdd5d61b6a38e42",
            "1283416421a841c6bb88dec79a877890",
            "db4717718c3e43b48f93f76b4f872fa5",
            "6666c9a7956241c5b6b970ae0e03a6eb",
            "65956c79ae8445629ae013930554c7f2",
            "6b0675320ef74960b25564e9f4afedd1",
            "b9c513c169a249e3b61da6a8c1060b99",
            "07a0f87ff9354b4c85cdfba289d03479",
            "e4b58f4bbcb641c883c4c53be7fa5729",
            "9af903f921064e5484f32457db9aecac",
            "eb41898edcf94935bde32d172d6d978f",
            "6c0e9f6288634a32af8b2af43b9d1830",
            "545d649ade3146feb16272c15ff42fa8",
            "67b7e28e861c41d0b3741b27d9072548",
            "3089fbdc77f84dd0ba2d4951e9e3b6ba",
            "fd51c4418295493b9f68f377db874986",
            "6e1bd5d010014b58bdbbb513d91213c0",
            "6c814e9b7ec241079e48c68cd46a968d",
            "32c657d729fd4fbdae3a13391ef8a2b9",
            "d7b44fb563a1451aba5dd941f804a67b",
            "ef70282b85a346d18d563d7c916fdb61",
            "e2dda32c91584cde849b41e83673155e",
            "5ace37b0370c428bb1a464c586e6e4fe",
            "1588a12a17e449ba8f1179fc470c51e8",
            "03755b8a4d0949e399803034ddd9aef9",
            "1a862d1ea11a49068ebe86f44e136b33",
            "96a13efbf547470a87be1c9db9dd2272",
            "8d36187ecf744498941b515f6ea8c85a",
            "46abe32f03094116a85839cae23b9c0f",
            "10476b81a0ea41beb3f54069c335b708",
            "dbad0d23c34c42f99e82dbc923ba7567",
            "4797b886396d4630a9aaf8c5a025eaf2",
            "50267adf874a4e17a5aeee7c82a14194",
            "438bd203129440fc93e7ea3dd36d67a8",
            "175088eb061648a79036d70990b42b7e",
            "ef93fb24c9d444d4a928d1167b8bffb0",
            "02e1a3b5094b42dfb92bf72a20d48658",
            "1206800d135f435e9fc8da9a5658df86",
            "ffb359a1cf4c462e8f7f006dfd148197",
            "3bb358d4ab1145f0a784011f8ac661c9",
            "154d21a5e42c4332af6b9fa093da2e0c",
            "e1220998d0b54205965ebb0feee394c6",
            "5e4258f202ee4ebf85c9195c8634e91c",
            "d0d327e8f53f4846b49814c9a268202f",
            "7a8af82a5b324ab89eb058d0583096c1",
            "8e763cb3dfda467abcdfda291e325cb6",
            "ba6fe5b7c30645f1884faf4282d55ba7",
            "47b3bb81b8484277906c2b460ac5be0a",
            "c098199528ee45979e849c6e5913254d",
            "f9b89c52f676487bbbbc5c83552a1776",
            "bbdfb39027be4988a6ea9ec090408bf9",
            "c50b2e2b4b794ff58857fd88d56ff05d",
            "b29dd93abef24a20b1157b5abd5d8a48",
            "7874344b77bf48bda06473cc7f788737",
            "d04f911c0d614436b26a0690dae20b11",
            "f2b41f0ff1e144aab36469bd09531a8e",
            "a050b5dfa21a430a82222e3949b909f9",
            "90ff7a5db7fa4925b6fa560656ad8b0f",
            "59d2470f514243b6b51a51a6c769acbb",
            "d3ee03896594418fa1d9fa1f2c33a2d2",
            "de0485a3bd254764853f3adcb6c26674",
            "800161aa93974147b4619728f44a3bd2",
            "fc476a0b2a7147e99e8e51f09b077f20",
            "a57427b060e14babb10b2ab25d0961c3",
            "f301d0ba13004c2dbedd5ba05cb61448",
            "e62f425c0ae74c99a52fc52fa51681f9",
            "58f2912b50ec4a749b3d3efed0a06ae2",
            "4a960afdd85f4c1f810712ca447f51fa",
            "86b48514e0f44eb4ace81af26d5acddf",
            "e4e25537895a4ff3b919c09ffcfc46b7",
            "b708eede63f74354b5100a6efaf63b24",
            "ec2e39a5b641410e97a7267967920e8e",
            "07355938f4174d6f9289812ccbc4d3e9",
            "e8a5943235bd4ee1b3d36d9b9644f6b9",
            "cb53e6c6e908497dbd709def074e4a6e",
            "44247bd81dee43f185898791f9f62915",
            "891f0c94c80c4bceb5928af747eab8e1",
            "7c0d55bd93974d4d89db34e2401050d6",
            "27828d1b909148e68263aed5ebbd1f3c",
            "f61294417a3b487281c36cb264ae7bb4",
            "dad7ed65b2304eb9bed2e8301a2c2103",
            "bf5d5e0d6c2343f1bbcbff29acee3545",
            "1789afc9665b420e86ce56f2dafa7072",
            "de8119660ee8459bbd65f6268a8258aa",
            "3bdd2bafdc1e46498df5eb177a0616e3",
            "757cbbec88c8430fb6b88cfd1b8e4e63",
            "49ed227c7e8149e8b01893fefdbc3893"
          ]
        },
        "id": "_DVEkLZyBu5h",
        "outputId": "affdf9c1-86b3-4165-e5b9-e121a6c5d382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71f384587e0b4553b07d885350a48dea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1ea5a6c8cf44bf3aa972e42a6f89449"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9423016dd66d4058ae6a98283b87e777"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9801e816e89f4c15983cbbcef1ce42e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b510b5c7fe14913a12107cda36f18f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb41898edcf94935bde32d172d6d978f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2dda32c91584cde849b41e83673155e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50267adf874a4e17a5aeee7c82a14194"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0d327e8f53f4846b49814c9a268202f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d04f911c0d614436b26a0690dae20b11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e62f425c0ae74c99a52fc52fa51681f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "891f0c94c80c4bceb5928af747eab8e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated embeddings with shape: (80, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "res = faiss.StandardGpuResources()  # Use GPU\n",
        "gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "gpu_index.add(embeddings)\n",
        "print(f\"FAISS index created with {gpu_index.ntotal} vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2eppvjrBy9q",
        "outputId": "33ae6632-cc6b-42dd-c5de-59241e3a527b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index created with 80 vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search(query, top_k=5):\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    distances, indices = gpu_index.search(query_embedding, top_k)\n",
        "    results = []\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        results.append({\n",
        "            'text': documents[idx]['text'],\n",
        "            'metadata': documents[idx]['metadata'],\n",
        "            'distance': distances[0][i]\n",
        "        })\n",
        "    return results"
      ],
      "metadata": {
        "id": "txYaZkrMB_Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rerank_results(query, results):\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)[0]\n",
        "    for result in results:\n",
        "        doc_embedding = model.encode([result['text']], convert_to_numpy=True)[0]\n",
        "        cosine_sim = np.dot(query_embedding, doc_embedding) / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding))\n",
        "        result['cosine_similarity'] = cosine_sim\n",
        "    return sorted(results, key=lambda x: x['cosine_similarity'], reverse=True)"
      ],
      "metadata": {
        "id": "sXMJ1PW3CCGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2').to('cuda')"
      ],
      "metadata": {
        "id": "c87e9I_JCDy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(context, query):\n",
        "    input_text = f\"Question: {query}\\nContext: {context[:500]}...\\nAnswer:\"  # Limit context length\n",
        "    inputs = tokenizer(input_text, return_tensors='pt', truncation=True, max_length=512).to('cuda')\n",
        "    outputs = gpt2_model.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=1024,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer.split(\"Answer:\")[1].strip()"
      ],
      "metadata": {
        "id": "QzbL-jm5EKy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_queries = [\n",
        "    \"Summarize the results of Paper 1?\",\n",
        "    \"What methodology did Paper 2 use?\",\n",
        "    \"Across all the papers, which paper had the best results and what techniques did they use?\"\n",
        "]"
      ],
      "metadata": {
        "id": "MTB4bxVjCGDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for query in example_queries:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    # Search and rerank\n",
        "    initial_results = semantic_search(query, top_k=5)\n",
        "    reranked_results = rerank_results(query, initial_results)\n",
        "    # Generate answer from top result\n",
        "    top_context = reranked_results[0]['text']\n",
        "    answer = generate_answer(top_context, query)\n",
        "    print(f\"Generated Answer: {answer}\")\n",
        "    # Display top-3 results with metadata\n",
        "    print(\"Top-3 Retrieved Results:\")\n",
        "    for i, result in enumerate(reranked_results[:3], 1):\n",
        "        excerpt = result['text'][:200] + \"...\" if len(result['text']) > 200 else result['text']\n",
        "        print(f\"{i}. PDF: {result['metadata']['pdf_name']}, Page: {result['metadata']['page_number']}\")\n",
        "        print(f\"   Similarity Score: {result['cosine_similarity']:.4f}\")\n",
        "        print(f\"   Excerpt: {excerpt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIlQGoxhCdC5",
        "outputId": "0895381e-45a4-457e-adc8-85a183d7e938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Summarize the results of Paper 1?\n",
            "Generated Answer: in this context, the number of authors in a do... hashemi is also an indicator of the number of authors in a do...\n",
            "3 4 5\n",
            "Number of Authors0.00.20.40.60.81.0ScoreT ask 2 F1-Score Over Number of Authors\n",
            "participant\n",
            "sengkungsukawaka\n",
            "hyoungmo\n",
            "sang\n",
            "sangchi\n",
            "\n",
            "young\n",
            "\n",
            "sangchi\n",
            "\n",
            "young\n",
            "\n",
            "4 5 4\n",
            "Group 1 (1st) 5.7 1.7 2.0 5.7 4.0 4.0 3.0 3.0 4.0 3.0 4.0 3.0 4.0 3.0\n",
            "5 6 7 8\n",
            "Group 2 (2nd) 7.6 3.2 4.0 6.0 6.0 4.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
            "9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n",
            "\n",
            "Loading... Loading...\n",
            "\n",
            "Quotes are not sourced from all markets and may be delayed up to 20 minutes. Information is provided 'as is' and solely for informational purposes, not for trading purposes or advice.Disclaimer Table 1\n",
            "\n",
            "A browser error has occurred.\n",
            "\n",
            "Please press Ctrl-F5 to refresh the page and try again.\n",
            "\n",
            "A browser error has occurred.\n",
            "\n",
            "Please hold the Shift key and click the Refresh button to try again.\n",
            "Top-3 Retrieved Results:\n",
            "1. PDF: pdfs/paper3.pdf, Page: 6\n",
            "   Similarity Score: 0.4434\n",
            "   Excerpt: easy medium hard\n",
            "Data Set0.00.20.40.60.81.0ScoreOverall Scores\n",
            "chen\n",
            "hashemihuang\n",
            "jacobokucukkaya\n",
            "yeFigure 1: Overall results for the Multi-Author Writing Style task at PAN 2023.\n",
            "2 3 4\n",
            "Number of Author...\n",
            "2. PDF: pdfs/paper4.pdf, Page: 8\n",
            "   Similarity Score: 0.4350\n",
            "   Excerpt: 1 2 3 4 5\n",
            "Number of Authors0.00.20.40.60.81.0ScoreT ask 2 F1-Score Over Number of Authors\n",
            "participant\n",
            "alshmasy\n",
            "alvi\n",
            "castro\n",
            "qidilao\n",
            "tzumilin\n",
            "xinyin\n",
            "yang\n",
            "zhang(a)Task 2\n",
            "1 2 3 4 5\n",
            "Number  of Authors0.00....\n",
            "3. PDF: pdfs/paper6.pdf, Page: 8\n",
            "   Similarity Score: 0.3968\n",
            "   Excerpt: task1 task2 task3\n",
            "Metric0.00.20.40.60.81.0ScoreOverall Scores For Single-Author Documents\n",
            "nath\n",
            "singhstrom\n",
            "zhangdeibel(a) Single-author documents\n",
            "task1 task2 task3\n",
            "Metric0.00.20.40.60.81.0ScoreOverall ...\n",
            "\n",
            "Query: What methodology did Paper 2 use?\n",
            "Generated Answer: Yes and no\n",
            "3 4 5\n",
            "Number of Authors0.00.20.40.60.81.0ScoreT ask 4 F1-Score Over Number of Authors\n",
            "chen\n",
            "hashemi\n",
            "huang\n",
            "kuang\n",
            "seim\n",
            "kucukkaya\n",
            "ye\n",
            "4 5 6\n",
            "Number  of Authors0.00.20.40.60.81.0ScoreT ask 5 F1-Score Over Number of Authors\n",
            "3.4 4 5\n",
            "Question: My wife and I were both asked to write for our company. What is your reaction?\n",
            "Top-3 Retrieved Results:\n",
            "1. PDF: pdfs/paper3.pdf, Page: 6\n",
            "   Similarity Score: 0.3394\n",
            "   Excerpt: easy medium hard\n",
            "Data Set0.00.20.40.60.81.0ScoreOverall Scores\n",
            "chen\n",
            "hashemihuang\n",
            "jacobokucukkaya\n",
            "yeFigure 1: Overall results for the Multi-Author Writing Style task at PAN 2023.\n",
            "2 3 4\n",
            "Number of Author...\n",
            "2. PDF: pdfs/paper1.pdf, Page: 2\n",
            "   Similarity Score: 0.3223\n",
            "   Excerpt: 2 Ayele et al.\n",
            "1 Introduction\n",
            "PAN is a workshop series and a networking initiative for stylometry and digi-\n",
            "tal text forensics. PAN hosts computational shared tasks on authorship analy-\n",
            "sis, computati...\n",
            "3. PDF: pdfs/paper1.pdf, Page: 3\n",
            "   Similarity Score: 0.3141\n",
            "   Excerpt: Overview of PAN 2024: Condensed Lab Overview 3\n",
            "2 Multi-Author Writing Style Analysis\n",
            "The analysis of writing styles is the foundation of authorship identification tasks.\n",
            "The multi-author writing style...\n",
            "\n",
            "Query: Across all the papers, which paper had the best results and what techniques did they use?\n",
            "Generated Answer: This is a great example of how you can actually use a tool like this to evaluate the effectiveness of a document. I've already mentioned something about using a tool like this in the post \"How to Evaluate a Document\".\n",
            "Figure 4: Comparison of the scores of the three different methods, and the results of this analysis.\n",
            "Top-3 Retrieved Results:\n",
            "1. PDF: pdfs/paper4.pdf, Page: 8\n",
            "   Similarity Score: 0.4066\n",
            "   Excerpt: 1 2 3 4 5\n",
            "Number of Authors0.00.20.40.60.81.0ScoreT ask 2 F1-Score Over Number of Authors\n",
            "participant\n",
            "alshmasy\n",
            "alvi\n",
            "castro\n",
            "qidilao\n",
            "tzumilin\n",
            "xinyin\n",
            "yang\n",
            "zhang(a)Task 2\n",
            "1 2 3 4 5\n",
            "Number  of Authors0.00....\n",
            "2. PDF: pdfs/paper3.pdf, Page: 6\n",
            "   Similarity Score: 0.3934\n",
            "   Excerpt: easy medium hard\n",
            "Data Set0.00.20.40.60.81.0ScoreOverall Scores\n",
            "chen\n",
            "hashemihuang\n",
            "jacobokucukkaya\n",
            "yeFigure 1: Overall results for the Multi-Author Writing Style task at PAN 2023.\n",
            "2 3 4\n",
            "Number of Author...\n",
            "3. PDF: pdfs/paper1.pdf, Page: 4\n",
            "   Similarity Score: 0.3287\n",
            "   Excerpt: 4 Ayele et al.\n",
            "Table 1: Overall results for the multi-author analysis task, ranked by average F 1\n",
            "performance across all three datasets. Best results are marked in bold.\n",
            "Team Easy F 1Medium F 1Hard F ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJR2qREYDmpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}